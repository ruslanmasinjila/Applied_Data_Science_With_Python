{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KEYWORDS\n",
    "\n",
    "merge, concatenate, idioms, scales, pivot table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging Data Frames\n",
    "# Merging them horizontally or concatenating them vertically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Role\n",
      "Name                 \n",
      "Kelly  Director of HR\n",
      "Sally  Course liasion\n",
      "James          Grader\n",
      "            School\n",
      "Name              \n",
      "James     Business\n",
      "Mike           Law\n",
      "Sally  Engineering\n"
     ]
    }
   ],
   "source": [
    "# First we create two DataFrames, staff and students.\n",
    "staff_df = pd.DataFrame([{'Name': 'Kelly', 'Role': 'Director of HR'},\n",
    "                         {'Name': 'Sally', 'Role': 'Course liasion'},\n",
    "                         {'Name': 'James', 'Role': 'Grader'}])\n",
    "\n",
    "# And lets index these staff by name\n",
    "staff_df = staff_df.set_index('Name')\n",
    "\n",
    "# Now we'll create a student dataframe\n",
    "student_df = pd.DataFrame([{'Name': 'James', 'School': 'Business'},\n",
    "                           {'Name': 'Mike', 'School': 'Law'},\n",
    "                           {'Name': 'Sally', 'School': 'Engineering'}])\n",
    "# And we'll index this by name too\n",
    "student_df = student_df.set_index('Name')\n",
    "\n",
    "# And lets just print out the dataframes\n",
    "print(staff_df.head())\n",
    "print(student_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Role</th>\n",
       "      <th>School</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>James</th>\n",
       "      <td>Grader</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kelly</th>\n",
       "      <td>Director of HR</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mike</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Law</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sally</th>\n",
       "      <td>Course liasion</td>\n",
       "      <td>Engineering</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Role       School\n",
       "Name                              \n",
       "James          Grader     Business\n",
       "Kelly  Director of HR          NaN\n",
       "Mike              NaN          Law\n",
       "Sally  Course liasion  Engineering"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There's some overlap in these DataFrames in that James and Sally are both students and staff, but Mike and\n",
    "# Kelly are not. Importantly, both DataFrames are indexed along the value we want to merge them on, which is\n",
    "# called Name.\n",
    "\n",
    "# If we want the union of these, we would call merge() passing in the DataFrame on the left and the DataFrame\n",
    "# on the right and telling merge that we want it to use an outer join. We want to use the left and right\n",
    "# indices as the joining columns.\n",
    "\n",
    "pd.merge(staff_df, student_df, how='outer', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Role</th>\n",
       "      <th>School</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sally</th>\n",
       "      <td>Course liasion</td>\n",
       "      <td>Engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>James</th>\n",
       "      <td>Grader</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Role       School\n",
       "Name                              \n",
       "Sally  Course liasion  Engineering\n",
       "James          Grader     Business"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We see in the resulting DataFrame that everyone is listed. And since Mike does not have a role, and John\n",
    "# does not have a school, those cells are listed as missing values.\n",
    "\n",
    "# If we wanted to get the intersection, that is, just those who are a student AND a staff, we could set the\n",
    "# how attribute to inner. Again, we set both left and right indices to be true as the joining columns\n",
    "pd.merge(staff_df, student_df, how='inner', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Role</th>\n",
       "      <th>School</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Kelly</th>\n",
       "      <td>Director of HR</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sally</th>\n",
       "      <td>Course liasion</td>\n",
       "      <td>Engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>James</th>\n",
       "      <td>Grader</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Role       School\n",
       "Name                              \n",
       "Kelly  Director of HR          NaN\n",
       "Sally  Course liasion  Engineering\n",
       "James          Grader     Business"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And we see the resulting DataFrame has only James and Sally in it. Now there are two other common use cases\n",
    "# when merging DataFrames, and both are examples of what we would call set addition. The first is when we\n",
    "# would want to get a list of all staff regardless of whether they were students or not. But if they were\n",
    "# students, we would want to get their student details as well. To do this we would use a left join. It is\n",
    "# important to note the order of dataframes in this function: the first dataframe is the left dataframe and\n",
    "# the second is the right\n",
    "\n",
    "pd.merge(staff_df, student_df, how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Role</th>\n",
       "      <th>School</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>James</th>\n",
       "      <td>Grader</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mike</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Law</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sally</th>\n",
       "      <td>Course liasion</td>\n",
       "      <td>Engineering</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Role       School\n",
       "Name                              \n",
       "James          Grader     Business\n",
       "Mike              NaN          Law\n",
       "Sally  Course liasion  Engineering"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You could probably guess what comes next. We want a list of all of the students and their roles if they were\n",
    "# also staff. To do this we would do a right join.\n",
    "pd.merge(staff_df, student_df, how='right', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Role</th>\n",
       "      <th>Location_x</th>\n",
       "      <th>School</th>\n",
       "      <th>Location_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kelly</td>\n",
       "      <td>Director of HR</td>\n",
       "      <td>State Street</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sally</td>\n",
       "      <td>Course liasion</td>\n",
       "      <td>Washington Avenue</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>512 Wilson Crescent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>James</td>\n",
       "      <td>Grader</td>\n",
       "      <td>Washington Avenue</td>\n",
       "      <td>Business</td>\n",
       "      <td>1024 Billiard Avenue</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name            Role         Location_x       School            Location_y\n",
       "0  Kelly  Director of HR       State Street          NaN                   NaN\n",
       "1  Sally  Course liasion  Washington Avenue  Engineering   512 Wilson Crescent\n",
       "2  James          Grader  Washington Avenue     Business  1024 Billiard Avenue"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the \"on\" parameter instead of a the index is how I find myself using merge() the most.\n",
    "\n",
    "# So what happens when we have conflicts between the DataFrames? Let's take a look by creating new staff and\n",
    "# student DataFrames that have a location information added to them.\n",
    "staff_df = pd.DataFrame([{'Name': 'Kelly', 'Role': 'Director of HR', \n",
    "                          'Location': 'State Street'},\n",
    "                         {'Name': 'Sally', 'Role': 'Course liasion', \n",
    "                          'Location': 'Washington Avenue'},\n",
    "                         {'Name': 'James', 'Role': 'Grader', \n",
    "                          'Location': 'Washington Avenue'}])\n",
    "student_df = pd.DataFrame([{'Name': 'James', 'School': 'Business', \n",
    "                            'Location': '1024 Billiard Avenue'},\n",
    "                           {'Name': 'Mike', 'School': 'Law', \n",
    "                            'Location': 'Fraternity House #22'},\n",
    "                           {'Name': 'Sally', 'School': 'Engineering', \n",
    "                            'Location': '512 Wilson Crescent'}])\n",
    "\n",
    "# In the staff DataFrame, this is an office location where we can find the staff person. And we can see the\n",
    "# Director of HR is on State Street, while the two students are on Washington Avenue, and these locations just\n",
    "# happen to be right outside my window as I film this. But for the student DataFrame, the location information\n",
    "# is actually their home address.\n",
    "\n",
    "# The merge function preserves this information, but appends an _x or _y to help differentiate between which\n",
    "# index went with which column of data. The _x is always the left DataFrame information, and the _y is always\n",
    "# the right DataFrame information.\n",
    "\n",
    "# Here, if we want all the staff information regardless of whether they were students or not. But if they were\n",
    "# students, we would want to get their student details as well.Then we can do a left join and on the column of\n",
    "# Name\n",
    "\n",
    "pd.merge(staff_df, student_df, how='left', on='Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>First Name</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Role</th>\n",
       "      <th>School</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sally</td>\n",
       "      <td>Brooks</td>\n",
       "      <td>Course liasion</td>\n",
       "      <td>Engineering</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  First Name Last Name            Role       School\n",
       "0      Sally    Brooks  Course liasion  Engineering"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From the output, we can see there are columns Location_x and Location_y. Location_x refers to the Location\n",
    "# column in the left dataframe, which is staff dataframe and Location_y refers to the Location column in the\n",
    "# right dataframe, which is student dataframe.\n",
    "\n",
    "# Before we leave merging of DataFrames, let's talk about multi-indexing and multiple columns. It's quite\n",
    "# possible that the first name for students and staff might overlap, but the last name might not. In this\n",
    "# case, we use a list of the multiple columns that should be used to join keys from both dataframes on the on\n",
    "# parameter. Recall that the column name(s) assigned to the on parameter needs to exist in both dataframes.\n",
    "\n",
    "# Here's an example with some new student and staff data\n",
    "staff_df = pd.DataFrame([{'First Name': 'Kelly', 'Last Name': 'Desjardins', \n",
    "                          'Role': 'Director of HR'},\n",
    "                         {'First Name': 'Sally', 'Last Name': 'Brooks', \n",
    "                          'Role': 'Course liasion'},\n",
    "                         {'First Name': 'James', 'Last Name': 'Wilde', \n",
    "                          'Role': 'Grader'}])\n",
    "student_df = pd.DataFrame([{'First Name': 'James', 'Last Name': 'Hammond', \n",
    "                            'School': 'Business'},\n",
    "                           {'First Name': 'Mike', 'Last Name': 'Smith', \n",
    "                            'School': 'Law'},\n",
    "                           {'First Name': 'Sally', 'Last Name': 'Brooks', \n",
    "                            'School': 'Engineering'}])\n",
    "\n",
    "# As you see here, James Wilde and James Hammond don't match on both keys since they have different last\n",
    "# names. So we would expect that an inner join doesn't include these individuals in the output, and only Sally\n",
    "# Brooks will be retained.\n",
    "pd.merge(staff_df, student_df, how='inner', on=['First Name','Last Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining dataframes through merging is incredibly common, and you'll need to know how to pull data from\n",
    "# different sources, clean it, and join it for analysis. This is a staple not only of pandas, but of database\n",
    "# technologies as well.\n",
    "\n",
    "# If we think of merging as joining \"horizontally\", meaning we join on similar values in a column found in two\n",
    "# dataframes then concatenating is joining \"vertically\", meaning we put dataframes on top or at the bottom of\n",
    "# each other\n",
    "\n",
    "# Let's understand this from an example. You have a dataset that tracks some information over the years. And\n",
    "# each year's record is a separate CSV and every CSV ofr every year's record has the exactly same columns.\n",
    "# What happens if you want to put all the data, from all years' record, together? You can concatenate them.\n",
    "\n",
    "# Let's take a look at the US Department of Education College Scorecard data It has each US university's data\n",
    "# on student completion, student debt, after-graduation income, etc. The data is stored in separate CSV's with\n",
    "# each CSV containing a year's record Let's say we want the records from 2011 to 2013 we first create three\n",
    "# dataframe, each containing one year's record. And, because the csv files we're working with are messy, I\n",
    "# want to supress some of the jupyter warning messages and just tell read_csv to ignore bad lines, so I'm\n",
    "# going to start the cell with a cell magic called %%capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# That's a bit surprising that the number of schools in the scorecard for 2011 is almost double that of the\n",
    "# next two years. But let's not worry about that. Instead, let's just put all three dataframes in a list and\n",
    "# call that list frames and pass the list into the concat() function Let's see what it looks like\n",
    "\n",
    "\n",
    "#=======================================================\n",
    "\n",
    "\n",
    "#frames = [df_2011, df_2012, df_2013]\n",
    "#pd.concat(frames)\n",
    "\n",
    "#=======================================================\n",
    "\n",
    "\n",
    "# As you can see, we have more observations in one dataframe and columns remain the same. If we scroll down to\n",
    "# the bottom of the output, we see that there are a total of 30,832 rows after concatenating three dataframes.\n",
    "# Let's add the number of rows of the three dataframes and see if the two numbers match\n",
    "\n",
    "\n",
    "#len(df_2011)+len(df_2012)+len(df_2013)\n",
    "\n",
    "\n",
    "#=======================================================\n",
    "\n",
    "# The two numbers match! Which means our concatenation is successful. But wait, now that all the data is\n",
    "# concatenated together, we don't know what observations are from what year anymore! Actually the concat\n",
    "# function has a parameter that solves such problem with the keys parameter, we can set an extra level of\n",
    "# indices, we pass in a list of keys that we want to correspond to the dataframes into the keys parameter\n",
    "\n",
    "# Now let's try it out\n",
    "#=======================================================\n",
    "# pd.concat(frames, keys=['2011','2012','2013'])\n",
    "#=======================================================\n",
    "\n",
    "# Now we have the indices as the year so we know what observations are from what year. You should know that\n",
    "# concatenation also has inner and outer method. If you are concatenating two dataframes that do not have\n",
    "# identical columns, and choose the outer method, some cells will be NaN. If you choose to do inner, then some\n",
    "# observations will be dropped due to NaN values. You can think of this as analogous to the left and right\n",
    "# joins of the merge() function.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you know how to merge and concatenate datasets together. You will find such functions very useful for\n",
    "combining data to get more complex or complicated results and to do analysis with. A solid understanding of\n",
    "how to merge data is absolutely essentially when you are procuring, cleaning, and manipulating data. It's\n",
    "worth knowing how to join different datasets quickly, and the different options you can use when joining\n",
    "datasets, and I would encourage you to check out the pandas docs for joining and concatenating data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Idioms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUMLEV</th>\n",
       "      <th>REGION</th>\n",
       "      <th>DIVISION</th>\n",
       "      <th>STATE</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>STNAME</th>\n",
       "      <th>CTYNAME</th>\n",
       "      <th>CENSUS2010POP</th>\n",
       "      <th>ESTIMATESBASE2010</th>\n",
       "      <th>POPESTIMATE2010</th>\n",
       "      <th>...</th>\n",
       "      <th>RDOMESTICMIG2011</th>\n",
       "      <th>RDOMESTICMIG2012</th>\n",
       "      <th>RDOMESTICMIG2013</th>\n",
       "      <th>RDOMESTICMIG2014</th>\n",
       "      <th>RDOMESTICMIG2015</th>\n",
       "      <th>RNETMIG2011</th>\n",
       "      <th>RNETMIG2012</th>\n",
       "      <th>RNETMIG2013</th>\n",
       "      <th>RNETMIG2014</th>\n",
       "      <th>RNETMIG2015</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>4779736</td>\n",
       "      <td>4780127</td>\n",
       "      <td>4785161</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002295</td>\n",
       "      <td>-0.193196</td>\n",
       "      <td>0.381066</td>\n",
       "      <td>0.582002</td>\n",
       "      <td>-0.467369</td>\n",
       "      <td>1.030015</td>\n",
       "      <td>0.826644</td>\n",
       "      <td>1.383282</td>\n",
       "      <td>1.724718</td>\n",
       "      <td>0.712594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>54571</td>\n",
       "      <td>54571</td>\n",
       "      <td>54660</td>\n",
       "      <td>...</td>\n",
       "      <td>7.242091</td>\n",
       "      <td>-2.915927</td>\n",
       "      <td>-3.012349</td>\n",
       "      <td>2.265971</td>\n",
       "      <td>-2.530799</td>\n",
       "      <td>7.606016</td>\n",
       "      <td>-2.626146</td>\n",
       "      <td>-2.722002</td>\n",
       "      <td>2.592270</td>\n",
       "      <td>-2.187333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Baldwin County</td>\n",
       "      <td>182265</td>\n",
       "      <td>182265</td>\n",
       "      <td>183193</td>\n",
       "      <td>...</td>\n",
       "      <td>14.832960</td>\n",
       "      <td>17.647293</td>\n",
       "      <td>21.845705</td>\n",
       "      <td>19.243287</td>\n",
       "      <td>17.197872</td>\n",
       "      <td>15.844176</td>\n",
       "      <td>18.559627</td>\n",
       "      <td>22.727626</td>\n",
       "      <td>20.317142</td>\n",
       "      <td>18.293499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Barbour County</td>\n",
       "      <td>27457</td>\n",
       "      <td>27457</td>\n",
       "      <td>27341</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.728132</td>\n",
       "      <td>-2.500690</td>\n",
       "      <td>-7.056824</td>\n",
       "      <td>-3.904217</td>\n",
       "      <td>-10.543299</td>\n",
       "      <td>-4.874741</td>\n",
       "      <td>-2.758113</td>\n",
       "      <td>-7.167664</td>\n",
       "      <td>-3.978583</td>\n",
       "      <td>-10.543299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Bibb County</td>\n",
       "      <td>22915</td>\n",
       "      <td>22919</td>\n",
       "      <td>22861</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.527043</td>\n",
       "      <td>-5.068871</td>\n",
       "      <td>-6.201001</td>\n",
       "      <td>-0.177537</td>\n",
       "      <td>0.177258</td>\n",
       "      <td>-5.088389</td>\n",
       "      <td>-4.363636</td>\n",
       "      <td>-5.403729</td>\n",
       "      <td>0.754533</td>\n",
       "      <td>1.107861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SUMLEV  REGION  DIVISION  STATE  COUNTY   STNAME         CTYNAME  \\\n",
       "0      40       3         6      1       0  Alabama         Alabama   \n",
       "1      50       3         6      1       1  Alabama  Autauga County   \n",
       "2      50       3         6      1       3  Alabama  Baldwin County   \n",
       "3      50       3         6      1       5  Alabama  Barbour County   \n",
       "4      50       3         6      1       7  Alabama     Bibb County   \n",
       "\n",
       "   CENSUS2010POP  ESTIMATESBASE2010  POPESTIMATE2010  ...  RDOMESTICMIG2011  \\\n",
       "0        4779736            4780127          4785161  ...          0.002295   \n",
       "1          54571              54571            54660  ...          7.242091   \n",
       "2         182265             182265           183193  ...         14.832960   \n",
       "3          27457              27457            27341  ...         -4.728132   \n",
       "4          22915              22919            22861  ...         -5.527043   \n",
       "\n",
       "   RDOMESTICMIG2012  RDOMESTICMIG2013  RDOMESTICMIG2014  RDOMESTICMIG2015  \\\n",
       "0         -0.193196          0.381066          0.582002         -0.467369   \n",
       "1         -2.915927         -3.012349          2.265971         -2.530799   \n",
       "2         17.647293         21.845705         19.243287         17.197872   \n",
       "3         -2.500690         -7.056824         -3.904217        -10.543299   \n",
       "4         -5.068871         -6.201001         -0.177537          0.177258   \n",
       "\n",
       "   RNETMIG2011  RNETMIG2012  RNETMIG2013  RNETMIG2014  RNETMIG2015  \n",
       "0     1.030015     0.826644     1.383282     1.724718     0.712594  \n",
       "1     7.606016    -2.626146    -2.722002     2.592270    -2.187333  \n",
       "2    15.844176    18.559627    22.727626    20.317142    18.293499  \n",
       "3    -4.874741    -2.758113    -7.167664    -3.978583   -10.543299  \n",
       "4    -5.088389    -4.363636    -5.403729     0.754533     1.107861  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's start by bringing in our data processing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# And we'll bring in some timing functionality too, from the timeit module\n",
    "import timeit\n",
    "\n",
    "# And lets look at some census data from the US\n",
    "df = pd.read_csv('datasets/census.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>SUMLEV</th>\n",
       "      <th>REGION</th>\n",
       "      <th>DIVISION</th>\n",
       "      <th>STATE</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>CENSUS2010POP</th>\n",
       "      <th>Estimates Base 2010</th>\n",
       "      <th>POPESTIMATE2010</th>\n",
       "      <th>POPESTIMATE2011</th>\n",
       "      <th>POPESTIMATE2012</th>\n",
       "      <th>...</th>\n",
       "      <th>RDOMESTICMIG2011</th>\n",
       "      <th>RDOMESTICMIG2012</th>\n",
       "      <th>RDOMESTICMIG2013</th>\n",
       "      <th>RDOMESTICMIG2014</th>\n",
       "      <th>RDOMESTICMIG2015</th>\n",
       "      <th>RNETMIG2011</th>\n",
       "      <th>RNETMIG2012</th>\n",
       "      <th>RNETMIG2013</th>\n",
       "      <th>RNETMIG2014</th>\n",
       "      <th>RNETMIG2015</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STNAME</th>\n",
       "      <th>CTYNAME</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Alabama</th>\n",
       "      <th>Autauga County</th>\n",
       "      <td>50.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>54571.0</td>\n",
       "      <td>54571.0</td>\n",
       "      <td>54660.0</td>\n",
       "      <td>55253.0</td>\n",
       "      <td>55175.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.242091</td>\n",
       "      <td>-2.915927</td>\n",
       "      <td>-3.012349</td>\n",
       "      <td>2.265971</td>\n",
       "      <td>-2.530799</td>\n",
       "      <td>7.606016</td>\n",
       "      <td>-2.626146</td>\n",
       "      <td>-2.722002</td>\n",
       "      <td>2.592270</td>\n",
       "      <td>-2.187333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baldwin County</th>\n",
       "      <td>50.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>182265.0</td>\n",
       "      <td>182265.0</td>\n",
       "      <td>183193.0</td>\n",
       "      <td>186659.0</td>\n",
       "      <td>190396.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.832960</td>\n",
       "      <td>17.647293</td>\n",
       "      <td>21.845705</td>\n",
       "      <td>19.243287</td>\n",
       "      <td>17.197872</td>\n",
       "      <td>15.844176</td>\n",
       "      <td>18.559627</td>\n",
       "      <td>22.727626</td>\n",
       "      <td>20.317142</td>\n",
       "      <td>18.293499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barbour County</th>\n",
       "      <td>50.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>27457.0</td>\n",
       "      <td>27457.0</td>\n",
       "      <td>27341.0</td>\n",
       "      <td>27226.0</td>\n",
       "      <td>27159.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.728132</td>\n",
       "      <td>-2.500690</td>\n",
       "      <td>-7.056824</td>\n",
       "      <td>-3.904217</td>\n",
       "      <td>-10.543299</td>\n",
       "      <td>-4.874741</td>\n",
       "      <td>-2.758113</td>\n",
       "      <td>-7.167664</td>\n",
       "      <td>-3.978583</td>\n",
       "      <td>-10.543299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bibb County</th>\n",
       "      <td>50.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>22915.0</td>\n",
       "      <td>22919.0</td>\n",
       "      <td>22861.0</td>\n",
       "      <td>22733.0</td>\n",
       "      <td>22642.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.527043</td>\n",
       "      <td>-5.068871</td>\n",
       "      <td>-6.201001</td>\n",
       "      <td>-0.177537</td>\n",
       "      <td>0.177258</td>\n",
       "      <td>-5.088389</td>\n",
       "      <td>-4.363636</td>\n",
       "      <td>-5.403729</td>\n",
       "      <td>0.754533</td>\n",
       "      <td>1.107861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blount County</th>\n",
       "      <td>50.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>57322.0</td>\n",
       "      <td>57322.0</td>\n",
       "      <td>57373.0</td>\n",
       "      <td>57711.0</td>\n",
       "      <td>57776.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.807375</td>\n",
       "      <td>-1.177622</td>\n",
       "      <td>-1.748766</td>\n",
       "      <td>-2.062535</td>\n",
       "      <td>-1.369970</td>\n",
       "      <td>1.859511</td>\n",
       "      <td>-0.848580</td>\n",
       "      <td>-1.402476</td>\n",
       "      <td>-1.577232</td>\n",
       "      <td>-0.884411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Wyoming</th>\n",
       "      <th>Sweetwater County</th>\n",
       "      <td>50.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>43806.0</td>\n",
       "      <td>43806.0</td>\n",
       "      <td>43593.0</td>\n",
       "      <td>44041.0</td>\n",
       "      <td>45104.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.072643</td>\n",
       "      <td>16.243199</td>\n",
       "      <td>-5.339774</td>\n",
       "      <td>-14.252889</td>\n",
       "      <td>-14.248864</td>\n",
       "      <td>1.255221</td>\n",
       "      <td>16.243199</td>\n",
       "      <td>-5.295460</td>\n",
       "      <td>-14.075283</td>\n",
       "      <td>-14.070195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Teton County</th>\n",
       "      <td>50.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>21294.0</td>\n",
       "      <td>21294.0</td>\n",
       "      <td>21297.0</td>\n",
       "      <td>21482.0</td>\n",
       "      <td>21697.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.589565</td>\n",
       "      <td>0.972695</td>\n",
       "      <td>19.525929</td>\n",
       "      <td>14.143021</td>\n",
       "      <td>-0.564849</td>\n",
       "      <td>0.654527</td>\n",
       "      <td>2.408578</td>\n",
       "      <td>21.160658</td>\n",
       "      <td>16.308671</td>\n",
       "      <td>1.520747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uinta County</th>\n",
       "      <td>50.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>21118.0</td>\n",
       "      <td>21118.0</td>\n",
       "      <td>21102.0</td>\n",
       "      <td>20912.0</td>\n",
       "      <td>20989.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-17.755986</td>\n",
       "      <td>-4.916350</td>\n",
       "      <td>-6.902954</td>\n",
       "      <td>-14.215862</td>\n",
       "      <td>-12.127022</td>\n",
       "      <td>-18.136812</td>\n",
       "      <td>-5.536861</td>\n",
       "      <td>-7.521840</td>\n",
       "      <td>-14.740608</td>\n",
       "      <td>-12.606351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Washakie County</th>\n",
       "      <td>50.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>8533.0</td>\n",
       "      <td>8533.0</td>\n",
       "      <td>8545.0</td>\n",
       "      <td>8469.0</td>\n",
       "      <td>8443.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.637475</td>\n",
       "      <td>-0.827815</td>\n",
       "      <td>-2.013502</td>\n",
       "      <td>-17.781491</td>\n",
       "      <td>1.682288</td>\n",
       "      <td>-11.990126</td>\n",
       "      <td>-1.182592</td>\n",
       "      <td>-2.250385</td>\n",
       "      <td>-18.020168</td>\n",
       "      <td>1.441961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weston County</th>\n",
       "      <td>50.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>7208.0</td>\n",
       "      <td>7208.0</td>\n",
       "      <td>7181.0</td>\n",
       "      <td>7114.0</td>\n",
       "      <td>7065.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.752361</td>\n",
       "      <td>-8.040059</td>\n",
       "      <td>12.372583</td>\n",
       "      <td>1.533635</td>\n",
       "      <td>6.935294</td>\n",
       "      <td>-12.032179</td>\n",
       "      <td>-8.040059</td>\n",
       "      <td>12.372583</td>\n",
       "      <td>1.533635</td>\n",
       "      <td>6.935294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3142 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           SUMLEV  REGION  DIVISION  STATE  COUNTY  \\\n",
       "STNAME  CTYNAME                                                      \n",
       "Alabama Autauga County       50.0     3.0       6.0    1.0     1.0   \n",
       "        Baldwin County       50.0     3.0       6.0    1.0     3.0   \n",
       "        Barbour County       50.0     3.0       6.0    1.0     5.0   \n",
       "        Bibb County          50.0     3.0       6.0    1.0     7.0   \n",
       "        Blount County        50.0     3.0       6.0    1.0     9.0   \n",
       "...                           ...     ...       ...    ...     ...   \n",
       "Wyoming Sweetwater County    50.0     4.0       8.0   56.0    37.0   \n",
       "        Teton County         50.0     4.0       8.0   56.0    39.0   \n",
       "        Uinta County         50.0     4.0       8.0   56.0    41.0   \n",
       "        Washakie County      50.0     4.0       8.0   56.0    43.0   \n",
       "        Weston County        50.0     4.0       8.0   56.0    45.0   \n",
       "\n",
       "                           CENSUS2010POP  Estimates Base 2010  \\\n",
       "STNAME  CTYNAME                                                 \n",
       "Alabama Autauga County           54571.0              54571.0   \n",
       "        Baldwin County          182265.0             182265.0   \n",
       "        Barbour County           27457.0              27457.0   \n",
       "        Bibb County              22915.0              22919.0   \n",
       "        Blount County            57322.0              57322.0   \n",
       "...                                  ...                  ...   \n",
       "Wyoming Sweetwater County        43806.0              43806.0   \n",
       "        Teton County             21294.0              21294.0   \n",
       "        Uinta County             21118.0              21118.0   \n",
       "        Washakie County           8533.0               8533.0   \n",
       "        Weston County             7208.0               7208.0   \n",
       "\n",
       "                           POPESTIMATE2010  POPESTIMATE2011  POPESTIMATE2012  \\\n",
       "STNAME  CTYNAME                                                                \n",
       "Alabama Autauga County             54660.0          55253.0          55175.0   \n",
       "        Baldwin County            183193.0         186659.0         190396.0   \n",
       "        Barbour County             27341.0          27226.0          27159.0   \n",
       "        Bibb County                22861.0          22733.0          22642.0   \n",
       "        Blount County              57373.0          57711.0          57776.0   \n",
       "...                                    ...              ...              ...   \n",
       "Wyoming Sweetwater County          43593.0          44041.0          45104.0   \n",
       "        Teton County               21297.0          21482.0          21697.0   \n",
       "        Uinta County               21102.0          20912.0          20989.0   \n",
       "        Washakie County             8545.0           8469.0           8443.0   \n",
       "        Weston County               7181.0           7114.0           7065.0   \n",
       "\n",
       "                           ...  RDOMESTICMIG2011  RDOMESTICMIG2012  \\\n",
       "STNAME  CTYNAME            ...                                       \n",
       "Alabama Autauga County     ...          7.242091         -2.915927   \n",
       "        Baldwin County     ...         14.832960         17.647293   \n",
       "        Barbour County     ...         -4.728132         -2.500690   \n",
       "        Bibb County        ...         -5.527043         -5.068871   \n",
       "        Blount County      ...          1.807375         -1.177622   \n",
       "...                        ...               ...               ...   \n",
       "Wyoming Sweetwater County  ...          1.072643         16.243199   \n",
       "        Teton County       ...         -1.589565          0.972695   \n",
       "        Uinta County       ...        -17.755986         -4.916350   \n",
       "        Washakie County    ...        -11.637475         -0.827815   \n",
       "        Weston County      ...        -11.752361         -8.040059   \n",
       "\n",
       "                           RDOMESTICMIG2013  RDOMESTICMIG2014  \\\n",
       "STNAME  CTYNAME                                                 \n",
       "Alabama Autauga County            -3.012349          2.265971   \n",
       "        Baldwin County            21.845705         19.243287   \n",
       "        Barbour County            -7.056824         -3.904217   \n",
       "        Bibb County               -6.201001         -0.177537   \n",
       "        Blount County             -1.748766         -2.062535   \n",
       "...                                     ...               ...   \n",
       "Wyoming Sweetwater County         -5.339774        -14.252889   \n",
       "        Teton County              19.525929         14.143021   \n",
       "        Uinta County              -6.902954        -14.215862   \n",
       "        Washakie County           -2.013502        -17.781491   \n",
       "        Weston County             12.372583          1.533635   \n",
       "\n",
       "                           RDOMESTICMIG2015  RNETMIG2011  RNETMIG2012  \\\n",
       "STNAME  CTYNAME                                                         \n",
       "Alabama Autauga County            -2.530799     7.606016    -2.626146   \n",
       "        Baldwin County            17.197872    15.844176    18.559627   \n",
       "        Barbour County           -10.543299    -4.874741    -2.758113   \n",
       "        Bibb County                0.177258    -5.088389    -4.363636   \n",
       "        Blount County             -1.369970     1.859511    -0.848580   \n",
       "...                                     ...          ...          ...   \n",
       "Wyoming Sweetwater County        -14.248864     1.255221    16.243199   \n",
       "        Teton County              -0.564849     0.654527     2.408578   \n",
       "        Uinta County             -12.127022   -18.136812    -5.536861   \n",
       "        Washakie County            1.682288   -11.990126    -1.182592   \n",
       "        Weston County              6.935294   -12.032179    -8.040059   \n",
       "\n",
       "                           RNETMIG2013  RNETMIG2014  RNETMIG2015  \n",
       "STNAME  CTYNAME                                                   \n",
       "Alabama Autauga County       -2.722002     2.592270    -2.187333  \n",
       "        Baldwin County       22.727626    20.317142    18.293499  \n",
       "        Barbour County       -7.167664    -3.978583   -10.543299  \n",
       "        Bibb County          -5.403729     0.754533     1.107861  \n",
       "        Blount County        -1.402476    -1.577232    -0.884411  \n",
       "...                                ...          ...          ...  \n",
       "Wyoming Sweetwater County    -5.295460   -14.075283   -14.070195  \n",
       "        Teton County         21.160658    16.308671     1.520747  \n",
       "        Uinta County         -7.521840   -14.740608   -12.606351  \n",
       "        Washakie County      -2.250385   -18.020168     1.441961  \n",
       "        Weston County        12.372583     1.533635     6.935294  \n",
       "\n",
       "[3142 rows x 98 columns]"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The first of the pandas idioms I would like to talk about is called method chaining. The general idea behind\n",
    "# method chaining is that every method on an object returns a reference to that object. The beauty of this is\n",
    "# that you can condense many different operations on a DataFrame, for instance, into one line or at least one\n",
    "# statement of code.\n",
    "\n",
    "# Here's the pandorable way to write code with method chaining. In this code I'm going to pull out the state\n",
    "# and city names as a multiple index, and I'm going to do so only for data which has a summary level of 50,\n",
    "# which in this dataset is county-level data. I'll rename a column too, just to make it a bit more readable.\n",
    "(df.where(df['SUMLEV']==50)\n",
    "    .dropna()\n",
    "    .set_index(['STNAME','CTYNAME'])\n",
    "    .rename(columns={'ESTIMATESBASE2010': 'Estimates Base 2010'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets walk through this. First, we use the where() function on the dataframe and pass in a boolean mask which\n",
    "# is only true for those rows where the SUMLEV is equal to 50. This indicates in our source data that the data\n",
    "# is summarized at the county level. With the result of the where() function evaluated, we drop missing\n",
    "# values. Remember that .where() doesn't drop missing values by default. Then we set an index on the result of\n",
    "# that. In this case I've set it to the state name followed by the county name. Finally. I rename a column to\n",
    "# make it more readable. Note that instead of writing this all on one line, as I could have done, I began the\n",
    "# statement with a parenthesis, which tells python I'm going to span the statement over multiple lines for\n",
    "# readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>SUMLEV</th>\n",
       "      <th>REGION</th>\n",
       "      <th>DIVISION</th>\n",
       "      <th>STATE</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>CENSUS2010POP</th>\n",
       "      <th>Estimates Base 2010</th>\n",
       "      <th>POPESTIMATE2010</th>\n",
       "      <th>POPESTIMATE2011</th>\n",
       "      <th>POPESTIMATE2012</th>\n",
       "      <th>...</th>\n",
       "      <th>RDOMESTICMIG2011</th>\n",
       "      <th>RDOMESTICMIG2012</th>\n",
       "      <th>RDOMESTICMIG2013</th>\n",
       "      <th>RDOMESTICMIG2014</th>\n",
       "      <th>RDOMESTICMIG2015</th>\n",
       "      <th>RNETMIG2011</th>\n",
       "      <th>RNETMIG2012</th>\n",
       "      <th>RNETMIG2013</th>\n",
       "      <th>RNETMIG2014</th>\n",
       "      <th>RNETMIG2015</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STNAME</th>\n",
       "      <th>CTYNAME</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Alabama</th>\n",
       "      <th>Autauga County</th>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>54571</td>\n",
       "      <td>54571</td>\n",
       "      <td>54660</td>\n",
       "      <td>55253</td>\n",
       "      <td>55175</td>\n",
       "      <td>...</td>\n",
       "      <td>7.242091</td>\n",
       "      <td>-2.915927</td>\n",
       "      <td>-3.012349</td>\n",
       "      <td>2.265971</td>\n",
       "      <td>-2.530799</td>\n",
       "      <td>7.606016</td>\n",
       "      <td>-2.626146</td>\n",
       "      <td>-2.722002</td>\n",
       "      <td>2.592270</td>\n",
       "      <td>-2.187333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baldwin County</th>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>182265</td>\n",
       "      <td>182265</td>\n",
       "      <td>183193</td>\n",
       "      <td>186659</td>\n",
       "      <td>190396</td>\n",
       "      <td>...</td>\n",
       "      <td>14.832960</td>\n",
       "      <td>17.647293</td>\n",
       "      <td>21.845705</td>\n",
       "      <td>19.243287</td>\n",
       "      <td>17.197872</td>\n",
       "      <td>15.844176</td>\n",
       "      <td>18.559627</td>\n",
       "      <td>22.727626</td>\n",
       "      <td>20.317142</td>\n",
       "      <td>18.293499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barbour County</th>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>27457</td>\n",
       "      <td>27457</td>\n",
       "      <td>27341</td>\n",
       "      <td>27226</td>\n",
       "      <td>27159</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.728132</td>\n",
       "      <td>-2.500690</td>\n",
       "      <td>-7.056824</td>\n",
       "      <td>-3.904217</td>\n",
       "      <td>-10.543299</td>\n",
       "      <td>-4.874741</td>\n",
       "      <td>-2.758113</td>\n",
       "      <td>-7.167664</td>\n",
       "      <td>-3.978583</td>\n",
       "      <td>-10.543299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bibb County</th>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>22915</td>\n",
       "      <td>22919</td>\n",
       "      <td>22861</td>\n",
       "      <td>22733</td>\n",
       "      <td>22642</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.527043</td>\n",
       "      <td>-5.068871</td>\n",
       "      <td>-6.201001</td>\n",
       "      <td>-0.177537</td>\n",
       "      <td>0.177258</td>\n",
       "      <td>-5.088389</td>\n",
       "      <td>-4.363636</td>\n",
       "      <td>-5.403729</td>\n",
       "      <td>0.754533</td>\n",
       "      <td>1.107861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blount County</th>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>57322</td>\n",
       "      <td>57322</td>\n",
       "      <td>57373</td>\n",
       "      <td>57711</td>\n",
       "      <td>57776</td>\n",
       "      <td>...</td>\n",
       "      <td>1.807375</td>\n",
       "      <td>-1.177622</td>\n",
       "      <td>-1.748766</td>\n",
       "      <td>-2.062535</td>\n",
       "      <td>-1.369970</td>\n",
       "      <td>1.859511</td>\n",
       "      <td>-0.848580</td>\n",
       "      <td>-1.402476</td>\n",
       "      <td>-1.577232</td>\n",
       "      <td>-0.884411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Wyoming</th>\n",
       "      <th>Sweetwater County</th>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>56</td>\n",
       "      <td>37</td>\n",
       "      <td>43806</td>\n",
       "      <td>43806</td>\n",
       "      <td>43593</td>\n",
       "      <td>44041</td>\n",
       "      <td>45104</td>\n",
       "      <td>...</td>\n",
       "      <td>1.072643</td>\n",
       "      <td>16.243199</td>\n",
       "      <td>-5.339774</td>\n",
       "      <td>-14.252889</td>\n",
       "      <td>-14.248864</td>\n",
       "      <td>1.255221</td>\n",
       "      <td>16.243199</td>\n",
       "      <td>-5.295460</td>\n",
       "      <td>-14.075283</td>\n",
       "      <td>-14.070195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Teton County</th>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>56</td>\n",
       "      <td>39</td>\n",
       "      <td>21294</td>\n",
       "      <td>21294</td>\n",
       "      <td>21297</td>\n",
       "      <td>21482</td>\n",
       "      <td>21697</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.589565</td>\n",
       "      <td>0.972695</td>\n",
       "      <td>19.525929</td>\n",
       "      <td>14.143021</td>\n",
       "      <td>-0.564849</td>\n",
       "      <td>0.654527</td>\n",
       "      <td>2.408578</td>\n",
       "      <td>21.160658</td>\n",
       "      <td>16.308671</td>\n",
       "      <td>1.520747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uinta County</th>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>56</td>\n",
       "      <td>41</td>\n",
       "      <td>21118</td>\n",
       "      <td>21118</td>\n",
       "      <td>21102</td>\n",
       "      <td>20912</td>\n",
       "      <td>20989</td>\n",
       "      <td>...</td>\n",
       "      <td>-17.755986</td>\n",
       "      <td>-4.916350</td>\n",
       "      <td>-6.902954</td>\n",
       "      <td>-14.215862</td>\n",
       "      <td>-12.127022</td>\n",
       "      <td>-18.136812</td>\n",
       "      <td>-5.536861</td>\n",
       "      <td>-7.521840</td>\n",
       "      <td>-14.740608</td>\n",
       "      <td>-12.606351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Washakie County</th>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>56</td>\n",
       "      <td>43</td>\n",
       "      <td>8533</td>\n",
       "      <td>8533</td>\n",
       "      <td>8545</td>\n",
       "      <td>8469</td>\n",
       "      <td>8443</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.637475</td>\n",
       "      <td>-0.827815</td>\n",
       "      <td>-2.013502</td>\n",
       "      <td>-17.781491</td>\n",
       "      <td>1.682288</td>\n",
       "      <td>-11.990126</td>\n",
       "      <td>-1.182592</td>\n",
       "      <td>-2.250385</td>\n",
       "      <td>-18.020168</td>\n",
       "      <td>1.441961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weston County</th>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>56</td>\n",
       "      <td>45</td>\n",
       "      <td>7208</td>\n",
       "      <td>7208</td>\n",
       "      <td>7181</td>\n",
       "      <td>7114</td>\n",
       "      <td>7065</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.752361</td>\n",
       "      <td>-8.040059</td>\n",
       "      <td>12.372583</td>\n",
       "      <td>1.533635</td>\n",
       "      <td>6.935294</td>\n",
       "      <td>-12.032179</td>\n",
       "      <td>-8.040059</td>\n",
       "      <td>12.372583</td>\n",
       "      <td>1.533635</td>\n",
       "      <td>6.935294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3142 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           SUMLEV  REGION  DIVISION  STATE  COUNTY  \\\n",
       "STNAME  CTYNAME                                                      \n",
       "Alabama Autauga County         50       3         6      1       1   \n",
       "        Baldwin County         50       3         6      1       3   \n",
       "        Barbour County         50       3         6      1       5   \n",
       "        Bibb County            50       3         6      1       7   \n",
       "        Blount County          50       3         6      1       9   \n",
       "...                           ...     ...       ...    ...     ...   \n",
       "Wyoming Sweetwater County      50       4         8     56      37   \n",
       "        Teton County           50       4         8     56      39   \n",
       "        Uinta County           50       4         8     56      41   \n",
       "        Washakie County        50       4         8     56      43   \n",
       "        Weston County          50       4         8     56      45   \n",
       "\n",
       "                           CENSUS2010POP  Estimates Base 2010  \\\n",
       "STNAME  CTYNAME                                                 \n",
       "Alabama Autauga County             54571                54571   \n",
       "        Baldwin County            182265               182265   \n",
       "        Barbour County             27457                27457   \n",
       "        Bibb County                22915                22919   \n",
       "        Blount County              57322                57322   \n",
       "...                                  ...                  ...   \n",
       "Wyoming Sweetwater County          43806                43806   \n",
       "        Teton County               21294                21294   \n",
       "        Uinta County               21118                21118   \n",
       "        Washakie County             8533                 8533   \n",
       "        Weston County               7208                 7208   \n",
       "\n",
       "                           POPESTIMATE2010  POPESTIMATE2011  POPESTIMATE2012  \\\n",
       "STNAME  CTYNAME                                                                \n",
       "Alabama Autauga County               54660            55253            55175   \n",
       "        Baldwin County              183193           186659           190396   \n",
       "        Barbour County               27341            27226            27159   \n",
       "        Bibb County                  22861            22733            22642   \n",
       "        Blount County                57373            57711            57776   \n",
       "...                                    ...              ...              ...   \n",
       "Wyoming Sweetwater County            43593            44041            45104   \n",
       "        Teton County                 21297            21482            21697   \n",
       "        Uinta County                 21102            20912            20989   \n",
       "        Washakie County               8545             8469             8443   \n",
       "        Weston County                 7181             7114             7065   \n",
       "\n",
       "                           ...  RDOMESTICMIG2011  RDOMESTICMIG2012  \\\n",
       "STNAME  CTYNAME            ...                                       \n",
       "Alabama Autauga County     ...          7.242091         -2.915927   \n",
       "        Baldwin County     ...         14.832960         17.647293   \n",
       "        Barbour County     ...         -4.728132         -2.500690   \n",
       "        Bibb County        ...         -5.527043         -5.068871   \n",
       "        Blount County      ...          1.807375         -1.177622   \n",
       "...                        ...               ...               ...   \n",
       "Wyoming Sweetwater County  ...          1.072643         16.243199   \n",
       "        Teton County       ...         -1.589565          0.972695   \n",
       "        Uinta County       ...        -17.755986         -4.916350   \n",
       "        Washakie County    ...        -11.637475         -0.827815   \n",
       "        Weston County      ...        -11.752361         -8.040059   \n",
       "\n",
       "                           RDOMESTICMIG2013  RDOMESTICMIG2014  \\\n",
       "STNAME  CTYNAME                                                 \n",
       "Alabama Autauga County            -3.012349          2.265971   \n",
       "        Baldwin County            21.845705         19.243287   \n",
       "        Barbour County            -7.056824         -3.904217   \n",
       "        Bibb County               -6.201001         -0.177537   \n",
       "        Blount County             -1.748766         -2.062535   \n",
       "...                                     ...               ...   \n",
       "Wyoming Sweetwater County         -5.339774        -14.252889   \n",
       "        Teton County              19.525929         14.143021   \n",
       "        Uinta County              -6.902954        -14.215862   \n",
       "        Washakie County           -2.013502        -17.781491   \n",
       "        Weston County             12.372583          1.533635   \n",
       "\n",
       "                           RDOMESTICMIG2015  RNETMIG2011  RNETMIG2012  \\\n",
       "STNAME  CTYNAME                                                         \n",
       "Alabama Autauga County            -2.530799     7.606016    -2.626146   \n",
       "        Baldwin County            17.197872    15.844176    18.559627   \n",
       "        Barbour County           -10.543299    -4.874741    -2.758113   \n",
       "        Bibb County                0.177258    -5.088389    -4.363636   \n",
       "        Blount County             -1.369970     1.859511    -0.848580   \n",
       "...                                     ...          ...          ...   \n",
       "Wyoming Sweetwater County        -14.248864     1.255221    16.243199   \n",
       "        Teton County              -0.564849     0.654527     2.408578   \n",
       "        Uinta County             -12.127022   -18.136812    -5.536861   \n",
       "        Washakie County            1.682288   -11.990126    -1.182592   \n",
       "        Weston County              6.935294   -12.032179    -8.040059   \n",
       "\n",
       "                           RNETMIG2013  RNETMIG2014  RNETMIG2015  \n",
       "STNAME  CTYNAME                                                   \n",
       "Alabama Autauga County       -2.722002     2.592270    -2.187333  \n",
       "        Baldwin County       22.727626    20.317142    18.293499  \n",
       "        Barbour County       -7.167664    -3.978583   -10.543299  \n",
       "        Bibb County          -5.403729     0.754533     1.107861  \n",
       "        Blount County        -1.402476    -1.577232    -0.884411  \n",
       "...                                ...          ...          ...  \n",
       "Wyoming Sweetwater County    -5.295460   -14.075283   -14.070195  \n",
       "        Teton County         21.160658    16.308671     1.520747  \n",
       "        Uinta County         -7.521840   -14.740608   -12.606351  \n",
       "        Washakie County      -2.250385   -18.020168     1.441961  \n",
       "        Weston County        12.372583     1.533635     6.935294  \n",
       "\n",
       "[3142 rows x 98 columns]"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here's a more traditional, non-pandorable way, of writing this. There's nothing wrong with this code in the\n",
    "# functional sense, you might even be able to understand it better as a new person to the language. It's just\n",
    "# not as pandorable as the first example.\n",
    "\n",
    "# First create a new dataframe from the original\n",
    "df = df[df['SUMLEV']==50] # I'll use the overloaded indexing operator [] which drops nans\n",
    "# Update the dataframe to have a new index, we use inplace=True to do this in place\n",
    "df.set_index(['STNAME','CTYNAME'], inplace=True)\n",
    "# Set the column names\n",
    "df.rename(columns={'ESTIMATESBASE2010': 'Estimates Base 2010'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15626813500057324"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, the key with any good idiom is to understand when it isn't helping you. In this case, you can actually\n",
    "# time both methods and see which one runs faster\n",
    "\n",
    "# We can put the approach into a function and pass the function into the timeit function to count the time the\n",
    "# parameter number allows us to choose how many times we want to run the function. Here we will just set it to\n",
    "# 10\n",
    "\n",
    "# Lets write a wrapper for our first function\n",
    "def first_approach():\n",
    "    global df\n",
    "    # And we'll just paste our code right here\n",
    "    return (df.where(df['SUMLEV']==50)\n",
    "             .dropna()\n",
    "             .set_index(['STNAME','CTYNAME'])\n",
    "             .rename(columns={'ESTIMATESBASE2010': 'Estimates Base 2010'}))\n",
    "\n",
    "# Read in our dataset anew\n",
    "df = pd.read_csv('datasets/census.csv')\n",
    "\n",
    "# And now lets run it\n",
    "timeit.timeit(first_approach, number=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04595089700160315"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's test the second approach. As you may notice, we use our global variable df in the function.\n",
    "# However, changing a global variable inside a function will modify the variable even in a global scope and we\n",
    "# do not want that to happen in this case. Therefore, for selecting summary levels of 50 only, I create a new\n",
    "# dataframe for those records\n",
    "\n",
    "# Let's run this for once and see how fast it is\n",
    "def second_approach():\n",
    "    global df\n",
    "    new_df = df[df['SUMLEV']==50]\n",
    "    new_df.set_index(['STNAME','CTYNAME'], inplace=True)\n",
    "    return new_df.rename(columns={'ESTIMATESBASE2010': 'Estimates Base 2010'})\n",
    "\n",
    "# Read in our dataset anew\n",
    "df = pd.read_csv('datasets/census.csv')\n",
    "\n",
    "# And now lets run it\n",
    "timeit.timeit(second_approach, number=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As you can see, the second approach is much faster! So, this is a particular example of a classic time\n",
    "# readability trade off.\n",
    "\n",
    "# You'll see lots of examples on stack overflow and in documentation of people using method chaining in their\n",
    "# pandas. And so, I think being able to read and understand the syntax is really worth your time. But keep in\n",
    "# mind that following what appears to be stylistic idioms might have performance issues that you need to\n",
    "# consider as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's another pandas idiom. Python has a wonderful function called map, which is sort of a basis for\n",
    "# functional programming in the language. When you want to use map in Python, you pass it some function you\n",
    "# want called, and some iterable, like a list, that you want the function to be applied to. The results are\n",
    "# that the function is called against each item in the list, and there's a resulting list of all of the\n",
    "# evaluations of that function.\n",
    "\n",
    "# Pandas has a similar function called applymap. In applymap, you provide some function which should operate\n",
    "# on each cell of a DataFrame, and the return set is itself a DataFrame. Now I think applymap is fine, but I\n",
    "# actually rarely use it. Instead, I find myself often wanting to map across all of the rows in a DataFrame.\n",
    "# And pandas has a function that I use heavily there, called apply. Let's look at an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at our census DataFrame. In this DataFrame, we have five columns for population estimates,\n",
    "# with each column corresponding with one year of estimates. It's quite reasonable to want to create some new\n",
    "# columns for minimum or maximum values, and the apply function is an easy way to do this.\n",
    "\n",
    "# First, we need to write a function which takes in a particular row of data, finds a minimum and maximum\n",
    "# values, and returns a new row of data nd returns a new row of data.  We'll call this function min_max, this\n",
    "# is pretty straight forward. We can create some small slice of a row by projecting the population columns.\n",
    "# Then use the NumPy min and max functions, and create a new series with a label values represent the new\n",
    "# values we want to apply.\n",
    "\n",
    "def min_max(row):\n",
    "    data = row[['POPESTIMATE2010',\n",
    "                'POPESTIMATE2011',\n",
    "                'POPESTIMATE2012',\n",
    "                'POPESTIMATE2013',\n",
    "                'POPESTIMATE2014',\n",
    "                'POPESTIMATE2015']]\n",
    "    return pd.Series({'min': np.min(data), 'max': np.max(data)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4785161</td>\n",
       "      <td>4858979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54660</td>\n",
       "      <td>55347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>183193</td>\n",
       "      <td>203709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26489</td>\n",
       "      <td>27341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22512</td>\n",
       "      <td>22861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       min      max\n",
       "0  4785161  4858979\n",
       "1    54660    55347\n",
       "2   183193   203709\n",
       "3    26489    27341\n",
       "4    22512    22861"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Then we just need to call apply on the DataFrame.\n",
    "\n",
    "# Apply takes the function and the axis on which to operate as parameters. Now, we have to be a bit careful,\n",
    "# we've talked about axis zero being the rows of the DataFrame in the past. But this parameter is really the\n",
    "# parameter of the index to use. So, to apply across all rows, which is applying on all columns, you pass axis\n",
    "# equal to 'columns'.\n",
    "df.apply(min_max, axis='columns').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Of course there's no need to limit yourself to returning a new series object. If you're doing this as part\n",
    "# of data cleaning your likely to find yourself wanting to add new data to the existing DataFrame. In that\n",
    "# case you just take the row values and add in new columns indicating the max and minimum scores. This is a\n",
    "# regular part of my workflow when bringing in data and building summary or descriptive statistics, and is\n",
    "# often used heavily with the merging of DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUMLEV</th>\n",
       "      <th>REGION</th>\n",
       "      <th>DIVISION</th>\n",
       "      <th>STATE</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>STNAME</th>\n",
       "      <th>CTYNAME</th>\n",
       "      <th>CENSUS2010POP</th>\n",
       "      <th>ESTIMATESBASE2010</th>\n",
       "      <th>POPESTIMATE2010</th>\n",
       "      <th>...</th>\n",
       "      <th>RDOMESTICMIG2013</th>\n",
       "      <th>RDOMESTICMIG2014</th>\n",
       "      <th>RDOMESTICMIG2015</th>\n",
       "      <th>RNETMIG2011</th>\n",
       "      <th>RNETMIG2012</th>\n",
       "      <th>RNETMIG2013</th>\n",
       "      <th>RNETMIG2014</th>\n",
       "      <th>RNETMIG2015</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>4779736</td>\n",
       "      <td>4780127</td>\n",
       "      <td>4785161</td>\n",
       "      <td>...</td>\n",
       "      <td>0.381066</td>\n",
       "      <td>0.582002</td>\n",
       "      <td>-0.467369</td>\n",
       "      <td>1.030015</td>\n",
       "      <td>0.826644</td>\n",
       "      <td>1.383282</td>\n",
       "      <td>1.724718</td>\n",
       "      <td>0.712594</td>\n",
       "      <td>4858979</td>\n",
       "      <td>4785161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>54571</td>\n",
       "      <td>54571</td>\n",
       "      <td>54660</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.012349</td>\n",
       "      <td>2.265971</td>\n",
       "      <td>-2.530799</td>\n",
       "      <td>7.606016</td>\n",
       "      <td>-2.626146</td>\n",
       "      <td>-2.722002</td>\n",
       "      <td>2.592270</td>\n",
       "      <td>-2.187333</td>\n",
       "      <td>55347</td>\n",
       "      <td>54660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Baldwin County</td>\n",
       "      <td>182265</td>\n",
       "      <td>182265</td>\n",
       "      <td>183193</td>\n",
       "      <td>...</td>\n",
       "      <td>21.845705</td>\n",
       "      <td>19.243287</td>\n",
       "      <td>17.197872</td>\n",
       "      <td>15.844176</td>\n",
       "      <td>18.559627</td>\n",
       "      <td>22.727626</td>\n",
       "      <td>20.317142</td>\n",
       "      <td>18.293499</td>\n",
       "      <td>203709</td>\n",
       "      <td>183193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Barbour County</td>\n",
       "      <td>27457</td>\n",
       "      <td>27457</td>\n",
       "      <td>27341</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.056824</td>\n",
       "      <td>-3.904217</td>\n",
       "      <td>-10.543299</td>\n",
       "      <td>-4.874741</td>\n",
       "      <td>-2.758113</td>\n",
       "      <td>-7.167664</td>\n",
       "      <td>-3.978583</td>\n",
       "      <td>-10.543299</td>\n",
       "      <td>27341</td>\n",
       "      <td>26489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Bibb County</td>\n",
       "      <td>22915</td>\n",
       "      <td>22919</td>\n",
       "      <td>22861</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.201001</td>\n",
       "      <td>-0.177537</td>\n",
       "      <td>0.177258</td>\n",
       "      <td>-5.088389</td>\n",
       "      <td>-4.363636</td>\n",
       "      <td>-5.403729</td>\n",
       "      <td>0.754533</td>\n",
       "      <td>1.107861</td>\n",
       "      <td>22861</td>\n",
       "      <td>22512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3188</th>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>56</td>\n",
       "      <td>37</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>Sweetwater County</td>\n",
       "      <td>43806</td>\n",
       "      <td>43806</td>\n",
       "      <td>43593</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.339774</td>\n",
       "      <td>-14.252889</td>\n",
       "      <td>-14.248864</td>\n",
       "      <td>1.255221</td>\n",
       "      <td>16.243199</td>\n",
       "      <td>-5.295460</td>\n",
       "      <td>-14.075283</td>\n",
       "      <td>-14.070195</td>\n",
       "      <td>45162</td>\n",
       "      <td>43593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3189</th>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>56</td>\n",
       "      <td>39</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>Teton County</td>\n",
       "      <td>21294</td>\n",
       "      <td>21294</td>\n",
       "      <td>21297</td>\n",
       "      <td>...</td>\n",
       "      <td>19.525929</td>\n",
       "      <td>14.143021</td>\n",
       "      <td>-0.564849</td>\n",
       "      <td>0.654527</td>\n",
       "      <td>2.408578</td>\n",
       "      <td>21.160658</td>\n",
       "      <td>16.308671</td>\n",
       "      <td>1.520747</td>\n",
       "      <td>23125</td>\n",
       "      <td>21297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3190</th>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>56</td>\n",
       "      <td>41</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>Uinta County</td>\n",
       "      <td>21118</td>\n",
       "      <td>21118</td>\n",
       "      <td>21102</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.902954</td>\n",
       "      <td>-14.215862</td>\n",
       "      <td>-12.127022</td>\n",
       "      <td>-18.136812</td>\n",
       "      <td>-5.536861</td>\n",
       "      <td>-7.521840</td>\n",
       "      <td>-14.740608</td>\n",
       "      <td>-12.606351</td>\n",
       "      <td>21102</td>\n",
       "      <td>20822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3191</th>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>56</td>\n",
       "      <td>43</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>Washakie County</td>\n",
       "      <td>8533</td>\n",
       "      <td>8533</td>\n",
       "      <td>8545</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.013502</td>\n",
       "      <td>-17.781491</td>\n",
       "      <td>1.682288</td>\n",
       "      <td>-11.990126</td>\n",
       "      <td>-1.182592</td>\n",
       "      <td>-2.250385</td>\n",
       "      <td>-18.020168</td>\n",
       "      <td>1.441961</td>\n",
       "      <td>8545</td>\n",
       "      <td>8316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3192</th>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>56</td>\n",
       "      <td>45</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>Weston County</td>\n",
       "      <td>7208</td>\n",
       "      <td>7208</td>\n",
       "      <td>7181</td>\n",
       "      <td>...</td>\n",
       "      <td>12.372583</td>\n",
       "      <td>1.533635</td>\n",
       "      <td>6.935294</td>\n",
       "      <td>-12.032179</td>\n",
       "      <td>-8.040059</td>\n",
       "      <td>12.372583</td>\n",
       "      <td>1.533635</td>\n",
       "      <td>6.935294</td>\n",
       "      <td>7234</td>\n",
       "      <td>7065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3193 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SUMLEV  REGION  DIVISION  STATE  COUNTY   STNAME            CTYNAME  \\\n",
       "0         40       3         6      1       0  Alabama            Alabama   \n",
       "1         50       3         6      1       1  Alabama     Autauga County   \n",
       "2         50       3         6      1       3  Alabama     Baldwin County   \n",
       "3         50       3         6      1       5  Alabama     Barbour County   \n",
       "4         50       3         6      1       7  Alabama        Bibb County   \n",
       "...      ...     ...       ...    ...     ...      ...                ...   \n",
       "3188      50       4         8     56      37  Wyoming  Sweetwater County   \n",
       "3189      50       4         8     56      39  Wyoming       Teton County   \n",
       "3190      50       4         8     56      41  Wyoming       Uinta County   \n",
       "3191      50       4         8     56      43  Wyoming    Washakie County   \n",
       "3192      50       4         8     56      45  Wyoming      Weston County   \n",
       "\n",
       "      CENSUS2010POP  ESTIMATESBASE2010  POPESTIMATE2010  ...  \\\n",
       "0           4779736            4780127          4785161  ...   \n",
       "1             54571              54571            54660  ...   \n",
       "2            182265             182265           183193  ...   \n",
       "3             27457              27457            27341  ...   \n",
       "4             22915              22919            22861  ...   \n",
       "...             ...                ...              ...  ...   \n",
       "3188          43806              43806            43593  ...   \n",
       "3189          21294              21294            21297  ...   \n",
       "3190          21118              21118            21102  ...   \n",
       "3191           8533               8533             8545  ...   \n",
       "3192           7208               7208             7181  ...   \n",
       "\n",
       "      RDOMESTICMIG2013  RDOMESTICMIG2014  RDOMESTICMIG2015  RNETMIG2011  \\\n",
       "0             0.381066          0.582002         -0.467369     1.030015   \n",
       "1            -3.012349          2.265971         -2.530799     7.606016   \n",
       "2            21.845705         19.243287         17.197872    15.844176   \n",
       "3            -7.056824         -3.904217        -10.543299    -4.874741   \n",
       "4            -6.201001         -0.177537          0.177258    -5.088389   \n",
       "...                ...               ...               ...          ...   \n",
       "3188         -5.339774        -14.252889        -14.248864     1.255221   \n",
       "3189         19.525929         14.143021         -0.564849     0.654527   \n",
       "3190         -6.902954        -14.215862        -12.127022   -18.136812   \n",
       "3191         -2.013502        -17.781491          1.682288   -11.990126   \n",
       "3192         12.372583          1.533635          6.935294   -12.032179   \n",
       "\n",
       "      RNETMIG2012  RNETMIG2013  RNETMIG2014  RNETMIG2015      max      min  \n",
       "0        0.826644     1.383282     1.724718     0.712594  4858979  4785161  \n",
       "1       -2.626146    -2.722002     2.592270    -2.187333    55347    54660  \n",
       "2       18.559627    22.727626    20.317142    18.293499   203709   183193  \n",
       "3       -2.758113    -7.167664    -3.978583   -10.543299    27341    26489  \n",
       "4       -4.363636    -5.403729     0.754533     1.107861    22861    22512  \n",
       "...           ...          ...          ...          ...      ...      ...  \n",
       "3188    16.243199    -5.295460   -14.075283   -14.070195    45162    43593  \n",
       "3189     2.408578    21.160658    16.308671     1.520747    23125    21297  \n",
       "3190    -5.536861    -7.521840   -14.740608   -12.606351    21102    20822  \n",
       "3191    -1.182592    -2.250385   -18.020168     1.441961     8545     8316  \n",
       "3192    -8.040059    12.372583     1.533635     6.935294     7234     7065  \n",
       "\n",
       "[3193 rows x 102 columns]"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here's an example where we have a revised version of the function min_max Instead of returning a separate\n",
    "# series to display the min and max we add two new columns in the original dataframe to store min and max\n",
    "\n",
    "def min_max(row):\n",
    "    data = row[['POPESTIMATE2010',\n",
    "                'POPESTIMATE2011',\n",
    "                'POPESTIMATE2012',\n",
    "                'POPESTIMATE2013',\n",
    "                'POPESTIMATE2014',\n",
    "                'POPESTIMATE2015']]\n",
    "    # Create a new entry for max\n",
    "    row['max'] = np.max(data)\n",
    "    # Create a new entry for min\n",
    "    row['min'] = np.min(data)\n",
    "    return row\n",
    "# Now just apply the function across the dataframe\n",
    "df.apply(min_max, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4858979\n",
       "1      55347\n",
       "2     203709\n",
       "3      27341\n",
       "4      22861\n",
       "dtype: int64"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply is an extremely important tool in your toolkit. The reason I introduced apply here is because you\n",
    "# rarely see it used with large function definitions, like we did. Instead, you typically see it used with\n",
    "# lambdas. To get the most of the discussions you'll see online, you're going to need to know how to at least\n",
    "# read lambdas.\n",
    "\n",
    "# Here's You can imagine how you might chain several apply calls with lambdas together to create a readable\n",
    "# yet succinct data manipulation script. One line example of how you might calculate the max of the columns\n",
    "# using the apply function.\n",
    "rows = ['POPESTIMATE2010', 'POPESTIMATE2011', 'POPESTIMATE2012', 'POPESTIMATE2013','POPESTIMATE2014', \n",
    "        'POPESTIMATE2015']\n",
    "# Now we'll just apply this across the dataframe with a lambda\n",
    "df.apply(lambda x: np.max(x[rows]), axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you don't remember lambdas just pause the video for a moment and look up the syntax. A lambda is just an\n",
    "# unnamed function in python, in this case it takes a single parameter, x, and returns a single value, in this\n",
    "# case the maximum over all columns associated with row x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The beauty of the apply function is that it allows flexibility in doing whatever manipulation that you\n",
    "# desire, as the function you pass into apply can be any customized however you want. Let's say we want to\n",
    "# divide the states into four categories: Northeast, Midwest, South, and West We can write a customized\n",
    "# function that returns the region based on the state the state regions information is obtained from Wikipedia\n",
    "\n",
    "def get_state_region(x):\n",
    "    northeast = ['Connecticut', 'Maine', 'Massachusetts', 'New Hampshire', \n",
    "                 'Rhode Island','Vermont','New York','New Jersey','Pennsylvania']\n",
    "    midwest = ['Illinois','Indiana','Michigan','Ohio','Wisconsin','Iowa',\n",
    "               'Kansas','Minnesota','Missouri','Nebraska','North Dakota',\n",
    "               'South Dakota']\n",
    "    south = ['Delaware','Florida','Georgia','Maryland','North Carolina',\n",
    "             'South Carolina','Virginia','District of Columbia','West Virginia',\n",
    "             'Alabama','Kentucky','Mississippi','Tennessee','Arkansas',\n",
    "             'Louisiana','Oklahoma','Texas']\n",
    "    west = ['Arizona','Colorado','Idaho','Montana','Nevada','New Mexico','Utah',\n",
    "            'Wyoming','Alaska','California','Hawaii','Oregon','Washington']\n",
    "    \n",
    "    if x in northeast:\n",
    "        return \"Northeast\"\n",
    "    elif x in midwest:\n",
    "        return \"Midwest\"\n",
    "    elif x in south:\n",
    "        return \"South\"\n",
    "    else:\n",
    "        return \"West\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have the customized function, let's say we want to create a new column called Region, which shows the\n",
    "# state's region, we can use the customized function and the apply function to do so. The customized function\n",
    "# is supposed to work on the state name column STNAME. So we will set the apply function on the state name\n",
    "# column and pass the customized function into the apply function\n",
    "df['state_region'] = df['STNAME'].apply(lambda x: get_state_region(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STNAME</th>\n",
       "      <th>state_region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>South</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>South</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>South</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>South</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>South</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    STNAME state_region\n",
       "0  Alabama        South\n",
       "1  Alabama        South\n",
       "2  Alabama        South\n",
       "3  Alabama        South\n",
       "4  Alabama        South"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's see the results\n",
    "df[['STNAME','state_region']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Groupby"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUMLEV</th>\n",
       "      <th>REGION</th>\n",
       "      <th>DIVISION</th>\n",
       "      <th>STATE</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>STNAME</th>\n",
       "      <th>CTYNAME</th>\n",
       "      <th>CENSUS2010POP</th>\n",
       "      <th>ESTIMATESBASE2010</th>\n",
       "      <th>POPESTIMATE2010</th>\n",
       "      <th>...</th>\n",
       "      <th>RDOMESTICMIG2011</th>\n",
       "      <th>RDOMESTICMIG2012</th>\n",
       "      <th>RDOMESTICMIG2013</th>\n",
       "      <th>RDOMESTICMIG2014</th>\n",
       "      <th>RDOMESTICMIG2015</th>\n",
       "      <th>RNETMIG2011</th>\n",
       "      <th>RNETMIG2012</th>\n",
       "      <th>RNETMIG2013</th>\n",
       "      <th>RNETMIG2014</th>\n",
       "      <th>RNETMIG2015</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>54571</td>\n",
       "      <td>54571</td>\n",
       "      <td>54660</td>\n",
       "      <td>...</td>\n",
       "      <td>7.242091</td>\n",
       "      <td>-2.915927</td>\n",
       "      <td>-3.012349</td>\n",
       "      <td>2.265971</td>\n",
       "      <td>-2.530799</td>\n",
       "      <td>7.606016</td>\n",
       "      <td>-2.626146</td>\n",
       "      <td>-2.722002</td>\n",
       "      <td>2.592270</td>\n",
       "      <td>-2.187333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Baldwin County</td>\n",
       "      <td>182265</td>\n",
       "      <td>182265</td>\n",
       "      <td>183193</td>\n",
       "      <td>...</td>\n",
       "      <td>14.832960</td>\n",
       "      <td>17.647293</td>\n",
       "      <td>21.845705</td>\n",
       "      <td>19.243287</td>\n",
       "      <td>17.197872</td>\n",
       "      <td>15.844176</td>\n",
       "      <td>18.559627</td>\n",
       "      <td>22.727626</td>\n",
       "      <td>20.317142</td>\n",
       "      <td>18.293499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Barbour County</td>\n",
       "      <td>27457</td>\n",
       "      <td>27457</td>\n",
       "      <td>27341</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.728132</td>\n",
       "      <td>-2.500690</td>\n",
       "      <td>-7.056824</td>\n",
       "      <td>-3.904217</td>\n",
       "      <td>-10.543299</td>\n",
       "      <td>-4.874741</td>\n",
       "      <td>-2.758113</td>\n",
       "      <td>-7.167664</td>\n",
       "      <td>-3.978583</td>\n",
       "      <td>-10.543299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Bibb County</td>\n",
       "      <td>22915</td>\n",
       "      <td>22919</td>\n",
       "      <td>22861</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.527043</td>\n",
       "      <td>-5.068871</td>\n",
       "      <td>-6.201001</td>\n",
       "      <td>-0.177537</td>\n",
       "      <td>0.177258</td>\n",
       "      <td>-5.088389</td>\n",
       "      <td>-4.363636</td>\n",
       "      <td>-5.403729</td>\n",
       "      <td>0.754533</td>\n",
       "      <td>1.107861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Blount County</td>\n",
       "      <td>57322</td>\n",
       "      <td>57322</td>\n",
       "      <td>57373</td>\n",
       "      <td>...</td>\n",
       "      <td>1.807375</td>\n",
       "      <td>-1.177622</td>\n",
       "      <td>-1.748766</td>\n",
       "      <td>-2.062535</td>\n",
       "      <td>-1.369970</td>\n",
       "      <td>1.859511</td>\n",
       "      <td>-0.848580</td>\n",
       "      <td>-1.402476</td>\n",
       "      <td>-1.577232</td>\n",
       "      <td>-0.884411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SUMLEV  REGION  DIVISION  STATE  COUNTY   STNAME         CTYNAME  \\\n",
       "1      50       3         6      1       1  Alabama  Autauga County   \n",
       "2      50       3         6      1       3  Alabama  Baldwin County   \n",
       "3      50       3         6      1       5  Alabama  Barbour County   \n",
       "4      50       3         6      1       7  Alabama     Bibb County   \n",
       "5      50       3         6      1       9  Alabama   Blount County   \n",
       "\n",
       "   CENSUS2010POP  ESTIMATESBASE2010  POPESTIMATE2010  ...  RDOMESTICMIG2011  \\\n",
       "1          54571              54571            54660  ...          7.242091   \n",
       "2         182265             182265           183193  ...         14.832960   \n",
       "3          27457              27457            27341  ...         -4.728132   \n",
       "4          22915              22919            22861  ...         -5.527043   \n",
       "5          57322              57322            57373  ...          1.807375   \n",
       "\n",
       "   RDOMESTICMIG2012  RDOMESTICMIG2013  RDOMESTICMIG2014  RDOMESTICMIG2015  \\\n",
       "1         -2.915927         -3.012349          2.265971         -2.530799   \n",
       "2         17.647293         21.845705         19.243287         17.197872   \n",
       "3         -2.500690         -7.056824         -3.904217        -10.543299   \n",
       "4         -5.068871         -6.201001         -0.177537          0.177258   \n",
       "5         -1.177622         -1.748766         -2.062535         -1.369970   \n",
       "\n",
       "   RNETMIG2011  RNETMIG2012  RNETMIG2013  RNETMIG2014  RNETMIG2015  \n",
       "1     7.606016    -2.626146    -2.722002     2.592270    -2.187333  \n",
       "2    15.844176    18.559627    22.727626    20.317142    18.293499  \n",
       "3    -4.874741    -2.758113    -7.167664    -3.978583   -10.543299  \n",
       "4    -5.088389    -4.363636    -5.403729     0.754533     1.107861  \n",
       "5     1.859511    -0.848580    -1.402476    -1.577232    -0.884411  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's look at some US census data\n",
    "df = pd.read_csv('datasets/census.csv')\n",
    "# And exclude state level summarizations, which have sum level value of 40\n",
    "df = df[df['SUMLEV']==50]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counties in state Alabama have an average population of 71339.34328358209\n",
      "Counties in state Alaska have an average population of 24490.724137931036\n",
      "Counties in state Arizona have an average population of 426134.4666666667\n",
      "Counties in state Arkansas have an average population of 38878.90666666667\n",
      "Counties in state California have an average population of 642309.5862068966\n",
      "Counties in state Colorado have an average population of 78581.1875\n",
      "Counties in state Connecticut have an average population of 446762.125\n",
      "Counties in state Delaware have an average population of 299311.3333333333\n",
      "Counties in state District of Columbia have an average population of 601723.0\n",
      "Counties in state Florida have an average population of 280616.5671641791\n",
      "Counties in state Georgia have an average population of 60928.63522012578\n",
      "Counties in state Hawaii have an average population of 272060.2\n",
      "Counties in state Idaho have an average population of 35626.86363636364\n",
      "Counties in state Illinois have an average population of 125790.50980392157\n",
      "Counties in state Indiana have an average population of 70476.10869565218\n",
      "Counties in state Iowa have an average population of 30771.262626262625\n",
      "Counties in state Kansas have an average population of 27172.55238095238\n",
      "Counties in state Kentucky have an average population of 36161.39166666667\n",
      "Counties in state Louisiana have an average population of 70833.9375\n",
      "Counties in state Maine have an average population of 83022.5625\n",
      "Counties in state Maryland have an average population of 240564.66666666666\n",
      "Counties in state Massachusetts have an average population of 467687.78571428574\n",
      "Counties in state Michigan have an average population of 119080.0\n",
      "Counties in state Minnesota have an average population of 60964.65517241379\n",
      "Counties in state Mississippi have an average population of 36186.54878048781\n",
      "Counties in state Missouri have an average population of 52077.62608695652\n",
      "Counties in state Montana have an average population of 17668.125\n",
      "Counties in state Nebraska have an average population of 19638.075268817203\n",
      "Counties in state Nevada have an average population of 158855.9411764706\n",
      "Counties in state New Hampshire have an average population of 131647.0\n",
      "Counties in state New Jersey have an average population of 418661.61904761905\n",
      "Counties in state New Mexico have an average population of 62399.36363636364\n",
      "Counties in state New York have an average population of 312550.03225806454\n",
      "Counties in state North Carolina have an average population of 95354.83\n",
      "Counties in state North Dakota have an average population of 12690.396226415094\n",
      "Counties in state Ohio have an average population of 131096.63636363635\n",
      "Counties in state Oklahoma have an average population of 48718.844155844155\n",
      "Counties in state Oregon have an average population of 106418.72222222222\n",
      "Counties in state Pennsylvania have an average population of 189587.74626865672\n",
      "Counties in state Rhode Island have an average population of 210513.4\n",
      "Counties in state South Carolina have an average population of 100551.39130434782\n",
      "Counties in state South Dakota have an average population of 12336.060606060606\n",
      "Counties in state Tennessee have an average population of 66801.1052631579\n",
      "Counties in state Texas have an average population of 98998.27165354331\n",
      "Counties in state Utah have an average population of 95306.37931034483\n",
      "Counties in state Vermont have an average population of 44695.78571428572\n",
      "Counties in state Virginia have an average population of 60111.29323308271\n",
      "Counties in state Washington have an average population of 172424.10256410256\n",
      "Counties in state West Virginia have an average population of 33690.8\n",
      "Counties in state Wisconsin have an average population of 78985.91666666667\n",
      "Counties in state Wyoming have an average population of 24505.478260869564\n",
      "Counties in state Alabama have an average population of 71339.34328358209\n",
      "Counties in state Alaska have an average population of 24490.724137931036\n",
      "Counties in state Arizona have an average population of 426134.4666666667\n",
      "Counties in state Arkansas have an average population of 38878.90666666667\n",
      "Counties in state California have an average population of 642309.5862068966\n",
      "Counties in state Colorado have an average population of 78581.1875\n",
      "Counties in state Connecticut have an average population of 446762.125\n",
      "Counties in state Delaware have an average population of 299311.3333333333\n",
      "Counties in state District of Columbia have an average population of 601723.0\n",
      "Counties in state Florida have an average population of 280616.5671641791\n",
      "Counties in state Georgia have an average population of 60928.63522012578\n",
      "Counties in state Hawaii have an average population of 272060.2\n",
      "Counties in state Idaho have an average population of 35626.86363636364\n",
      "Counties in state Illinois have an average population of 125790.50980392157\n",
      "Counties in state Indiana have an average population of 70476.10869565218\n",
      "Counties in state Iowa have an average population of 30771.262626262625\n",
      "Counties in state Kansas have an average population of 27172.55238095238\n",
      "Counties in state Kentucky have an average population of 36161.39166666667\n",
      "Counties in state Louisiana have an average population of 70833.9375\n",
      "Counties in state Maine have an average population of 83022.5625\n",
      "Counties in state Maryland have an average population of 240564.66666666666\n",
      "Counties in state Massachusetts have an average population of 467687.78571428574\n",
      "Counties in state Michigan have an average population of 119080.0\n",
      "Counties in state Minnesota have an average population of 60964.65517241379\n",
      "Counties in state Mississippi have an average population of 36186.54878048781\n",
      "Counties in state Missouri have an average population of 52077.62608695652\n",
      "Counties in state Montana have an average population of 17668.125\n",
      "Counties in state Nebraska have an average population of 19638.075268817203\n",
      "Counties in state Nevada have an average population of 158855.9411764706\n",
      "Counties in state New Hampshire have an average population of 131647.0\n",
      "Counties in state New Jersey have an average population of 418661.61904761905\n",
      "Counties in state New Mexico have an average population of 62399.36363636364\n",
      "Counties in state New York have an average population of 312550.03225806454\n",
      "Counties in state North Carolina have an average population of 95354.83\n",
      "Counties in state North Dakota have an average population of 12690.396226415094\n",
      "Counties in state Ohio have an average population of 131096.63636363635\n",
      "Counties in state Oklahoma have an average population of 48718.844155844155\n",
      "Counties in state Oregon have an average population of 106418.72222222222\n",
      "Counties in state Pennsylvania have an average population of 189587.74626865672\n",
      "Counties in state Rhode Island have an average population of 210513.4\n",
      "Counties in state South Carolina have an average population of 100551.39130434782\n",
      "Counties in state South Dakota have an average population of 12336.060606060606\n",
      "Counties in state Tennessee have an average population of 66801.1052631579\n",
      "Counties in state Texas have an average population of 98998.27165354331\n",
      "Counties in state Utah have an average population of 95306.37931034483\n",
      "Counties in state Vermont have an average population of 44695.78571428572\n",
      "Counties in state Virginia have an average population of 60111.29323308271\n",
      "Counties in state Washington have an average population of 172424.10256410256\n",
      "Counties in state West Virginia have an average population of 33690.8\n",
      "Counties in state Wisconsin have an average population of 78985.91666666667\n",
      "Counties in state Wyoming have an average population of 24505.478260869564\n",
      "Counties in state Alabama have an average population of 71339.34328358209\n",
      "Counties in state Alaska have an average population of 24490.724137931036\n",
      "Counties in state Arizona have an average population of 426134.4666666667\n",
      "Counties in state Arkansas have an average population of 38878.90666666667\n",
      "Counties in state California have an average population of 642309.5862068966\n",
      "Counties in state Colorado have an average population of 78581.1875\n",
      "Counties in state Connecticut have an average population of 446762.125\n",
      "Counties in state Delaware have an average population of 299311.3333333333\n",
      "Counties in state District of Columbia have an average population of 601723.0\n",
      "Counties in state Florida have an average population of 280616.5671641791\n",
      "Counties in state Georgia have an average population of 60928.63522012578\n",
      "Counties in state Hawaii have an average population of 272060.2\n",
      "Counties in state Idaho have an average population of 35626.86363636364\n",
      "Counties in state Illinois have an average population of 125790.50980392157\n",
      "Counties in state Indiana have an average population of 70476.10869565218\n",
      "Counties in state Iowa have an average population of 30771.262626262625\n",
      "Counties in state Kansas have an average population of 27172.55238095238\n",
      "Counties in state Kentucky have an average population of 36161.39166666667\n",
      "Counties in state Louisiana have an average population of 70833.9375\n",
      "Counties in state Maine have an average population of 83022.5625\n",
      "Counties in state Maryland have an average population of 240564.66666666666\n",
      "Counties in state Massachusetts have an average population of 467687.78571428574\n",
      "Counties in state Michigan have an average population of 119080.0\n",
      "Counties in state Minnesota have an average population of 60964.65517241379\n",
      "Counties in state Mississippi have an average population of 36186.54878048781\n",
      "Counties in state Missouri have an average population of 52077.62608695652\n",
      "Counties in state Montana have an average population of 17668.125\n",
      "Counties in state Nebraska have an average population of 19638.075268817203\n",
      "Counties in state Nevada have an average population of 158855.9411764706\n",
      "Counties in state New Hampshire have an average population of 131647.0\n",
      "Counties in state New Jersey have an average population of 418661.61904761905\n",
      "Counties in state New Mexico have an average population of 62399.36363636364\n",
      "Counties in state New York have an average population of 312550.03225806454\n",
      "Counties in state North Carolina have an average population of 95354.83\n",
      "Counties in state North Dakota have an average population of 12690.396226415094\n",
      "Counties in state Ohio have an average population of 131096.63636363635\n",
      "Counties in state Oklahoma have an average population of 48718.844155844155\n",
      "Counties in state Oregon have an average population of 106418.72222222222\n",
      "Counties in state Pennsylvania have an average population of 189587.74626865672\n",
      "Counties in state Rhode Island have an average population of 210513.4\n",
      "Counties in state South Carolina have an average population of 100551.39130434782\n",
      "Counties in state South Dakota have an average population of 12336.060606060606\n",
      "Counties in state Tennessee have an average population of 66801.1052631579\n",
      "Counties in state Texas have an average population of 98998.27165354331\n",
      "Counties in state Utah have an average population of 95306.37931034483\n",
      "Counties in state Vermont have an average population of 44695.78571428572\n",
      "Counties in state Virginia have an average population of 60111.29323308271\n",
      "Counties in state Washington have an average population of 172424.10256410256\n",
      "Counties in state West Virginia have an average population of 33690.8\n",
      "Counties in state Wisconsin have an average population of 78985.91666666667\n",
      "Counties in state Wyoming have an average population of 24505.478260869564\n",
      "Counties in state Alabama have an average population of 71339.34328358209\n",
      "Counties in state Alaska have an average population of 24490.724137931036\n",
      "Counties in state Arizona have an average population of 426134.4666666667\n",
      "Counties in state Arkansas have an average population of 38878.90666666667\n",
      "Counties in state California have an average population of 642309.5862068966\n",
      "Counties in state Colorado have an average population of 78581.1875\n",
      "Counties in state Connecticut have an average population of 446762.125\n",
      "Counties in state Delaware have an average population of 299311.3333333333\n",
      "Counties in state District of Columbia have an average population of 601723.0\n",
      "Counties in state Florida have an average population of 280616.5671641791\n",
      "Counties in state Georgia have an average population of 60928.63522012578\n",
      "Counties in state Hawaii have an average population of 272060.2\n",
      "Counties in state Idaho have an average population of 35626.86363636364\n",
      "Counties in state Illinois have an average population of 125790.50980392157\n",
      "Counties in state Indiana have an average population of 70476.10869565218\n",
      "Counties in state Iowa have an average population of 30771.262626262625\n",
      "Counties in state Kansas have an average population of 27172.55238095238\n",
      "Counties in state Kentucky have an average population of 36161.39166666667\n",
      "Counties in state Louisiana have an average population of 70833.9375\n",
      "Counties in state Maine have an average population of 83022.5625\n",
      "Counties in state Maryland have an average population of 240564.66666666666\n",
      "Counties in state Massachusetts have an average population of 467687.78571428574\n",
      "Counties in state Michigan have an average population of 119080.0\n",
      "Counties in state Minnesota have an average population of 60964.65517241379\n",
      "Counties in state Mississippi have an average population of 36186.54878048781\n",
      "Counties in state Missouri have an average population of 52077.62608695652\n",
      "Counties in state Montana have an average population of 17668.125\n",
      "Counties in state Nebraska have an average population of 19638.075268817203\n",
      "Counties in state Nevada have an average population of 158855.9411764706\n",
      "Counties in state New Hampshire have an average population of 131647.0\n",
      "Counties in state New Jersey have an average population of 418661.61904761905\n",
      "Counties in state New Mexico have an average population of 62399.36363636364\n",
      "Counties in state New York have an average population of 312550.03225806454\n",
      "Counties in state North Carolina have an average population of 95354.83\n",
      "Counties in state North Dakota have an average population of 12690.396226415094\n",
      "Counties in state Ohio have an average population of 131096.63636363635\n",
      "Counties in state Oklahoma have an average population of 48718.844155844155\n",
      "Counties in state Oregon have an average population of 106418.72222222222\n",
      "Counties in state Pennsylvania have an average population of 189587.74626865672\n",
      "Counties in state Rhode Island have an average population of 210513.4\n",
      "Counties in state South Carolina have an average population of 100551.39130434782\n",
      "Counties in state South Dakota have an average population of 12336.060606060606\n",
      "Counties in state Tennessee have an average population of 66801.1052631579\n",
      "Counties in state Texas have an average population of 98998.27165354331\n",
      "Counties in state Utah have an average population of 95306.37931034483\n",
      "Counties in state Vermont have an average population of 44695.78571428572\n",
      "Counties in state Virginia have an average population of 60111.29323308271\n",
      "Counties in state Washington have an average population of 172424.10256410256\n",
      "Counties in state West Virginia have an average population of 33690.8\n",
      "Counties in state Wisconsin have an average population of 78985.91666666667\n",
      "Counties in state Wyoming have an average population of 24505.478260869564\n",
      "Counties in state Alabama have an average population of 71339.34328358209\n",
      "Counties in state Alaska have an average population of 24490.724137931036\n",
      "Counties in state Arizona have an average population of 426134.4666666667\n",
      "Counties in state Arkansas have an average population of 38878.90666666667\n",
      "Counties in state California have an average population of 642309.5862068966\n",
      "Counties in state Colorado have an average population of 78581.1875\n",
      "Counties in state Connecticut have an average population of 446762.125\n",
      "Counties in state Delaware have an average population of 299311.3333333333\n",
      "Counties in state District of Columbia have an average population of 601723.0\n",
      "Counties in state Florida have an average population of 280616.5671641791\n",
      "Counties in state Georgia have an average population of 60928.63522012578\n",
      "Counties in state Hawaii have an average population of 272060.2\n",
      "Counties in state Idaho have an average population of 35626.86363636364\n",
      "Counties in state Illinois have an average population of 125790.50980392157\n",
      "Counties in state Indiana have an average population of 70476.10869565218\n",
      "Counties in state Iowa have an average population of 30771.262626262625\n",
      "Counties in state Kansas have an average population of 27172.55238095238\n",
      "Counties in state Kentucky have an average population of 36161.39166666667\n",
      "Counties in state Louisiana have an average population of 70833.9375\n",
      "Counties in state Maine have an average population of 83022.5625\n",
      "Counties in state Maryland have an average population of 240564.66666666666\n",
      "Counties in state Massachusetts have an average population of 467687.78571428574\n",
      "Counties in state Michigan have an average population of 119080.0\n",
      "Counties in state Minnesota have an average population of 60964.65517241379\n",
      "Counties in state Mississippi have an average population of 36186.54878048781\n",
      "Counties in state Missouri have an average population of 52077.62608695652\n",
      "Counties in state Montana have an average population of 17668.125\n",
      "Counties in state Nebraska have an average population of 19638.075268817203\n",
      "Counties in state Nevada have an average population of 158855.9411764706\n",
      "Counties in state New Hampshire have an average population of 131647.0\n",
      "Counties in state New Jersey have an average population of 418661.61904761905\n",
      "Counties in state New Mexico have an average population of 62399.36363636364\n",
      "Counties in state New York have an average population of 312550.03225806454\n",
      "Counties in state North Carolina have an average population of 95354.83\n",
      "Counties in state North Dakota have an average population of 12690.396226415094\n",
      "Counties in state Ohio have an average population of 131096.63636363635\n",
      "Counties in state Oklahoma have an average population of 48718.844155844155\n",
      "Counties in state Oregon have an average population of 106418.72222222222\n",
      "Counties in state Pennsylvania have an average population of 189587.74626865672\n",
      "Counties in state Rhode Island have an average population of 210513.4\n",
      "Counties in state South Carolina have an average population of 100551.39130434782\n",
      "Counties in state South Dakota have an average population of 12336.060606060606\n",
      "Counties in state Tennessee have an average population of 66801.1052631579\n",
      "Counties in state Texas have an average population of 98998.27165354331\n",
      "Counties in state Utah have an average population of 95306.37931034483\n",
      "Counties in state Vermont have an average population of 44695.78571428572\n",
      "Counties in state Virginia have an average population of 60111.29323308271\n",
      "Counties in state Washington have an average population of 172424.10256410256\n",
      "Counties in state West Virginia have an average population of 33690.8\n",
      "Counties in state Wisconsin have an average population of 78985.91666666667\n",
      "Counties in state Wyoming have an average population of 24505.478260869564\n",
      "Counties in state Alabama have an average population of 71339.34328358209\n",
      "Counties in state Alaska have an average population of 24490.724137931036\n",
      "Counties in state Arizona have an average population of 426134.4666666667\n",
      "Counties in state Arkansas have an average population of 38878.90666666667\n",
      "Counties in state California have an average population of 642309.5862068966\n",
      "Counties in state Colorado have an average population of 78581.1875\n",
      "Counties in state Connecticut have an average population of 446762.125\n",
      "Counties in state Delaware have an average population of 299311.3333333333\n",
      "Counties in state District of Columbia have an average population of 601723.0\n",
      "Counties in state Florida have an average population of 280616.5671641791\n",
      "Counties in state Georgia have an average population of 60928.63522012578\n",
      "Counties in state Hawaii have an average population of 272060.2\n",
      "Counties in state Idaho have an average population of 35626.86363636364\n",
      "Counties in state Illinois have an average population of 125790.50980392157\n",
      "Counties in state Indiana have an average population of 70476.10869565218\n",
      "Counties in state Iowa have an average population of 30771.262626262625\n",
      "Counties in state Kansas have an average population of 27172.55238095238\n",
      "Counties in state Kentucky have an average population of 36161.39166666667\n",
      "Counties in state Louisiana have an average population of 70833.9375\n",
      "Counties in state Maine have an average population of 83022.5625\n",
      "Counties in state Maryland have an average population of 240564.66666666666\n",
      "Counties in state Massachusetts have an average population of 467687.78571428574\n",
      "Counties in state Michigan have an average population of 119080.0\n",
      "Counties in state Minnesota have an average population of 60964.65517241379\n",
      "Counties in state Mississippi have an average population of 36186.54878048781\n",
      "Counties in state Missouri have an average population of 52077.62608695652\n",
      "Counties in state Montana have an average population of 17668.125\n",
      "Counties in state Nebraska have an average population of 19638.075268817203\n",
      "Counties in state Nevada have an average population of 158855.9411764706\n",
      "Counties in state New Hampshire have an average population of 131647.0\n",
      "Counties in state New Jersey have an average population of 418661.61904761905\n",
      "Counties in state New Mexico have an average population of 62399.36363636364\n",
      "Counties in state New York have an average population of 312550.03225806454\n",
      "Counties in state North Carolina have an average population of 95354.83\n",
      "Counties in state North Dakota have an average population of 12690.396226415094\n",
      "Counties in state Ohio have an average population of 131096.63636363635\n",
      "Counties in state Oklahoma have an average population of 48718.844155844155\n",
      "Counties in state Oregon have an average population of 106418.72222222222\n",
      "Counties in state Pennsylvania have an average population of 189587.74626865672\n",
      "Counties in state Rhode Island have an average population of 210513.4\n",
      "Counties in state South Carolina have an average population of 100551.39130434782\n",
      "Counties in state South Dakota have an average population of 12336.060606060606\n",
      "Counties in state Tennessee have an average population of 66801.1052631579\n",
      "Counties in state Texas have an average population of 98998.27165354331\n",
      "Counties in state Utah have an average population of 95306.37931034483\n",
      "Counties in state Vermont have an average population of 44695.78571428572\n",
      "Counties in state Virginia have an average population of 60111.29323308271\n",
      "Counties in state Washington have an average population of 172424.10256410256\n",
      "Counties in state West Virginia have an average population of 33690.8\n",
      "Counties in state Wisconsin have an average population of 78985.91666666667\n",
      "Counties in state Wyoming have an average population of 24505.478260869564\n",
      "Counties in state Alabama have an average population of 71339.34328358209\n",
      "Counties in state Alaska have an average population of 24490.724137931036\n",
      "Counties in state Arizona have an average population of 426134.4666666667\n",
      "Counties in state Arkansas have an average population of 38878.90666666667\n",
      "Counties in state California have an average population of 642309.5862068966\n",
      "Counties in state Colorado have an average population of 78581.1875\n",
      "Counties in state Connecticut have an average population of 446762.125\n",
      "Counties in state Delaware have an average population of 299311.3333333333\n",
      "Counties in state District of Columbia have an average population of 601723.0\n",
      "Counties in state Florida have an average population of 280616.5671641791\n",
      "Counties in state Georgia have an average population of 60928.63522012578\n",
      "Counties in state Hawaii have an average population of 272060.2\n",
      "Counties in state Idaho have an average population of 35626.86363636364\n",
      "Counties in state Illinois have an average population of 125790.50980392157\n",
      "Counties in state Indiana have an average population of 70476.10869565218\n",
      "Counties in state Iowa have an average population of 30771.262626262625\n",
      "Counties in state Kansas have an average population of 27172.55238095238\n",
      "Counties in state Kentucky have an average population of 36161.39166666667\n",
      "Counties in state Louisiana have an average population of 70833.9375\n",
      "Counties in state Maine have an average population of 83022.5625\n",
      "Counties in state Maryland have an average population of 240564.66666666666\n",
      "Counties in state Massachusetts have an average population of 467687.78571428574\n",
      "Counties in state Michigan have an average population of 119080.0\n",
      "Counties in state Minnesota have an average population of 60964.65517241379\n",
      "Counties in state Mississippi have an average population of 36186.54878048781\n",
      "Counties in state Missouri have an average population of 52077.62608695652\n",
      "Counties in state Montana have an average population of 17668.125\n",
      "Counties in state Nebraska have an average population of 19638.075268817203\n",
      "Counties in state Nevada have an average population of 158855.9411764706\n",
      "Counties in state New Hampshire have an average population of 131647.0\n",
      "Counties in state New Jersey have an average population of 418661.61904761905\n",
      "Counties in state New Mexico have an average population of 62399.36363636364\n",
      "Counties in state New York have an average population of 312550.03225806454\n",
      "Counties in state North Carolina have an average population of 95354.83\n",
      "Counties in state North Dakota have an average population of 12690.396226415094\n",
      "Counties in state Ohio have an average population of 131096.63636363635\n",
      "Counties in state Oklahoma have an average population of 48718.844155844155\n",
      "Counties in state Oregon have an average population of 106418.72222222222\n",
      "Counties in state Pennsylvania have an average population of 189587.74626865672\n",
      "Counties in state Rhode Island have an average population of 210513.4\n",
      "Counties in state South Carolina have an average population of 100551.39130434782\n",
      "Counties in state South Dakota have an average population of 12336.060606060606\n",
      "Counties in state Tennessee have an average population of 66801.1052631579\n",
      "Counties in state Texas have an average population of 98998.27165354331\n",
      "Counties in state Utah have an average population of 95306.37931034483\n",
      "Counties in state Vermont have an average population of 44695.78571428572\n",
      "Counties in state Virginia have an average population of 60111.29323308271\n",
      "Counties in state Washington have an average population of 172424.10256410256\n",
      "Counties in state West Virginia have an average population of 33690.8\n",
      "Counties in state Wisconsin have an average population of 78985.91666666667\n",
      "Counties in state Wyoming have an average population of 24505.478260869564\n",
      "Counties in state Alabama have an average population of 71339.34328358209\n",
      "Counties in state Alaska have an average population of 24490.724137931036\n",
      "Counties in state Arizona have an average population of 426134.4666666667\n",
      "Counties in state Arkansas have an average population of 38878.90666666667\n",
      "Counties in state California have an average population of 642309.5862068966\n",
      "Counties in state Colorado have an average population of 78581.1875\n",
      "Counties in state Connecticut have an average population of 446762.125\n",
      "Counties in state Delaware have an average population of 299311.3333333333\n",
      "Counties in state District of Columbia have an average population of 601723.0\n",
      "Counties in state Florida have an average population of 280616.5671641791\n",
      "Counties in state Georgia have an average population of 60928.63522012578\n",
      "Counties in state Hawaii have an average population of 272060.2\n",
      "Counties in state Idaho have an average population of 35626.86363636364\n",
      "Counties in state Illinois have an average population of 125790.50980392157\n",
      "Counties in state Indiana have an average population of 70476.10869565218\n",
      "Counties in state Iowa have an average population of 30771.262626262625\n",
      "Counties in state Kansas have an average population of 27172.55238095238\n",
      "Counties in state Kentucky have an average population of 36161.39166666667\n",
      "Counties in state Louisiana have an average population of 70833.9375\n",
      "Counties in state Maine have an average population of 83022.5625\n",
      "Counties in state Maryland have an average population of 240564.66666666666\n",
      "Counties in state Massachusetts have an average population of 467687.78571428574\n",
      "Counties in state Michigan have an average population of 119080.0\n",
      "Counties in state Minnesota have an average population of 60964.65517241379\n",
      "Counties in state Mississippi have an average population of 36186.54878048781\n",
      "Counties in state Missouri have an average population of 52077.62608695652\n",
      "Counties in state Montana have an average population of 17668.125\n",
      "Counties in state Nebraska have an average population of 19638.075268817203\n",
      "Counties in state Nevada have an average population of 158855.9411764706\n",
      "Counties in state New Hampshire have an average population of 131647.0\n",
      "Counties in state New Jersey have an average population of 418661.61904761905\n",
      "Counties in state New Mexico have an average population of 62399.36363636364\n",
      "Counties in state New York have an average population of 312550.03225806454\n",
      "Counties in state North Carolina have an average population of 95354.83\n",
      "Counties in state North Dakota have an average population of 12690.396226415094\n",
      "Counties in state Ohio have an average population of 131096.63636363635\n",
      "Counties in state Oklahoma have an average population of 48718.844155844155\n",
      "Counties in state Oregon have an average population of 106418.72222222222\n",
      "Counties in state Pennsylvania have an average population of 189587.74626865672\n",
      "Counties in state Rhode Island have an average population of 210513.4\n",
      "Counties in state South Carolina have an average population of 100551.39130434782\n",
      "Counties in state South Dakota have an average population of 12336.060606060606\n",
      "Counties in state Tennessee have an average population of 66801.1052631579\n",
      "Counties in state Texas have an average population of 98998.27165354331\n",
      "Counties in state Utah have an average population of 95306.37931034483\n",
      "Counties in state Vermont have an average population of 44695.78571428572\n",
      "Counties in state Virginia have an average population of 60111.29323308271\n",
      "Counties in state Washington have an average population of 172424.10256410256\n",
      "Counties in state West Virginia have an average population of 33690.8\n",
      "Counties in state Wisconsin have an average population of 78985.91666666667\n",
      "Counties in state Wyoming have an average population of 24505.478260869564\n",
      "Counties in state Alabama have an average population of 71339.34328358209\n",
      "Counties in state Alaska have an average population of 24490.724137931036\n",
      "Counties in state Arizona have an average population of 426134.4666666667\n",
      "Counties in state Arkansas have an average population of 38878.90666666667\n",
      "Counties in state California have an average population of 642309.5862068966\n",
      "Counties in state Colorado have an average population of 78581.1875\n",
      "Counties in state Connecticut have an average population of 446762.125\n",
      "Counties in state Delaware have an average population of 299311.3333333333\n",
      "Counties in state District of Columbia have an average population of 601723.0\n",
      "Counties in state Florida have an average population of 280616.5671641791\n",
      "Counties in state Georgia have an average population of 60928.63522012578\n",
      "Counties in state Hawaii have an average population of 272060.2\n",
      "Counties in state Idaho have an average population of 35626.86363636364\n",
      "Counties in state Illinois have an average population of 125790.50980392157\n",
      "Counties in state Indiana have an average population of 70476.10869565218\n",
      "Counties in state Iowa have an average population of 30771.262626262625\n",
      "Counties in state Kansas have an average population of 27172.55238095238\n",
      "Counties in state Kentucky have an average population of 36161.39166666667\n",
      "Counties in state Louisiana have an average population of 70833.9375\n",
      "Counties in state Maine have an average population of 83022.5625\n",
      "Counties in state Maryland have an average population of 240564.66666666666\n",
      "Counties in state Massachusetts have an average population of 467687.78571428574\n",
      "Counties in state Michigan have an average population of 119080.0\n",
      "Counties in state Minnesota have an average population of 60964.65517241379\n",
      "Counties in state Mississippi have an average population of 36186.54878048781\n",
      "Counties in state Missouri have an average population of 52077.62608695652\n",
      "Counties in state Montana have an average population of 17668.125\n",
      "Counties in state Nebraska have an average population of 19638.075268817203\n",
      "Counties in state Nevada have an average population of 158855.9411764706\n",
      "Counties in state New Hampshire have an average population of 131647.0\n",
      "Counties in state New Jersey have an average population of 418661.61904761905\n",
      "Counties in state New Mexico have an average population of 62399.36363636364\n",
      "Counties in state New York have an average population of 312550.03225806454\n",
      "Counties in state North Carolina have an average population of 95354.83\n",
      "Counties in state North Dakota have an average population of 12690.396226415094\n",
      "Counties in state Ohio have an average population of 131096.63636363635\n",
      "Counties in state Oklahoma have an average population of 48718.844155844155\n",
      "Counties in state Oregon have an average population of 106418.72222222222\n",
      "Counties in state Pennsylvania have an average population of 189587.74626865672\n",
      "Counties in state Rhode Island have an average population of 210513.4\n",
      "Counties in state South Carolina have an average population of 100551.39130434782\n",
      "Counties in state South Dakota have an average population of 12336.060606060606\n",
      "Counties in state Tennessee have an average population of 66801.1052631579\n",
      "Counties in state Texas have an average population of 98998.27165354331\n",
      "Counties in state Utah have an average population of 95306.37931034483\n",
      "Counties in state Vermont have an average population of 44695.78571428572\n",
      "Counties in state Virginia have an average population of 60111.29323308271\n",
      "Counties in state Washington have an average population of 172424.10256410256\n",
      "Counties in state West Virginia have an average population of 33690.8\n",
      "Counties in state Wisconsin have an average population of 78985.91666666667\n",
      "Counties in state Wyoming have an average population of 24505.478260869564\n",
      "Counties in state Alabama have an average population of 71339.34328358209\n",
      "Counties in state Alaska have an average population of 24490.724137931036\n",
      "Counties in state Arizona have an average population of 426134.4666666667\n",
      "Counties in state Arkansas have an average population of 38878.90666666667\n",
      "Counties in state California have an average population of 642309.5862068966\n",
      "Counties in state Colorado have an average population of 78581.1875\n",
      "Counties in state Connecticut have an average population of 446762.125\n",
      "Counties in state Delaware have an average population of 299311.3333333333\n",
      "Counties in state District of Columbia have an average population of 601723.0\n",
      "Counties in state Florida have an average population of 280616.5671641791\n",
      "Counties in state Georgia have an average population of 60928.63522012578\n",
      "Counties in state Hawaii have an average population of 272060.2\n",
      "Counties in state Idaho have an average population of 35626.86363636364\n",
      "Counties in state Illinois have an average population of 125790.50980392157\n",
      "Counties in state Indiana have an average population of 70476.10869565218\n",
      "Counties in state Iowa have an average population of 30771.262626262625\n",
      "Counties in state Kansas have an average population of 27172.55238095238\n",
      "Counties in state Kentucky have an average population of 36161.39166666667\n",
      "Counties in state Louisiana have an average population of 70833.9375\n",
      "Counties in state Maine have an average population of 83022.5625\n",
      "Counties in state Maryland have an average population of 240564.66666666666\n",
      "Counties in state Massachusetts have an average population of 467687.78571428574\n",
      "Counties in state Michigan have an average population of 119080.0\n",
      "Counties in state Minnesota have an average population of 60964.65517241379\n",
      "Counties in state Mississippi have an average population of 36186.54878048781\n",
      "Counties in state Missouri have an average population of 52077.62608695652\n",
      "Counties in state Montana have an average population of 17668.125\n",
      "Counties in state Nebraska have an average population of 19638.075268817203\n",
      "Counties in state Nevada have an average population of 158855.9411764706\n",
      "Counties in state New Hampshire have an average population of 131647.0\n",
      "Counties in state New Jersey have an average population of 418661.61904761905\n",
      "Counties in state New Mexico have an average population of 62399.36363636364\n",
      "Counties in state New York have an average population of 312550.03225806454\n",
      "Counties in state North Carolina have an average population of 95354.83\n",
      "Counties in state North Dakota have an average population of 12690.396226415094\n",
      "Counties in state Ohio have an average population of 131096.63636363635\n",
      "Counties in state Oklahoma have an average population of 48718.844155844155\n",
      "Counties in state Oregon have an average population of 106418.72222222222\n",
      "Counties in state Pennsylvania have an average population of 189587.74626865672\n",
      "Counties in state Rhode Island have an average population of 210513.4\n",
      "Counties in state South Carolina have an average population of 100551.39130434782\n",
      "Counties in state South Dakota have an average population of 12336.060606060606\n",
      "Counties in state Tennessee have an average population of 66801.1052631579\n",
      "Counties in state Texas have an average population of 98998.27165354331\n",
      "Counties in state Utah have an average population of 95306.37931034483\n",
      "Counties in state Vermont have an average population of 44695.78571428572\n",
      "Counties in state Virginia have an average population of 60111.29323308271\n",
      "Counties in state Washington have an average population of 172424.10256410256\n",
      "Counties in state West Virginia have an average population of 33690.8\n",
      "Counties in state Wisconsin have an average population of 78985.91666666667\n",
      "Counties in state Wyoming have an average population of 24505.478260869564\n",
      "Counties in state Alabama have an average population of 71339.34328358209\n",
      "Counties in state Alaska have an average population of 24490.724137931036\n",
      "Counties in state Arizona have an average population of 426134.4666666667\n",
      "Counties in state Arkansas have an average population of 38878.90666666667\n",
      "Counties in state California have an average population of 642309.5862068966\n",
      "Counties in state Colorado have an average population of 78581.1875\n",
      "Counties in state Connecticut have an average population of 446762.125\n",
      "Counties in state Delaware have an average population of 299311.3333333333\n",
      "Counties in state District of Columbia have an average population of 601723.0\n",
      "Counties in state Florida have an average population of 280616.5671641791\n",
      "Counties in state Georgia have an average population of 60928.63522012578\n",
      "Counties in state Hawaii have an average population of 272060.2\n",
      "Counties in state Idaho have an average population of 35626.86363636364\n",
      "Counties in state Illinois have an average population of 125790.50980392157\n",
      "Counties in state Indiana have an average population of 70476.10869565218\n",
      "Counties in state Iowa have an average population of 30771.262626262625\n",
      "Counties in state Kansas have an average population of 27172.55238095238\n",
      "Counties in state Kentucky have an average population of 36161.39166666667\n",
      "Counties in state Louisiana have an average population of 70833.9375\n",
      "Counties in state Maine have an average population of 83022.5625\n",
      "Counties in state Maryland have an average population of 240564.66666666666\n",
      "Counties in state Massachusetts have an average population of 467687.78571428574\n",
      "Counties in state Michigan have an average population of 119080.0\n",
      "Counties in state Minnesota have an average population of 60964.65517241379\n",
      "Counties in state Mississippi have an average population of 36186.54878048781\n",
      "Counties in state Missouri have an average population of 52077.62608695652\n",
      "Counties in state Montana have an average population of 17668.125\n",
      "Counties in state Nebraska have an average population of 19638.075268817203\n",
      "Counties in state Nevada have an average population of 158855.9411764706\n",
      "Counties in state New Hampshire have an average population of 131647.0\n",
      "Counties in state New Jersey have an average population of 418661.61904761905\n",
      "Counties in state New Mexico have an average population of 62399.36363636364\n",
      "Counties in state New York have an average population of 312550.03225806454\n",
      "Counties in state North Carolina have an average population of 95354.83\n",
      "Counties in state North Dakota have an average population of 12690.396226415094\n",
      "Counties in state Ohio have an average population of 131096.63636363635\n",
      "Counties in state Oklahoma have an average population of 48718.844155844155\n",
      "Counties in state Oregon have an average population of 106418.72222222222\n",
      "Counties in state Pennsylvania have an average population of 189587.74626865672\n",
      "Counties in state Rhode Island have an average population of 210513.4\n",
      "Counties in state South Carolina have an average population of 100551.39130434782\n",
      "Counties in state South Dakota have an average population of 12336.060606060606\n",
      "Counties in state Tennessee have an average population of 66801.1052631579\n",
      "Counties in state Texas have an average population of 98998.27165354331\n",
      "Counties in state Utah have an average population of 95306.37931034483\n",
      "Counties in state Vermont have an average population of 44695.78571428572\n",
      "Counties in state Virginia have an average population of 60111.29323308271\n",
      "Counties in state Washington have an average population of 172424.10256410256\n",
      "Counties in state West Virginia have an average population of 33690.8\n",
      "Counties in state Wisconsin have an average population of 78985.91666666667\n",
      "Counties in state Wyoming have an average population of 24505.478260869564\n",
      "Counties in state Alabama have an average population of 71339.34328358209\n",
      "Counties in state Alaska have an average population of 24490.724137931036\n",
      "Counties in state Arizona have an average population of 426134.4666666667\n",
      "Counties in state Arkansas have an average population of 38878.90666666667\n",
      "Counties in state California have an average population of 642309.5862068966\n",
      "Counties in state Colorado have an average population of 78581.1875\n",
      "Counties in state Connecticut have an average population of 446762.125\n",
      "Counties in state Delaware have an average population of 299311.3333333333\n",
      "Counties in state District of Columbia have an average population of 601723.0\n",
      "Counties in state Florida have an average population of 280616.5671641791\n",
      "Counties in state Georgia have an average population of 60928.63522012578\n",
      "Counties in state Hawaii have an average population of 272060.2\n",
      "Counties in state Idaho have an average population of 35626.86363636364\n",
      "Counties in state Illinois have an average population of 125790.50980392157\n",
      "Counties in state Indiana have an average population of 70476.10869565218\n",
      "Counties in state Iowa have an average population of 30771.262626262625\n",
      "Counties in state Kansas have an average population of 27172.55238095238\n",
      "Counties in state Kentucky have an average population of 36161.39166666667\n",
      "Counties in state Louisiana have an average population of 70833.9375\n",
      "Counties in state Maine have an average population of 83022.5625\n",
      "Counties in state Maryland have an average population of 240564.66666666666\n",
      "Counties in state Massachusetts have an average population of 467687.78571428574\n",
      "Counties in state Michigan have an average population of 119080.0\n",
      "Counties in state Minnesota have an average population of 60964.65517241379\n",
      "Counties in state Mississippi have an average population of 36186.54878048781\n",
      "Counties in state Missouri have an average population of 52077.62608695652\n",
      "Counties in state Montana have an average population of 17668.125\n",
      "Counties in state Nebraska have an average population of 19638.075268817203\n",
      "Counties in state Nevada have an average population of 158855.9411764706\n",
      "Counties in state New Hampshire have an average population of 131647.0\n",
      "Counties in state New Jersey have an average population of 418661.61904761905\n",
      "Counties in state New Mexico have an average population of 62399.36363636364\n",
      "Counties in state New York have an average population of 312550.03225806454\n",
      "Counties in state North Carolina have an average population of 95354.83\n",
      "Counties in state North Dakota have an average population of 12690.396226415094\n",
      "Counties in state Ohio have an average population of 131096.63636363635\n",
      "Counties in state Oklahoma have an average population of 48718.844155844155\n",
      "Counties in state Oregon have an average population of 106418.72222222222\n",
      "Counties in state Pennsylvania have an average population of 189587.74626865672\n",
      "Counties in state Rhode Island have an average population of 210513.4\n",
      "Counties in state South Carolina have an average population of 100551.39130434782\n",
      "Counties in state South Dakota have an average population of 12336.060606060606\n",
      "Counties in state Tennessee have an average population of 66801.1052631579\n",
      "Counties in state Texas have an average population of 98998.27165354331\n",
      "Counties in state Utah have an average population of 95306.37931034483\n",
      "Counties in state Vermont have an average population of 44695.78571428572\n",
      "Counties in state Virginia have an average population of 60111.29323308271\n",
      "Counties in state Washington have an average population of 172424.10256410256\n",
      "Counties in state West Virginia have an average population of 33690.8\n",
      "Counties in state Wisconsin have an average population of 78985.91666666667\n",
      "Counties in state Wyoming have an average population of 24505.478260869564\n",
      "Counties in state Alabama have an average population of 71339.34328358209\n",
      "Counties in state Alaska have an average population of 24490.724137931036\n",
      "Counties in state Arizona have an average population of 426134.4666666667\n",
      "Counties in state Arkansas have an average population of 38878.90666666667\n",
      "Counties in state California have an average population of 642309.5862068966\n",
      "Counties in state Colorado have an average population of 78581.1875\n",
      "Counties in state Connecticut have an average population of 446762.125\n",
      "Counties in state Delaware have an average population of 299311.3333333333\n",
      "Counties in state District of Columbia have an average population of 601723.0\n",
      "Counties in state Florida have an average population of 280616.5671641791\n",
      "Counties in state Georgia have an average population of 60928.63522012578\n",
      "Counties in state Hawaii have an average population of 272060.2\n",
      "Counties in state Idaho have an average population of 35626.86363636364\n",
      "Counties in state Illinois have an average population of 125790.50980392157\n",
      "Counties in state Indiana have an average population of 70476.10869565218\n",
      "Counties in state Iowa have an average population of 30771.262626262625\n",
      "Counties in state Kansas have an average population of 27172.55238095238\n",
      "Counties in state Kentucky have an average population of 36161.39166666667\n",
      "Counties in state Louisiana have an average population of 70833.9375\n",
      "Counties in state Maine have an average population of 83022.5625\n",
      "Counties in state Maryland have an average population of 240564.66666666666\n",
      "Counties in state Massachusetts have an average population of 467687.78571428574\n",
      "Counties in state Michigan have an average population of 119080.0\n",
      "Counties in state Minnesota have an average population of 60964.65517241379\n",
      "Counties in state Mississippi have an average population of 36186.54878048781\n",
      "Counties in state Missouri have an average population of 52077.62608695652\n",
      "Counties in state Montana have an average population of 17668.125\n",
      "Counties in state Nebraska have an average population of 19638.075268817203\n",
      "Counties in state Nevada have an average population of 158855.9411764706\n",
      "Counties in state New Hampshire have an average population of 131647.0\n",
      "Counties in state New Jersey have an average population of 418661.61904761905\n",
      "Counties in state New Mexico have an average population of 62399.36363636364\n",
      "Counties in state New York have an average population of 312550.03225806454\n",
      "Counties in state North Carolina have an average population of 95354.83\n",
      "Counties in state North Dakota have an average population of 12690.396226415094\n",
      "Counties in state Ohio have an average population of 131096.63636363635\n",
      "Counties in state Oklahoma have an average population of 48718.844155844155\n",
      "Counties in state Oregon have an average population of 106418.72222222222\n",
      "Counties in state Pennsylvania have an average population of 189587.74626865672\n",
      "Counties in state Rhode Island have an average population of 210513.4\n",
      "Counties in state South Carolina have an average population of 100551.39130434782\n",
      "Counties in state South Dakota have an average population of 12336.060606060606\n",
      "Counties in state Tennessee have an average population of 66801.1052631579\n",
      "Counties in state Texas have an average population of 98998.27165354331\n",
      "Counties in state Utah have an average population of 95306.37931034483\n",
      "Counties in state Vermont have an average population of 44695.78571428572\n",
      "Counties in state Virginia have an average population of 60111.29323308271\n",
      "Counties in state Washington have an average population of 172424.10256410256\n",
      "Counties in state West Virginia have an average population of 33690.8\n",
      "Counties in state Wisconsin have an average population of 78985.91666666667\n",
      "Counties in state Wyoming have an average population of 24505.478260869564\n",
      "Counties in state Alabama have an average population of 71339.34328358209\n",
      "Counties in state Alaska have an average population of 24490.724137931036\n",
      "Counties in state Arizona have an average population of 426134.4666666667\n",
      "Counties in state Arkansas have an average population of 38878.90666666667\n",
      "Counties in state California have an average population of 642309.5862068966\n",
      "Counties in state Colorado have an average population of 78581.1875\n",
      "Counties in state Connecticut have an average population of 446762.125\n",
      "Counties in state Delaware have an average population of 299311.3333333333\n",
      "Counties in state District of Columbia have an average population of 601723.0\n",
      "Counties in state Florida have an average population of 280616.5671641791\n",
      "Counties in state Georgia have an average population of 60928.63522012578\n",
      "Counties in state Hawaii have an average population of 272060.2\n",
      "Counties in state Idaho have an average population of 35626.86363636364\n",
      "Counties in state Illinois have an average population of 125790.50980392157\n",
      "Counties in state Indiana have an average population of 70476.10869565218\n",
      "Counties in state Iowa have an average population of 30771.262626262625\n",
      "Counties in state Kansas have an average population of 27172.55238095238\n",
      "Counties in state Kentucky have an average population of 36161.39166666667\n",
      "Counties in state Louisiana have an average population of 70833.9375\n",
      "Counties in state Maine have an average population of 83022.5625\n",
      "Counties in state Maryland have an average population of 240564.66666666666\n",
      "Counties in state Massachusetts have an average population of 467687.78571428574\n",
      "Counties in state Michigan have an average population of 119080.0\n",
      "Counties in state Minnesota have an average population of 60964.65517241379\n",
      "Counties in state Mississippi have an average population of 36186.54878048781\n",
      "Counties in state Missouri have an average population of 52077.62608695652\n",
      "Counties in state Montana have an average population of 17668.125\n",
      "Counties in state Nebraska have an average population of 19638.075268817203\n",
      "Counties in state Nevada have an average population of 158855.9411764706\n",
      "Counties in state New Hampshire have an average population of 131647.0\n",
      "Counties in state New Jersey have an average population of 418661.61904761905\n",
      "Counties in state New Mexico have an average population of 62399.36363636364\n",
      "Counties in state New York have an average population of 312550.03225806454\n",
      "Counties in state North Carolina have an average population of 95354.83\n",
      "Counties in state North Dakota have an average population of 12690.396226415094\n",
      "Counties in state Ohio have an average population of 131096.63636363635\n",
      "Counties in state Oklahoma have an average population of 48718.844155844155\n",
      "Counties in state Oregon have an average population of 106418.72222222222\n",
      "Counties in state Pennsylvania have an average population of 189587.74626865672\n",
      "Counties in state Rhode Island have an average population of 210513.4\n",
      "Counties in state South Carolina have an average population of 100551.39130434782\n",
      "Counties in state South Dakota have an average population of 12336.060606060606\n",
      "Counties in state Tennessee have an average population of 66801.1052631579\n",
      "Counties in state Texas have an average population of 98998.27165354331\n",
      "Counties in state Utah have an average population of 95306.37931034483\n",
      "Counties in state Vermont have an average population of 44695.78571428572\n",
      "Counties in state Virginia have an average population of 60111.29323308271\n",
      "Counties in state Washington have an average population of 172424.10256410256\n",
      "Counties in state West Virginia have an average population of 33690.8\n",
      "Counties in state Wisconsin have an average population of 78985.91666666667\n",
      "Counties in state Wyoming have an average population of 24505.478260869564\n",
      "Counties in state Alabama have an average population of 71339.34328358209\n",
      "Counties in state Alaska have an average population of 24490.724137931036\n",
      "Counties in state Arizona have an average population of 426134.4666666667\n",
      "Counties in state Arkansas have an average population of 38878.90666666667\n",
      "Counties in state California have an average population of 642309.5862068966\n",
      "Counties in state Colorado have an average population of 78581.1875\n",
      "Counties in state Connecticut have an average population of 446762.125\n",
      "Counties in state Delaware have an average population of 299311.3333333333\n",
      "Counties in state District of Columbia have an average population of 601723.0\n",
      "Counties in state Florida have an average population of 280616.5671641791\n",
      "Counties in state Georgia have an average population of 60928.63522012578\n",
      "Counties in state Hawaii have an average population of 272060.2\n",
      "Counties in state Idaho have an average population of 35626.86363636364\n",
      "Counties in state Illinois have an average population of 125790.50980392157\n",
      "Counties in state Indiana have an average population of 70476.10869565218\n",
      "Counties in state Iowa have an average population of 30771.262626262625\n",
      "Counties in state Kansas have an average population of 27172.55238095238\n",
      "Counties in state Kentucky have an average population of 36161.39166666667\n",
      "Counties in state Louisiana have an average population of 70833.9375\n",
      "Counties in state Maine have an average population of 83022.5625\n",
      "Counties in state Maryland have an average population of 240564.66666666666\n",
      "Counties in state Massachusetts have an average population of 467687.78571428574\n",
      "Counties in state Michigan have an average population of 119080.0\n",
      "Counties in state Minnesota have an average population of 60964.65517241379\n",
      "Counties in state Mississippi have an average population of 36186.54878048781\n",
      "Counties in state Missouri have an average population of 52077.62608695652\n",
      "Counties in state Montana have an average population of 17668.125\n",
      "Counties in state Nebraska have an average population of 19638.075268817203\n",
      "Counties in state Nevada have an average population of 158855.9411764706\n",
      "Counties in state New Hampshire have an average population of 131647.0\n",
      "Counties in state New Jersey have an average population of 418661.61904761905\n",
      "Counties in state New Mexico have an average population of 62399.36363636364\n",
      "Counties in state New York have an average population of 312550.03225806454\n",
      "Counties in state North Carolina have an average population of 95354.83\n",
      "Counties in state North Dakota have an average population of 12690.396226415094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counties in state Ohio have an average population of 131096.63636363635\n",
      "Counties in state Oklahoma have an average population of 48718.844155844155\n",
      "Counties in state Oregon have an average population of 106418.72222222222\n",
      "Counties in state Pennsylvania have an average population of 189587.74626865672\n",
      "Counties in state Rhode Island have an average population of 210513.4\n",
      "Counties in state South Carolina have an average population of 100551.39130434782\n",
      "Counties in state South Dakota have an average population of 12336.060606060606\n",
      "Counties in state Tennessee have an average population of 66801.1052631579\n",
      "Counties in state Texas have an average population of 98998.27165354331\n",
      "Counties in state Utah have an average population of 95306.37931034483\n",
      "Counties in state Vermont have an average population of 44695.78571428572\n",
      "Counties in state Virginia have an average population of 60111.29323308271\n",
      "Counties in state Washington have an average population of 172424.10256410256\n",
      "Counties in state West Virginia have an average population of 33690.8\n",
      "Counties in state Wisconsin have an average population of 78985.91666666667\n",
      "Counties in state Wyoming have an average population of 24505.478260869564\n",
      "Counties in state Alabama have an average population of 71339.34328358209\n",
      "Counties in state Alaska have an average population of 24490.724137931036\n",
      "Counties in state Arizona have an average population of 426134.4666666667\n",
      "Counties in state Arkansas have an average population of 38878.90666666667\n",
      "Counties in state California have an average population of 642309.5862068966\n",
      "Counties in state Colorado have an average population of 78581.1875\n",
      "Counties in state Connecticut have an average population of 446762.125\n",
      "Counties in state Delaware have an average population of 299311.3333333333\n",
      "Counties in state District of Columbia have an average population of 601723.0\n",
      "Counties in state Florida have an average population of 280616.5671641791\n",
      "Counties in state Georgia have an average population of 60928.63522012578\n",
      "Counties in state Hawaii have an average population of 272060.2\n",
      "Counties in state Idaho have an average population of 35626.86363636364\n",
      "Counties in state Illinois have an average population of 125790.50980392157\n",
      "Counties in state Indiana have an average population of 70476.10869565218\n",
      "Counties in state Iowa have an average population of 30771.262626262625\n",
      "Counties in state Kansas have an average population of 27172.55238095238\n",
      "Counties in state Kentucky have an average population of 36161.39166666667\n",
      "Counties in state Louisiana have an average population of 70833.9375\n",
      "Counties in state Maine have an average population of 83022.5625\n",
      "Counties in state Maryland have an average population of 240564.66666666666\n",
      "Counties in state Massachusetts have an average population of 467687.78571428574\n",
      "Counties in state Michigan have an average population of 119080.0\n",
      "Counties in state Minnesota have an average population of 60964.65517241379\n",
      "Counties in state Mississippi have an average population of 36186.54878048781\n",
      "Counties in state Missouri have an average population of 52077.62608695652\n",
      "Counties in state Montana have an average population of 17668.125\n",
      "Counties in state Nebraska have an average population of 19638.075268817203\n",
      "Counties in state Nevada have an average population of 158855.9411764706\n",
      "Counties in state New Hampshire have an average population of 131647.0\n",
      "Counties in state New Jersey have an average population of 418661.61904761905\n",
      "Counties in state New Mexico have an average population of 62399.36363636364\n",
      "Counties in state New York have an average population of 312550.03225806454\n",
      "Counties in state North Carolina have an average population of 95354.83\n",
      "Counties in state North Dakota have an average population of 12690.396226415094\n",
      "Counties in state Ohio have an average population of 131096.63636363635\n",
      "Counties in state Oklahoma have an average population of 48718.844155844155\n",
      "Counties in state Oregon have an average population of 106418.72222222222\n",
      "Counties in state Pennsylvania have an average population of 189587.74626865672\n",
      "Counties in state Rhode Island have an average population of 210513.4\n",
      "Counties in state South Carolina have an average population of 100551.39130434782\n",
      "Counties in state South Dakota have an average population of 12336.060606060606\n",
      "Counties in state Tennessee have an average population of 66801.1052631579\n",
      "Counties in state Texas have an average population of 98998.27165354331\n",
      "Counties in state Utah have an average population of 95306.37931034483\n",
      "Counties in state Vermont have an average population of 44695.78571428572\n",
      "Counties in state Virginia have an average population of 60111.29323308271\n",
      "Counties in state Washington have an average population of 172424.10256410256\n",
      "Counties in state West Virginia have an average population of 33690.8\n",
      "Counties in state Wisconsin have an average population of 78985.91666666667\n",
      "Counties in state Wyoming have an average population of 24505.478260869564\n",
      "Counties in state Alabama have an average population of 71339.34328358209\n",
      "Counties in state Alaska have an average population of 24490.724137931036\n",
      "Counties in state Arizona have an average population of 426134.4666666667\n",
      "Counties in state Arkansas have an average population of 38878.90666666667\n",
      "Counties in state California have an average population of 642309.5862068966\n",
      "Counties in state Colorado have an average population of 78581.1875\n",
      "Counties in state Connecticut have an average population of 446762.125\n",
      "Counties in state Delaware have an average population of 299311.3333333333\n",
      "Counties in state District of Columbia have an average population of 601723.0\n",
      "Counties in state Florida have an average population of 280616.5671641791\n",
      "Counties in state Georgia have an average population of 60928.63522012578\n",
      "Counties in state Hawaii have an average population of 272060.2\n",
      "Counties in state Idaho have an average population of 35626.86363636364\n",
      "Counties in state Illinois have an average population of 125790.50980392157\n",
      "Counties in state Indiana have an average population of 70476.10869565218\n",
      "Counties in state Iowa have an average population of 30771.262626262625\n",
      "Counties in state Kansas have an average population of 27172.55238095238\n",
      "Counties in state Kentucky have an average population of 36161.39166666667\n",
      "Counties in state Louisiana have an average population of 70833.9375\n",
      "Counties in state Maine have an average population of 83022.5625\n",
      "Counties in state Maryland have an average population of 240564.66666666666\n",
      "Counties in state Massachusetts have an average population of 467687.78571428574\n",
      "Counties in state Michigan have an average population of 119080.0\n",
      "Counties in state Minnesota have an average population of 60964.65517241379\n",
      "Counties in state Mississippi have an average population of 36186.54878048781\n",
      "Counties in state Missouri have an average population of 52077.62608695652\n",
      "Counties in state Montana have an average population of 17668.125\n",
      "Counties in state Nebraska have an average population of 19638.075268817203\n",
      "Counties in state Nevada have an average population of 158855.9411764706\n",
      "Counties in state New Hampshire have an average population of 131647.0\n",
      "Counties in state New Jersey have an average population of 418661.61904761905\n",
      "Counties in state New Mexico have an average population of 62399.36363636364\n",
      "Counties in state New York have an average population of 312550.03225806454\n",
      "Counties in state North Carolina have an average population of 95354.83\n",
      "Counties in state North Dakota have an average population of 12690.396226415094\n",
      "Counties in state Ohio have an average population of 131096.63636363635\n",
      "Counties in state Oklahoma have an average population of 48718.844155844155\n",
      "Counties in state Oregon have an average population of 106418.72222222222\n",
      "Counties in state Pennsylvania have an average population of 189587.74626865672\n",
      "Counties in state Rhode Island have an average population of 210513.4\n",
      "Counties in state South Carolina have an average population of 100551.39130434782\n",
      "Counties in state South Dakota have an average population of 12336.060606060606\n",
      "Counties in state Tennessee have an average population of 66801.1052631579\n",
      "Counties in state Texas have an average population of 98998.27165354331\n",
      "Counties in state Utah have an average population of 95306.37931034483\n",
      "Counties in state Vermont have an average population of 44695.78571428572\n",
      "Counties in state Virginia have an average population of 60111.29323308271\n",
      "Counties in state Washington have an average population of 172424.10256410256\n",
      "Counties in state West Virginia have an average population of 33690.8\n",
      "Counties in state Wisconsin have an average population of 78985.91666666667\n",
      "Counties in state Wyoming have an average population of 24505.478260869564\n",
      "Counties in state Alabama have an average population of 71339.34328358209\n",
      "Counties in state Alaska have an average population of 24490.724137931036\n",
      "Counties in state Arizona have an average population of 426134.4666666667\n",
      "Counties in state Arkansas have an average population of 38878.90666666667\n",
      "Counties in state California have an average population of 642309.5862068966\n",
      "Counties in state Colorado have an average population of 78581.1875\n",
      "Counties in state Connecticut have an average population of 446762.125\n",
      "Counties in state Delaware have an average population of 299311.3333333333\n",
      "Counties in state District of Columbia have an average population of 601723.0\n",
      "Counties in state Florida have an average population of 280616.5671641791\n",
      "Counties in state Georgia have an average population of 60928.63522012578\n",
      "Counties in state Hawaii have an average population of 272060.2\n",
      "Counties in state Idaho have an average population of 35626.86363636364\n",
      "Counties in state Illinois have an average population of 125790.50980392157\n",
      "Counties in state Indiana have an average population of 70476.10869565218\n",
      "Counties in state Iowa have an average population of 30771.262626262625\n",
      "Counties in state Kansas have an average population of 27172.55238095238\n",
      "Counties in state Kentucky have an average population of 36161.39166666667\n",
      "Counties in state Louisiana have an average population of 70833.9375\n",
      "Counties in state Maine have an average population of 83022.5625\n",
      "Counties in state Maryland have an average population of 240564.66666666666\n",
      "Counties in state Massachusetts have an average population of 467687.78571428574\n",
      "Counties in state Michigan have an average population of 119080.0\n",
      "Counties in state Minnesota have an average population of 60964.65517241379\n",
      "Counties in state Mississippi have an average population of 36186.54878048781\n",
      "Counties in state Missouri have an average population of 52077.62608695652\n",
      "Counties in state Montana have an average population of 17668.125\n",
      "Counties in state Nebraska have an average population of 19638.075268817203\n",
      "Counties in state Nevada have an average population of 158855.9411764706\n",
      "Counties in state New Hampshire have an average population of 131647.0\n",
      "Counties in state New Jersey have an average population of 418661.61904761905\n",
      "Counties in state New Mexico have an average population of 62399.36363636364\n",
      "Counties in state New York have an average population of 312550.03225806454\n",
      "Counties in state North Carolina have an average population of 95354.83\n",
      "Counties in state North Dakota have an average population of 12690.396226415094\n",
      "Counties in state Ohio have an average population of 131096.63636363635\n",
      "Counties in state Oklahoma have an average population of 48718.844155844155\n",
      "Counties in state Oregon have an average population of 106418.72222222222\n",
      "Counties in state Pennsylvania have an average population of 189587.74626865672\n",
      "Counties in state Rhode Island have an average population of 210513.4\n",
      "Counties in state South Carolina have an average population of 100551.39130434782\n",
      "Counties in state South Dakota have an average population of 12336.060606060606\n",
      "Counties in state Tennessee have an average population of 66801.1052631579\n",
      "Counties in state Texas have an average population of 98998.27165354331\n",
      "Counties in state Utah have an average population of 95306.37931034483\n",
      "Counties in state Vermont have an average population of 44695.78571428572\n",
      "Counties in state Virginia have an average population of 60111.29323308271\n",
      "Counties in state Washington have an average population of 172424.10256410256\n",
      "Counties in state West Virginia have an average population of 33690.8\n",
      "Counties in state Wisconsin have an average population of 78985.91666666667\n",
      "Counties in state Wyoming have an average population of 24505.478260869564\n",
      "Counties in state Alabama have an average population of 71339.34328358209\n",
      "Counties in state Alaska have an average population of 24490.724137931036\n",
      "Counties in state Arizona have an average population of 426134.4666666667\n",
      "Counties in state Arkansas have an average population of 38878.90666666667\n",
      "Counties in state California have an average population of 642309.5862068966\n",
      "Counties in state Colorado have an average population of 78581.1875\n",
      "Counties in state Connecticut have an average population of 446762.125\n",
      "Counties in state Delaware have an average population of 299311.3333333333\n",
      "Counties in state District of Columbia have an average population of 601723.0\n",
      "Counties in state Florida have an average population of 280616.5671641791\n",
      "Counties in state Georgia have an average population of 60928.63522012578\n",
      "Counties in state Hawaii have an average population of 272060.2\n",
      "Counties in state Idaho have an average population of 35626.86363636364\n",
      "Counties in state Illinois have an average population of 125790.50980392157\n",
      "Counties in state Indiana have an average population of 70476.10869565218\n",
      "Counties in state Iowa have an average population of 30771.262626262625\n",
      "Counties in state Kansas have an average population of 27172.55238095238\n",
      "Counties in state Kentucky have an average population of 36161.39166666667\n",
      "Counties in state Louisiana have an average population of 70833.9375\n",
      "Counties in state Maine have an average population of 83022.5625\n",
      "Counties in state Maryland have an average population of 240564.66666666666\n",
      "Counties in state Massachusetts have an average population of 467687.78571428574\n",
      "Counties in state Michigan have an average population of 119080.0\n",
      "Counties in state Minnesota have an average population of 60964.65517241379\n",
      "Counties in state Mississippi have an average population of 36186.54878048781\n",
      "Counties in state Missouri have an average population of 52077.62608695652\n",
      "Counties in state Montana have an average population of 17668.125\n",
      "Counties in state Nebraska have an average population of 19638.075268817203\n",
      "Counties in state Nevada have an average population of 158855.9411764706\n",
      "Counties in state New Hampshire have an average population of 131647.0\n",
      "Counties in state New Jersey have an average population of 418661.61904761905\n",
      "Counties in state New Mexico have an average population of 62399.36363636364\n",
      "Counties in state New York have an average population of 312550.03225806454\n",
      "Counties in state North Carolina have an average population of 95354.83\n",
      "Counties in state North Dakota have an average population of 12690.396226415094\n",
      "Counties in state Ohio have an average population of 131096.63636363635\n",
      "Counties in state Oklahoma have an average population of 48718.844155844155\n",
      "Counties in state Oregon have an average population of 106418.72222222222\n",
      "Counties in state Pennsylvania have an average population of 189587.74626865672\n",
      "Counties in state Rhode Island have an average population of 210513.4\n",
      "Counties in state South Carolina have an average population of 100551.39130434782\n",
      "Counties in state South Dakota have an average population of 12336.060606060606\n",
      "Counties in state Tennessee have an average population of 66801.1052631579\n",
      "Counties in state Texas have an average population of 98998.27165354331\n",
      "Counties in state Utah have an average population of 95306.37931034483\n",
      "Counties in state Vermont have an average population of 44695.78571428572\n",
      "Counties in state Virginia have an average population of 60111.29323308271\n",
      "Counties in state Washington have an average population of 172424.10256410256\n",
      "Counties in state West Virginia have an average population of 33690.8\n",
      "Counties in state Wisconsin have an average population of 78985.91666666667\n",
      "Counties in state Wyoming have an average population of 24505.478260869564\n",
      "Counties in state Alabama have an average population of 71339.34328358209\n",
      "Counties in state Alaska have an average population of 24490.724137931036\n",
      "Counties in state Arizona have an average population of 426134.4666666667\n",
      "Counties in state Arkansas have an average population of 38878.90666666667\n",
      "Counties in state California have an average population of 642309.5862068966\n",
      "Counties in state Colorado have an average population of 78581.1875\n",
      "Counties in state Connecticut have an average population of 446762.125\n",
      "Counties in state Delaware have an average population of 299311.3333333333\n",
      "Counties in state District of Columbia have an average population of 601723.0\n",
      "Counties in state Florida have an average population of 280616.5671641791\n",
      "Counties in state Georgia have an average population of 60928.63522012578\n",
      "Counties in state Hawaii have an average population of 272060.2\n",
      "Counties in state Idaho have an average population of 35626.86363636364\n",
      "Counties in state Illinois have an average population of 125790.50980392157\n",
      "Counties in state Indiana have an average population of 70476.10869565218\n",
      "Counties in state Iowa have an average population of 30771.262626262625\n",
      "Counties in state Kansas have an average population of 27172.55238095238\n",
      "Counties in state Kentucky have an average population of 36161.39166666667\n",
      "Counties in state Louisiana have an average population of 70833.9375\n",
      "Counties in state Maine have an average population of 83022.5625\n",
      "Counties in state Maryland have an average population of 240564.66666666666\n",
      "Counties in state Massachusetts have an average population of 467687.78571428574\n",
      "Counties in state Michigan have an average population of 119080.0\n",
      "Counties in state Minnesota have an average population of 60964.65517241379\n",
      "Counties in state Mississippi have an average population of 36186.54878048781\n",
      "Counties in state Missouri have an average population of 52077.62608695652\n",
      "Counties in state Montana have an average population of 17668.125\n",
      "Counties in state Nebraska have an average population of 19638.075268817203\n",
      "Counties in state Nevada have an average population of 158855.9411764706\n",
      "Counties in state New Hampshire have an average population of 131647.0\n",
      "Counties in state New Jersey have an average population of 418661.61904761905\n",
      "Counties in state New Mexico have an average population of 62399.36363636364\n",
      "Counties in state New York have an average population of 312550.03225806454\n",
      "Counties in state North Carolina have an average population of 95354.83\n",
      "Counties in state North Dakota have an average population of 12690.396226415094\n",
      "Counties in state Ohio have an average population of 131096.63636363635\n",
      "Counties in state Oklahoma have an average population of 48718.844155844155\n",
      "Counties in state Oregon have an average population of 106418.72222222222\n",
      "Counties in state Pennsylvania have an average population of 189587.74626865672\n",
      "Counties in state Rhode Island have an average population of 210513.4\n",
      "Counties in state South Carolina have an average population of 100551.39130434782\n",
      "Counties in state South Dakota have an average population of 12336.060606060606\n",
      "Counties in state Tennessee have an average population of 66801.1052631579\n",
      "Counties in state Texas have an average population of 98998.27165354331\n",
      "Counties in state Utah have an average population of 95306.37931034483\n",
      "Counties in state Vermont have an average population of 44695.78571428572\n",
      "Counties in state Virginia have an average population of 60111.29323308271\n",
      "Counties in state Washington have an average population of 172424.10256410256\n",
      "Counties in state West Virginia have an average population of 33690.8\n",
      "Counties in state Wisconsin have an average population of 78985.91666666667\n",
      "Counties in state Wyoming have an average population of 24505.478260869564\n",
      "Counties in state Alabama have an average population of 71339.34328358209\n",
      "Counties in state Alaska have an average population of 24490.724137931036\n",
      "Counties in state Arizona have an average population of 426134.4666666667\n",
      "Counties in state Arkansas have an average population of 38878.90666666667\n",
      "Counties in state California have an average population of 642309.5862068966\n",
      "Counties in state Colorado have an average population of 78581.1875\n",
      "Counties in state Connecticut have an average population of 446762.125\n",
      "Counties in state Delaware have an average population of 299311.3333333333\n",
      "Counties in state District of Columbia have an average population of 601723.0\n",
      "Counties in state Florida have an average population of 280616.5671641791\n",
      "Counties in state Georgia have an average population of 60928.63522012578\n",
      "Counties in state Hawaii have an average population of 272060.2\n",
      "Counties in state Idaho have an average population of 35626.86363636364\n",
      "Counties in state Illinois have an average population of 125790.50980392157\n",
      "Counties in state Indiana have an average population of 70476.10869565218\n",
      "Counties in state Iowa have an average population of 30771.262626262625\n",
      "Counties in state Kansas have an average population of 27172.55238095238\n",
      "Counties in state Kentucky have an average population of 36161.39166666667\n",
      "Counties in state Louisiana have an average population of 70833.9375\n",
      "Counties in state Maine have an average population of 83022.5625\n",
      "Counties in state Maryland have an average population of 240564.66666666666\n",
      "Counties in state Massachusetts have an average population of 467687.78571428574\n",
      "Counties in state Michigan have an average population of 119080.0\n",
      "Counties in state Minnesota have an average population of 60964.65517241379\n",
      "Counties in state Mississippi have an average population of 36186.54878048781\n",
      "Counties in state Missouri have an average population of 52077.62608695652\n",
      "Counties in state Montana have an average population of 17668.125\n",
      "Counties in state Nebraska have an average population of 19638.075268817203\n",
      "Counties in state Nevada have an average population of 158855.9411764706\n",
      "Counties in state New Hampshire have an average population of 131647.0\n",
      "Counties in state New Jersey have an average population of 418661.61904761905\n",
      "Counties in state New Mexico have an average population of 62399.36363636364\n",
      "Counties in state New York have an average population of 312550.03225806454\n",
      "Counties in state North Carolina have an average population of 95354.83\n",
      "Counties in state North Dakota have an average population of 12690.396226415094\n",
      "Counties in state Ohio have an average population of 131096.63636363635\n",
      "Counties in state Oklahoma have an average population of 48718.844155844155\n",
      "Counties in state Oregon have an average population of 106418.72222222222\n",
      "Counties in state Pennsylvania have an average population of 189587.74626865672\n",
      "Counties in state Rhode Island have an average population of 210513.4\n",
      "Counties in state South Carolina have an average population of 100551.39130434782\n",
      "Counties in state South Dakota have an average population of 12336.060606060606\n",
      "Counties in state Tennessee have an average population of 66801.1052631579\n",
      "Counties in state Texas have an average population of 98998.27165354331\n",
      "Counties in state Utah have an average population of 95306.37931034483\n",
      "Counties in state Vermont have an average population of 44695.78571428572\n",
      "Counties in state Virginia have an average population of 60111.29323308271\n",
      "Counties in state Washington have an average population of 172424.10256410256\n",
      "Counties in state West Virginia have an average population of 33690.8\n",
      "Counties in state Wisconsin have an average population of 78985.91666666667\n",
      "Counties in state Wyoming have an average population of 24505.478260869564\n",
      "14.2 ms ± 1.09 ms per loop (mean ± std. dev. of 7 runs, 3 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 3\n",
    "# For this method, we start by telling pandas we're interested in grouping by state name, this is the \"split\"\n",
    "for group, frame in df.groupby('STNAME'):\n",
    "    # You'll notice there are two values we set here. groupby() returns a tuple, where the first value is the\n",
    "    # value of the key we were trying to group by, in this case a specific state name, and the second one is\n",
    "    # projected dataframe that was found for that group\n",
    "    \n",
    "    # Now we include our logic in the \"apply\" step, which is to calculate an average of the census2010pop\n",
    "    avg = np.average(frame['CENSUS2010POP'])\n",
    "    # And print the results\n",
    "    print('Counties in state ' + group + \n",
    "          ' have an average population of ' + str(avg))\n",
    "# And we don't have to worry about the combine step in this case, because all of our data transformation is\n",
    "# actually printing out results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>listing_url</th>\n",
       "      <th>scrape_id</th>\n",
       "      <th>last_scraped</th>\n",
       "      <th>name</th>\n",
       "      <th>summary</th>\n",
       "      <th>space</th>\n",
       "      <th>description</th>\n",
       "      <th>experiences_offered</th>\n",
       "      <th>neighborhood_overview</th>\n",
       "      <th>...</th>\n",
       "      <th>review_scores_value</th>\n",
       "      <th>requires_license</th>\n",
       "      <th>license</th>\n",
       "      <th>jurisdiction_names</th>\n",
       "      <th>instant_bookable</th>\n",
       "      <th>cancellation_policy</th>\n",
       "      <th>require_guest_profile_picture</th>\n",
       "      <th>require_guest_phone_verification</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>reviews_per_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12147973</td>\n",
       "      <td>https://www.airbnb.com/rooms/12147973</td>\n",
       "      <td>20160906204935</td>\n",
       "      <td>2016-09-07</td>\n",
       "      <td>Sunny Bungalow in the City</td>\n",
       "      <td>Cozy, sunny, family home.  Master bedroom high...</td>\n",
       "      <td>The house has an open and cozy feel at the sam...</td>\n",
       "      <td>Cozy, sunny, family home.  Master bedroom high...</td>\n",
       "      <td>none</td>\n",
       "      <td>Roslindale is quiet, convenient and friendly. ...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>moderate</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3075044</td>\n",
       "      <td>https://www.airbnb.com/rooms/3075044</td>\n",
       "      <td>20160906204935</td>\n",
       "      <td>2016-09-07</td>\n",
       "      <td>Charming room in pet friendly apt</td>\n",
       "      <td>Charming and quiet room in a second floor 1910...</td>\n",
       "      <td>Small but cozy and quite room with a full size...</td>\n",
       "      <td>Charming and quiet room in a second floor 1910...</td>\n",
       "      <td>none</td>\n",
       "      <td>The room is in Roslindale, a diverse and prima...</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>moderate</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>1.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6976</td>\n",
       "      <td>https://www.airbnb.com/rooms/6976</td>\n",
       "      <td>20160906204935</td>\n",
       "      <td>2016-09-07</td>\n",
       "      <td>Mexican Folk Art Haven in Boston</td>\n",
       "      <td>Come stay with a friendly, middle-aged guy in ...</td>\n",
       "      <td>Come stay with a friendly, middle-aged guy in ...</td>\n",
       "      <td>Come stay with a friendly, middle-aged guy in ...</td>\n",
       "      <td>none</td>\n",
       "      <td>The LOCATION: Roslindale is a safe and diverse...</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>moderate</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1436513</td>\n",
       "      <td>https://www.airbnb.com/rooms/1436513</td>\n",
       "      <td>20160906204935</td>\n",
       "      <td>2016-09-07</td>\n",
       "      <td>Spacious Sunny Bedroom Suite in Historic Home</td>\n",
       "      <td>Come experience the comforts of home away from...</td>\n",
       "      <td>Most places you find in Boston are small howev...</td>\n",
       "      <td>Come experience the comforts of home away from...</td>\n",
       "      <td>none</td>\n",
       "      <td>Roslindale is a lovely little neighborhood loc...</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>moderate</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7651065</td>\n",
       "      <td>https://www.airbnb.com/rooms/7651065</td>\n",
       "      <td>20160906204935</td>\n",
       "      <td>2016-09-07</td>\n",
       "      <td>Come Home to Boston</td>\n",
       "      <td>My comfy, clean and relaxing home is one block...</td>\n",
       "      <td>Clean, attractive, private room, one block fro...</td>\n",
       "      <td>My comfy, clean and relaxing home is one block...</td>\n",
       "      <td>none</td>\n",
       "      <td>I love the proximity to downtown, the neighbor...</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>flexible</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>2.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                            listing_url       scrape_id  \\\n",
       "0  12147973  https://www.airbnb.com/rooms/12147973  20160906204935   \n",
       "1   3075044   https://www.airbnb.com/rooms/3075044  20160906204935   \n",
       "2      6976      https://www.airbnb.com/rooms/6976  20160906204935   \n",
       "3   1436513   https://www.airbnb.com/rooms/1436513  20160906204935   \n",
       "4   7651065   https://www.airbnb.com/rooms/7651065  20160906204935   \n",
       "\n",
       "  last_scraped                                           name  \\\n",
       "0   2016-09-07                     Sunny Bungalow in the City   \n",
       "1   2016-09-07              Charming room in pet friendly apt   \n",
       "2   2016-09-07               Mexican Folk Art Haven in Boston   \n",
       "3   2016-09-07  Spacious Sunny Bedroom Suite in Historic Home   \n",
       "4   2016-09-07                            Come Home to Boston   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Cozy, sunny, family home.  Master bedroom high...   \n",
       "1  Charming and quiet room in a second floor 1910...   \n",
       "2  Come stay with a friendly, middle-aged guy in ...   \n",
       "3  Come experience the comforts of home away from...   \n",
       "4  My comfy, clean and relaxing home is one block...   \n",
       "\n",
       "                                               space  \\\n",
       "0  The house has an open and cozy feel at the sam...   \n",
       "1  Small but cozy and quite room with a full size...   \n",
       "2  Come stay with a friendly, middle-aged guy in ...   \n",
       "3  Most places you find in Boston are small howev...   \n",
       "4  Clean, attractive, private room, one block fro...   \n",
       "\n",
       "                                         description experiences_offered  \\\n",
       "0  Cozy, sunny, family home.  Master bedroom high...                none   \n",
       "1  Charming and quiet room in a second floor 1910...                none   \n",
       "2  Come stay with a friendly, middle-aged guy in ...                none   \n",
       "3  Come experience the comforts of home away from...                none   \n",
       "4  My comfy, clean and relaxing home is one block...                none   \n",
       "\n",
       "                               neighborhood_overview  ... review_scores_value  \\\n",
       "0  Roslindale is quiet, convenient and friendly. ...  ...                 NaN   \n",
       "1  The room is in Roslindale, a diverse and prima...  ...                 9.0   \n",
       "2  The LOCATION: Roslindale is a safe and diverse...  ...                10.0   \n",
       "3  Roslindale is a lovely little neighborhood loc...  ...                10.0   \n",
       "4  I love the proximity to downtown, the neighbor...  ...                10.0   \n",
       "\n",
       "  requires_license license jurisdiction_names instant_bookable  \\\n",
       "0                f     NaN                NaN                f   \n",
       "1                f     NaN                NaN                t   \n",
       "2                f     NaN                NaN                f   \n",
       "3                f     NaN                NaN                f   \n",
       "4                f     NaN                NaN                f   \n",
       "\n",
       "  cancellation_policy require_guest_profile_picture  \\\n",
       "0            moderate                             f   \n",
       "1            moderate                             f   \n",
       "2            moderate                             t   \n",
       "3            moderate                             f   \n",
       "4            flexible                             f   \n",
       "\n",
       "  require_guest_phone_verification calculated_host_listings_count  \\\n",
       "0                                f                              1   \n",
       "1                                f                              1   \n",
       "2                                f                              1   \n",
       "3                                f                              1   \n",
       "4                                f                              1   \n",
       "\n",
       "   reviews_per_month  \n",
       "0                NaN  \n",
       "1               1.30  \n",
       "2               0.47  \n",
       "3               1.00  \n",
       "4               2.25  \n",
       "\n",
       "[5 rows x 95 columns]"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's take one more look at an example of how we might group data. In this example, I want to use a dataset\n",
    "# of housing from airbnb. In this dataset there are two columns of interest, one is the cancellation_policy\n",
    "# and the other is the review_scores_value.\n",
    "df=pd.read_csv(\"datasets/listings.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('flexible', 2.0)\n",
      "('flexible', 4.0)\n",
      "('flexible', 5.0)\n",
      "('flexible', 6.0)\n",
      "('flexible', 7.0)\n",
      "('flexible', 8.0)\n",
      "('flexible', 9.0)\n",
      "('flexible', 10.0)\n",
      "('moderate', 2.0)\n",
      "('moderate', 4.0)\n",
      "('moderate', 6.0)\n",
      "('moderate', 7.0)\n",
      "('moderate', 8.0)\n",
      "('moderate', 9.0)\n",
      "('moderate', 10.0)\n",
      "('strict', 2.0)\n",
      "('strict', 3.0)\n",
      "('strict', 4.0)\n",
      "('strict', 5.0)\n",
      "('strict', 6.0)\n",
      "('strict', 7.0)\n",
      "('strict', 8.0)\n",
      "('strict', 9.0)\n",
      "('strict', 10.0)\n",
      "('super_strict_30', 6.0)\n",
      "('super_strict_30', 7.0)\n",
      "('super_strict_30', 8.0)\n",
      "('super_strict_30', 9.0)\n",
      "('super_strict_30', 10.0)\n"
     ]
    }
   ],
   "source": [
    "# So, how would I group by both of these columns? A first approach might be to promote them to a multiindex\n",
    "# and just call groupby()\n",
    "df=df.set_index([\"cancellation_policy\",\"review_scores_value\"])\n",
    "\n",
    "# When we have a multiindex we need to pass in the levels we are interested in grouping by\n",
    "for group, frame in df.groupby(level=(0,1)):\n",
    "    print(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('flexible', '10.0')\n",
      "('flexible', 'not 10.0')\n",
      "('moderate', '10.0')\n",
      "('moderate', 'not 10.0')\n",
      "('strict', '10.0')\n",
      "('strict', 'not 10.0')\n",
      "('super_strict_30', '10.0')\n",
      "('super_strict_30', 'not 10.0')\n"
     ]
    }
   ],
   "source": [
    "# This seems to work ok. But what if we wanted to group by the cancelation policy and review scores, but\n",
    "# separate out all the 10's from those under ten? In this case, we could use a function to manage the\n",
    "# groupings\n",
    "\n",
    "def grouping_fun(item):\n",
    "    # Check the \"review_scores_value\" portion of the index. item is in the format of\n",
    "    # (cancellation_policy,review_scores_value\n",
    "    if item[1] == 10.0:\n",
    "        return (item[0],\"10.0\")\n",
    "    else:\n",
    "        return (item[0],\"not 10.0\")\n",
    "\n",
    "for group, frame in df.groupby(by=grouping_fun):\n",
    "    print(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>listing_url</th>\n",
       "      <th>scrape_id</th>\n",
       "      <th>last_scraped</th>\n",
       "      <th>name</th>\n",
       "      <th>summary</th>\n",
       "      <th>space</th>\n",
       "      <th>description</th>\n",
       "      <th>experiences_offered</th>\n",
       "      <th>neighborhood_overview</th>\n",
       "      <th>...</th>\n",
       "      <th>review_scores_communication</th>\n",
       "      <th>review_scores_location</th>\n",
       "      <th>requires_license</th>\n",
       "      <th>license</th>\n",
       "      <th>jurisdiction_names</th>\n",
       "      <th>instant_bookable</th>\n",
       "      <th>require_guest_profile_picture</th>\n",
       "      <th>require_guest_phone_verification</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>reviews_per_month</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cancellation_policy</th>\n",
       "      <th>review_scores_value</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">moderate</th>\n",
       "      <th>NaN</th>\n",
       "      <td>12147973</td>\n",
       "      <td>https://www.airbnb.com/rooms/12147973</td>\n",
       "      <td>20160906204935</td>\n",
       "      <td>2016-09-07</td>\n",
       "      <td>Sunny Bungalow in the City</td>\n",
       "      <td>Cozy, sunny, family home.  Master bedroom high...</td>\n",
       "      <td>The house has an open and cozy feel at the sam...</td>\n",
       "      <td>Cozy, sunny, family home.  Master bedroom high...</td>\n",
       "      <td>none</td>\n",
       "      <td>Roslindale is quiet, convenient and friendly. ...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.0</th>\n",
       "      <td>3075044</td>\n",
       "      <td>https://www.airbnb.com/rooms/3075044</td>\n",
       "      <td>20160906204935</td>\n",
       "      <td>2016-09-07</td>\n",
       "      <td>Charming room in pet friendly apt</td>\n",
       "      <td>Charming and quiet room in a second floor 1910...</td>\n",
       "      <td>Small but cozy and quite room with a full size...</td>\n",
       "      <td>Charming and quiet room in a second floor 1910...</td>\n",
       "      <td>none</td>\n",
       "      <td>The room is in Roslindale, a diverse and prima...</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>1.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>6976</td>\n",
       "      <td>https://www.airbnb.com/rooms/6976</td>\n",
       "      <td>20160906204935</td>\n",
       "      <td>2016-09-07</td>\n",
       "      <td>Mexican Folk Art Haven in Boston</td>\n",
       "      <td>Come stay with a friendly, middle-aged guy in ...</td>\n",
       "      <td>Come stay with a friendly, middle-aged guy in ...</td>\n",
       "      <td>Come stay with a friendly, middle-aged guy in ...</td>\n",
       "      <td>none</td>\n",
       "      <td>The LOCATION: Roslindale is a safe and diverse...</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>1436513</td>\n",
       "      <td>https://www.airbnb.com/rooms/1436513</td>\n",
       "      <td>20160906204935</td>\n",
       "      <td>2016-09-07</td>\n",
       "      <td>Spacious Sunny Bedroom Suite in Historic Home</td>\n",
       "      <td>Come experience the comforts of home away from...</td>\n",
       "      <td>Most places you find in Boston are small howev...</td>\n",
       "      <td>Come experience the comforts of home away from...</td>\n",
       "      <td>none</td>\n",
       "      <td>Roslindale is a lovely little neighborhood loc...</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flexible</th>\n",
       "      <th>10.0</th>\n",
       "      <td>7651065</td>\n",
       "      <td>https://www.airbnb.com/rooms/7651065</td>\n",
       "      <td>20160906204935</td>\n",
       "      <td>2016-09-07</td>\n",
       "      <td>Come Home to Boston</td>\n",
       "      <td>My comfy, clean and relaxing home is one block...</td>\n",
       "      <td>Clean, attractive, private room, one block fro...</td>\n",
       "      <td>My comfy, clean and relaxing home is one block...</td>\n",
       "      <td>none</td>\n",
       "      <td>I love the proximity to downtown, the neighbor...</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>2.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               id  \\\n",
       "cancellation_policy review_scores_value             \n",
       "moderate            NaN                  12147973   \n",
       "                    9.0                   3075044   \n",
       "                    10.0                     6976   \n",
       "                    10.0                  1436513   \n",
       "flexible            10.0                  7651065   \n",
       "\n",
       "                                                                   listing_url  \\\n",
       "cancellation_policy review_scores_value                                          \n",
       "moderate            NaN                  https://www.airbnb.com/rooms/12147973   \n",
       "                    9.0                   https://www.airbnb.com/rooms/3075044   \n",
       "                    10.0                     https://www.airbnb.com/rooms/6976   \n",
       "                    10.0                  https://www.airbnb.com/rooms/1436513   \n",
       "flexible            10.0                  https://www.airbnb.com/rooms/7651065   \n",
       "\n",
       "                                              scrape_id last_scraped  \\\n",
       "cancellation_policy review_scores_value                                \n",
       "moderate            NaN                  20160906204935   2016-09-07   \n",
       "                    9.0                  20160906204935   2016-09-07   \n",
       "                    10.0                 20160906204935   2016-09-07   \n",
       "                    10.0                 20160906204935   2016-09-07   \n",
       "flexible            10.0                 20160906204935   2016-09-07   \n",
       "\n",
       "                                                                                  name  \\\n",
       "cancellation_policy review_scores_value                                                  \n",
       "moderate            NaN                                     Sunny Bungalow in the City   \n",
       "                    9.0                              Charming room in pet friendly apt   \n",
       "                    10.0                              Mexican Folk Art Haven in Boston   \n",
       "                    10.0                 Spacious Sunny Bedroom Suite in Historic Home   \n",
       "flexible            10.0                                           Come Home to Boston   \n",
       "\n",
       "                                                                                   summary  \\\n",
       "cancellation_policy review_scores_value                                                      \n",
       "moderate            NaN                  Cozy, sunny, family home.  Master bedroom high...   \n",
       "                    9.0                  Charming and quiet room in a second floor 1910...   \n",
       "                    10.0                 Come stay with a friendly, middle-aged guy in ...   \n",
       "                    10.0                 Come experience the comforts of home away from...   \n",
       "flexible            10.0                 My comfy, clean and relaxing home is one block...   \n",
       "\n",
       "                                                                                     space  \\\n",
       "cancellation_policy review_scores_value                                                      \n",
       "moderate            NaN                  The house has an open and cozy feel at the sam...   \n",
       "                    9.0                  Small but cozy and quite room with a full size...   \n",
       "                    10.0                 Come stay with a friendly, middle-aged guy in ...   \n",
       "                    10.0                 Most places you find in Boston are small howev...   \n",
       "flexible            10.0                 Clean, attractive, private room, one block fro...   \n",
       "\n",
       "                                                                               description  \\\n",
       "cancellation_policy review_scores_value                                                      \n",
       "moderate            NaN                  Cozy, sunny, family home.  Master bedroom high...   \n",
       "                    9.0                  Charming and quiet room in a second floor 1910...   \n",
       "                    10.0                 Come stay with a friendly, middle-aged guy in ...   \n",
       "                    10.0                 Come experience the comforts of home away from...   \n",
       "flexible            10.0                 My comfy, clean and relaxing home is one block...   \n",
       "\n",
       "                                        experiences_offered  \\\n",
       "cancellation_policy review_scores_value                       \n",
       "moderate            NaN                                none   \n",
       "                    9.0                                none   \n",
       "                    10.0                               none   \n",
       "                    10.0                               none   \n",
       "flexible            10.0                               none   \n",
       "\n",
       "                                                                     neighborhood_overview  \\\n",
       "cancellation_policy review_scores_value                                                      \n",
       "moderate            NaN                  Roslindale is quiet, convenient and friendly. ...   \n",
       "                    9.0                  The room is in Roslindale, a diverse and prima...   \n",
       "                    10.0                 The LOCATION: Roslindale is a safe and diverse...   \n",
       "                    10.0                 Roslindale is a lovely little neighborhood loc...   \n",
       "flexible            10.0                 I love the proximity to downtown, the neighbor...   \n",
       "\n",
       "                                         ... review_scores_communication  \\\n",
       "cancellation_policy review_scores_value  ...                               \n",
       "moderate            NaN                  ...                         NaN   \n",
       "                    9.0                  ...                        10.0   \n",
       "                    10.0                 ...                        10.0   \n",
       "                    10.0                 ...                        10.0   \n",
       "flexible            10.0                 ...                        10.0   \n",
       "\n",
       "                                        review_scores_location  \\\n",
       "cancellation_policy review_scores_value                          \n",
       "moderate            NaN                                    NaN   \n",
       "                    9.0                                    9.0   \n",
       "                    10.0                                   9.0   \n",
       "                    10.0                                  10.0   \n",
       "flexible            10.0                                   9.0   \n",
       "\n",
       "                                        requires_license license  \\\n",
       "cancellation_policy review_scores_value                            \n",
       "moderate            NaN                                f     NaN   \n",
       "                    9.0                                f     NaN   \n",
       "                    10.0                               f     NaN   \n",
       "                    10.0                               f     NaN   \n",
       "flexible            10.0                               f     NaN   \n",
       "\n",
       "                                        jurisdiction_names instant_bookable  \\\n",
       "cancellation_policy review_scores_value                                       \n",
       "moderate            NaN                                NaN                f   \n",
       "                    9.0                                NaN                t   \n",
       "                    10.0                               NaN                f   \n",
       "                    10.0                               NaN                f   \n",
       "flexible            10.0                               NaN                f   \n",
       "\n",
       "                                        require_guest_profile_picture  \\\n",
       "cancellation_policy review_scores_value                                 \n",
       "moderate            NaN                                             f   \n",
       "                    9.0                                             f   \n",
       "                    10.0                                            t   \n",
       "                    10.0                                            f   \n",
       "flexible            10.0                                            f   \n",
       "\n",
       "                                        require_guest_phone_verification  \\\n",
       "cancellation_policy review_scores_value                                    \n",
       "moderate            NaN                                                f   \n",
       "                    9.0                                                f   \n",
       "                    10.0                                               f   \n",
       "                    10.0                                               f   \n",
       "flexible            10.0                                               f   \n",
       "\n",
       "                                        calculated_host_listings_count  \\\n",
       "cancellation_policy review_scores_value                                  \n",
       "moderate            NaN                                              1   \n",
       "                    9.0                                              1   \n",
       "                    10.0                                             1   \n",
       "                    10.0                                             1   \n",
       "flexible            10.0                                             1   \n",
       "\n",
       "                                         reviews_per_month  \n",
       "cancellation_policy review_scores_value                     \n",
       "moderate            NaN                                NaN  \n",
       "                    9.0                               1.30  \n",
       "                    10.0                              0.47  \n",
       "                    10.0                              1.00  \n",
       "flexible            10.0                              2.25  \n",
       "\n",
       "[5 rows x 93 columns]"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To this point we have applied very simple processing to our data after splitting, really just outputting\n",
    "# some print statements to demonstrate how the splitting works. The pandas developers have three broad\n",
    "# categories of data processing to happen during the apply step, Aggregation of group data, Transformation of\n",
    "# group data, and Filtration of group data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cancellation_policy</th>\n",
       "      <th>review_scores_value</th>\n",
       "      <th>id</th>\n",
       "      <th>listing_url</th>\n",
       "      <th>scrape_id</th>\n",
       "      <th>last_scraped</th>\n",
       "      <th>name</th>\n",
       "      <th>summary</th>\n",
       "      <th>space</th>\n",
       "      <th>description</th>\n",
       "      <th>...</th>\n",
       "      <th>review_scores_communication</th>\n",
       "      <th>review_scores_location</th>\n",
       "      <th>requires_license</th>\n",
       "      <th>license</th>\n",
       "      <th>jurisdiction_names</th>\n",
       "      <th>instant_bookable</th>\n",
       "      <th>require_guest_profile_picture</th>\n",
       "      <th>require_guest_phone_verification</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>reviews_per_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>moderate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12147973</td>\n",
       "      <td>https://www.airbnb.com/rooms/12147973</td>\n",
       "      <td>20160906204935</td>\n",
       "      <td>2016-09-07</td>\n",
       "      <td>Sunny Bungalow in the City</td>\n",
       "      <td>Cozy, sunny, family home.  Master bedroom high...</td>\n",
       "      <td>The house has an open and cozy feel at the sam...</td>\n",
       "      <td>Cozy, sunny, family home.  Master bedroom high...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>moderate</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3075044</td>\n",
       "      <td>https://www.airbnb.com/rooms/3075044</td>\n",
       "      <td>20160906204935</td>\n",
       "      <td>2016-09-07</td>\n",
       "      <td>Charming room in pet friendly apt</td>\n",
       "      <td>Charming and quiet room in a second floor 1910...</td>\n",
       "      <td>Small but cozy and quite room with a full size...</td>\n",
       "      <td>Charming and quiet room in a second floor 1910...</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>1.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>moderate</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6976</td>\n",
       "      <td>https://www.airbnb.com/rooms/6976</td>\n",
       "      <td>20160906204935</td>\n",
       "      <td>2016-09-07</td>\n",
       "      <td>Mexican Folk Art Haven in Boston</td>\n",
       "      <td>Come stay with a friendly, middle-aged guy in ...</td>\n",
       "      <td>Come stay with a friendly, middle-aged guy in ...</td>\n",
       "      <td>Come stay with a friendly, middle-aged guy in ...</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>moderate</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1436513</td>\n",
       "      <td>https://www.airbnb.com/rooms/1436513</td>\n",
       "      <td>20160906204935</td>\n",
       "      <td>2016-09-07</td>\n",
       "      <td>Spacious Sunny Bedroom Suite in Historic Home</td>\n",
       "      <td>Come experience the comforts of home away from...</td>\n",
       "      <td>Most places you find in Boston are small howev...</td>\n",
       "      <td>Come experience the comforts of home away from...</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>flexible</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7651065</td>\n",
       "      <td>https://www.airbnb.com/rooms/7651065</td>\n",
       "      <td>20160906204935</td>\n",
       "      <td>2016-09-07</td>\n",
       "      <td>Come Home to Boston</td>\n",
       "      <td>My comfy, clean and relaxing home is one block...</td>\n",
       "      <td>Clean, attractive, private room, one block fro...</td>\n",
       "      <td>My comfy, clean and relaxing home is one block...</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>2.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3580</th>\n",
       "      <td>strict</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8373729</td>\n",
       "      <td>https://www.airbnb.com/rooms/8373729</td>\n",
       "      <td>20160906204935</td>\n",
       "      <td>2016-09-07</td>\n",
       "      <td>Big cozy room near T</td>\n",
       "      <td>5 min walking to Orange Line subway with 2 sto...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5 min walking to Orange Line subway with 2 sto...</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>8</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3581</th>\n",
       "      <td>strict</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14844274</td>\n",
       "      <td>https://www.airbnb.com/rooms/14844274</td>\n",
       "      <td>20160906204935</td>\n",
       "      <td>2016-09-07</td>\n",
       "      <td>BU Apartment DexterPark Bright room</td>\n",
       "      <td>Most popular apartment in BU, best located in ...</td>\n",
       "      <td>Best location in BU</td>\n",
       "      <td>Most popular apartment in BU, best located in ...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3582</th>\n",
       "      <td>flexible</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14585486</td>\n",
       "      <td>https://www.airbnb.com/rooms/14585486</td>\n",
       "      <td>20160906204935</td>\n",
       "      <td>2016-09-07</td>\n",
       "      <td>Gorgeous funky apartment</td>\n",
       "      <td>Funky little apartment close to public transpo...</td>\n",
       "      <td>Modern and relaxed space with many facilities ...</td>\n",
       "      <td>Funky little apartment close to public transpo...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3583</th>\n",
       "      <td>strict</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14603878</td>\n",
       "      <td>https://www.airbnb.com/rooms/14603878</td>\n",
       "      <td>20160906204935</td>\n",
       "      <td>2016-09-07</td>\n",
       "      <td>Great Location; Train and Restaurants</td>\n",
       "      <td>My place is close to Taco Loco Mexican Grill, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My place is close to Taco Loco Mexican Grill, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3584</th>\n",
       "      <td>flexible</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14504422</td>\n",
       "      <td>https://www.airbnb.com/rooms/14504422</td>\n",
       "      <td>20160906204935</td>\n",
       "      <td>2016-09-07</td>\n",
       "      <td>(K1) Private Room near Harvard/MIT</td>\n",
       "      <td>My place is close to My home is a warm and fri...</td>\n",
       "      <td>To ensure a smooth check in: 1. You MUST have ...</td>\n",
       "      <td>My place is close to My home is a warm and fri...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3585 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     cancellation_policy  review_scores_value        id  \\\n",
       "0               moderate                  NaN  12147973   \n",
       "1               moderate                  9.0   3075044   \n",
       "2               moderate                 10.0      6976   \n",
       "3               moderate                 10.0   1436513   \n",
       "4               flexible                 10.0   7651065   \n",
       "...                  ...                  ...       ...   \n",
       "3580              strict                  9.0   8373729   \n",
       "3581              strict                  NaN  14844274   \n",
       "3582            flexible                  NaN  14585486   \n",
       "3583              strict                  7.0  14603878   \n",
       "3584            flexible                  NaN  14504422   \n",
       "\n",
       "                                listing_url       scrape_id last_scraped  \\\n",
       "0     https://www.airbnb.com/rooms/12147973  20160906204935   2016-09-07   \n",
       "1      https://www.airbnb.com/rooms/3075044  20160906204935   2016-09-07   \n",
       "2         https://www.airbnb.com/rooms/6976  20160906204935   2016-09-07   \n",
       "3      https://www.airbnb.com/rooms/1436513  20160906204935   2016-09-07   \n",
       "4      https://www.airbnb.com/rooms/7651065  20160906204935   2016-09-07   \n",
       "...                                     ...             ...          ...   \n",
       "3580   https://www.airbnb.com/rooms/8373729  20160906204935   2016-09-07   \n",
       "3581  https://www.airbnb.com/rooms/14844274  20160906204935   2016-09-07   \n",
       "3582  https://www.airbnb.com/rooms/14585486  20160906204935   2016-09-07   \n",
       "3583  https://www.airbnb.com/rooms/14603878  20160906204935   2016-09-07   \n",
       "3584  https://www.airbnb.com/rooms/14504422  20160906204935   2016-09-07   \n",
       "\n",
       "                                               name  \\\n",
       "0                        Sunny Bungalow in the City   \n",
       "1                 Charming room in pet friendly apt   \n",
       "2                  Mexican Folk Art Haven in Boston   \n",
       "3     Spacious Sunny Bedroom Suite in Historic Home   \n",
       "4                               Come Home to Boston   \n",
       "...                                             ...   \n",
       "3580                           Big cozy room near T   \n",
       "3581            BU Apartment DexterPark Bright room   \n",
       "3582                       Gorgeous funky apartment   \n",
       "3583          Great Location; Train and Restaurants   \n",
       "3584             (K1) Private Room near Harvard/MIT   \n",
       "\n",
       "                                                summary  \\\n",
       "0     Cozy, sunny, family home.  Master bedroom high...   \n",
       "1     Charming and quiet room in a second floor 1910...   \n",
       "2     Come stay with a friendly, middle-aged guy in ...   \n",
       "3     Come experience the comforts of home away from...   \n",
       "4     My comfy, clean and relaxing home is one block...   \n",
       "...                                                 ...   \n",
       "3580  5 min walking to Orange Line subway with 2 sto...   \n",
       "3581  Most popular apartment in BU, best located in ...   \n",
       "3582  Funky little apartment close to public transpo...   \n",
       "3583  My place is close to Taco Loco Mexican Grill, ...   \n",
       "3584  My place is close to My home is a warm and fri...   \n",
       "\n",
       "                                                  space  \\\n",
       "0     The house has an open and cozy feel at the sam...   \n",
       "1     Small but cozy and quite room with a full size...   \n",
       "2     Come stay with a friendly, middle-aged guy in ...   \n",
       "3     Most places you find in Boston are small howev...   \n",
       "4     Clean, attractive, private room, one block fro...   \n",
       "...                                                 ...   \n",
       "3580                                                NaN   \n",
       "3581                                Best location in BU   \n",
       "3582  Modern and relaxed space with many facilities ...   \n",
       "3583                                                NaN   \n",
       "3584  To ensure a smooth check in: 1. You MUST have ...   \n",
       "\n",
       "                                            description  ...  \\\n",
       "0     Cozy, sunny, family home.  Master bedroom high...  ...   \n",
       "1     Charming and quiet room in a second floor 1910...  ...   \n",
       "2     Come stay with a friendly, middle-aged guy in ...  ...   \n",
       "3     Come experience the comforts of home away from...  ...   \n",
       "4     My comfy, clean and relaxing home is one block...  ...   \n",
       "...                                                 ...  ...   \n",
       "3580  5 min walking to Orange Line subway with 2 sto...  ...   \n",
       "3581  Most popular apartment in BU, best located in ...  ...   \n",
       "3582  Funky little apartment close to public transpo...  ...   \n",
       "3583  My place is close to Taco Loco Mexican Grill, ...  ...   \n",
       "3584  My place is close to My home is a warm and fri...  ...   \n",
       "\n",
       "     review_scores_communication review_scores_location requires_license  \\\n",
       "0                            NaN                    NaN                f   \n",
       "1                           10.0                    9.0                f   \n",
       "2                           10.0                    9.0                f   \n",
       "3                           10.0                   10.0                f   \n",
       "4                           10.0                    9.0                f   \n",
       "...                          ...                    ...              ...   \n",
       "3580                        10.0                    8.0                f   \n",
       "3581                         NaN                    NaN                f   \n",
       "3582                         NaN                    NaN                f   \n",
       "3583                         9.0                    8.0                f   \n",
       "3584                         NaN                    NaN                f   \n",
       "\n",
       "     license jurisdiction_names instant_bookable  \\\n",
       "0        NaN                NaN                f   \n",
       "1        NaN                NaN                t   \n",
       "2        NaN                NaN                f   \n",
       "3        NaN                NaN                f   \n",
       "4        NaN                NaN                f   \n",
       "...      ...                ...              ...   \n",
       "3580     NaN                NaN                t   \n",
       "3581     NaN                NaN                f   \n",
       "3582     NaN                NaN                f   \n",
       "3583     NaN                NaN                f   \n",
       "3584     NaN                NaN                t   \n",
       "\n",
       "     require_guest_profile_picture require_guest_phone_verification  \\\n",
       "0                                f                                f   \n",
       "1                                f                                f   \n",
       "2                                t                                f   \n",
       "3                                f                                f   \n",
       "4                                f                                f   \n",
       "...                            ...                              ...   \n",
       "3580                             f                                f   \n",
       "3581                             f                                f   \n",
       "3582                             f                                f   \n",
       "3583                             f                                f   \n",
       "3584                             f                                f   \n",
       "\n",
       "     calculated_host_listings_count reviews_per_month  \n",
       "0                                 1               NaN  \n",
       "1                                 1              1.30  \n",
       "2                                 1              0.47  \n",
       "3                                 1              1.00  \n",
       "4                                 1              2.25  \n",
       "...                             ...               ...  \n",
       "3580                              8              0.34  \n",
       "3581                              2               NaN  \n",
       "3582                              1               NaN  \n",
       "3583                              1              2.00  \n",
       "3584                              3               NaN  \n",
       "\n",
       "[3585 rows x 95 columns]"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_scores_value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cancellation_policy</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>flexible</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moderate</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strict</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>super_strict_30</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     review_scores_value\n",
       "cancellation_policy                     \n",
       "flexible                             NaN\n",
       "moderate                             NaN\n",
       "strict                               NaN\n",
       "super_strict_30                      NaN"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The most straight forward apply step is the aggregation of data, and uses the method agg() on the groupby\n",
    "# object. Thus far we have only iterated through the groupby object, unpacking it into a label (the group\n",
    "# name) and a dataframe. But with agg we can pass in a dictionary of the columns we are interested in\n",
    "# aggregating along with the function we are looking to apply to aggregate.\n",
    "\n",
    "# Let's reset the index for our airbnb data\n",
    "df=df.reset_index()\n",
    "\n",
    "# Now lets group by the cancellation policy and find the average review_scores_value by group\n",
    "df.groupby(\"cancellation_policy\").agg({\"review_scores_value\":np.average})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_scores_value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cancellation_policy</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>flexible</th>\n",
       "      <td>9.237421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moderate</th>\n",
       "      <td>9.307398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strict</th>\n",
       "      <td>9.081441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>super_strict_30</th>\n",
       "      <td>8.537313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     review_scores_value\n",
       "cancellation_policy                     \n",
       "flexible                        9.237421\n",
       "moderate                        9.307398\n",
       "strict                          9.081441\n",
       "super_strict_30                 8.537313"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hrm. That didn't seem to work at all. Just a bunch of not a numbers. The issue is actually in the function\n",
    "# that we sent to aggregate. np.average does not ignore nans! However, there is a function we can use for this\n",
    "df.groupby(\"cancellation_policy\").agg({\"review_scores_value\":np.nanmean})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">review_scores_value</th>\n",
       "      <th>reviews_per_month</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>nanmean</th>\n",
       "      <th>nanstd</th>\n",
       "      <th>nanmean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cancellation_policy</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>flexible</th>\n",
       "      <td>9.237421</td>\n",
       "      <td>1.096271</td>\n",
       "      <td>1.829210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moderate</th>\n",
       "      <td>9.307398</td>\n",
       "      <td>0.859859</td>\n",
       "      <td>2.391922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strict</th>\n",
       "      <td>9.081441</td>\n",
       "      <td>1.040531</td>\n",
       "      <td>1.873467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>super_strict_30</th>\n",
       "      <td>8.537313</td>\n",
       "      <td>0.840785</td>\n",
       "      <td>0.340143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    review_scores_value           reviews_per_month\n",
       "                                nanmean    nanstd           nanmean\n",
       "cancellation_policy                                                \n",
       "flexible                       9.237421  1.096271          1.829210\n",
       "moderate                       9.307398  0.859859          2.391922\n",
       "strict                         9.081441  1.040531          1.873467\n",
       "super_strict_30                8.537313  0.840785          0.340143"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can just extend this dictionary to aggregate by multiple functions or multiple columns.\n",
    "df.groupby(\"cancellation_policy\").agg({\"review_scores_value\":(np.nanmean,np.nanstd),\n",
    "                                      \"reviews_per_month\":np.nanmean})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation is different from aggregation. Where agg() returns a single value per column, so one row per\n",
    "# group, tranform() returns an object that is the same size as the group. Essentially, it broadcasts the\n",
    "# function you supply over the grouped dataframe, returning a new dataframe. This makes combining data later\n",
    "# easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_scores_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.307398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.307398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.307398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.307398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.237421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_scores_value\n",
       "0             9.307398\n",
       "1             9.307398\n",
       "2             9.307398\n",
       "3             9.307398\n",
       "4             9.237421"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For instance, suppose we want to include the average rating values in a given group by cancellation policy,\n",
    "# but preserve the dataframe shape so that we could generate a difference between an individual observation\n",
    "# and the sum.\n",
    "\n",
    "# First, lets define just some subset of columns we are interested in\n",
    "cols=['cancellation_policy','review_scores_value']\n",
    "# Now lets transform it, I'll store this in its own dataframe\n",
    "transform_df=df[cols].groupby('cancellation_policy').transform(np.nanmean)\n",
    "transform_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cancellation_policy</th>\n",
       "      <th>review_scores_value</th>\n",
       "      <th>id</th>\n",
       "      <th>listing_url</th>\n",
       "      <th>scrape_id</th>\n",
       "      <th>last_scraped</th>\n",
       "      <th>name</th>\n",
       "      <th>summary</th>\n",
       "      <th>space</th>\n",
       "      <th>description</th>\n",
       "      <th>...</th>\n",
       "      <th>review_scores_location</th>\n",
       "      <th>requires_license</th>\n",
       "      <th>license</th>\n",
       "      <th>jurisdiction_names</th>\n",
       "      <th>instant_bookable</th>\n",
       "      <th>require_guest_profile_picture</th>\n",
       "      <th>require_guest_phone_verification</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>mean_review_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>moderate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12147973</td>\n",
       "      <td>https://www.airbnb.com/rooms/12147973</td>\n",
       "      <td>20160906204935</td>\n",
       "      <td>2016-09-07</td>\n",
       "      <td>Sunny Bungalow in the City</td>\n",
       "      <td>Cozy, sunny, family home.  Master bedroom high...</td>\n",
       "      <td>The house has an open and cozy feel at the sam...</td>\n",
       "      <td>Cozy, sunny, family home.  Master bedroom high...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.307398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>moderate</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3075044</td>\n",
       "      <td>https://www.airbnb.com/rooms/3075044</td>\n",
       "      <td>20160906204935</td>\n",
       "      <td>2016-09-07</td>\n",
       "      <td>Charming room in pet friendly apt</td>\n",
       "      <td>Charming and quiet room in a second floor 1910...</td>\n",
       "      <td>Small but cozy and quite room with a full size...</td>\n",
       "      <td>Charming and quiet room in a second floor 1910...</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>1.30</td>\n",
       "      <td>9.307398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>moderate</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6976</td>\n",
       "      <td>https://www.airbnb.com/rooms/6976</td>\n",
       "      <td>20160906204935</td>\n",
       "      <td>2016-09-07</td>\n",
       "      <td>Mexican Folk Art Haven in Boston</td>\n",
       "      <td>Come stay with a friendly, middle-aged guy in ...</td>\n",
       "      <td>Come stay with a friendly, middle-aged guy in ...</td>\n",
       "      <td>Come stay with a friendly, middle-aged guy in ...</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>0.47</td>\n",
       "      <td>9.307398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>moderate</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1436513</td>\n",
       "      <td>https://www.airbnb.com/rooms/1436513</td>\n",
       "      <td>20160906204935</td>\n",
       "      <td>2016-09-07</td>\n",
       "      <td>Spacious Sunny Bedroom Suite in Historic Home</td>\n",
       "      <td>Come experience the comforts of home away from...</td>\n",
       "      <td>Most places you find in Boston are small howev...</td>\n",
       "      <td>Come experience the comforts of home away from...</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>9.307398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>flexible</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7651065</td>\n",
       "      <td>https://www.airbnb.com/rooms/7651065</td>\n",
       "      <td>20160906204935</td>\n",
       "      <td>2016-09-07</td>\n",
       "      <td>Come Home to Boston</td>\n",
       "      <td>My comfy, clean and relaxing home is one block...</td>\n",
       "      <td>Clean, attractive, private room, one block fro...</td>\n",
       "      <td>My comfy, clean and relaxing home is one block...</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>2.25</td>\n",
       "      <td>9.237421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  cancellation_policy  review_scores_value        id  \\\n",
       "0            moderate                  NaN  12147973   \n",
       "1            moderate                  9.0   3075044   \n",
       "2            moderate                 10.0      6976   \n",
       "3            moderate                 10.0   1436513   \n",
       "4            flexible                 10.0   7651065   \n",
       "\n",
       "                             listing_url       scrape_id last_scraped  \\\n",
       "0  https://www.airbnb.com/rooms/12147973  20160906204935   2016-09-07   \n",
       "1   https://www.airbnb.com/rooms/3075044  20160906204935   2016-09-07   \n",
       "2      https://www.airbnb.com/rooms/6976  20160906204935   2016-09-07   \n",
       "3   https://www.airbnb.com/rooms/1436513  20160906204935   2016-09-07   \n",
       "4   https://www.airbnb.com/rooms/7651065  20160906204935   2016-09-07   \n",
       "\n",
       "                                            name  \\\n",
       "0                     Sunny Bungalow in the City   \n",
       "1              Charming room in pet friendly apt   \n",
       "2               Mexican Folk Art Haven in Boston   \n",
       "3  Spacious Sunny Bedroom Suite in Historic Home   \n",
       "4                            Come Home to Boston   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Cozy, sunny, family home.  Master bedroom high...   \n",
       "1  Charming and quiet room in a second floor 1910...   \n",
       "2  Come stay with a friendly, middle-aged guy in ...   \n",
       "3  Come experience the comforts of home away from...   \n",
       "4  My comfy, clean and relaxing home is one block...   \n",
       "\n",
       "                                               space  \\\n",
       "0  The house has an open and cozy feel at the sam...   \n",
       "1  Small but cozy and quite room with a full size...   \n",
       "2  Come stay with a friendly, middle-aged guy in ...   \n",
       "3  Most places you find in Boston are small howev...   \n",
       "4  Clean, attractive, private room, one block fro...   \n",
       "\n",
       "                                         description  ...  \\\n",
       "0  Cozy, sunny, family home.  Master bedroom high...  ...   \n",
       "1  Charming and quiet room in a second floor 1910...  ...   \n",
       "2  Come stay with a friendly, middle-aged guy in ...  ...   \n",
       "3  Come experience the comforts of home away from...  ...   \n",
       "4  My comfy, clean and relaxing home is one block...  ...   \n",
       "\n",
       "  review_scores_location requires_license license jurisdiction_names  \\\n",
       "0                    NaN                f     NaN                NaN   \n",
       "1                    9.0                f     NaN                NaN   \n",
       "2                    9.0                f     NaN                NaN   \n",
       "3                   10.0                f     NaN                NaN   \n",
       "4                    9.0                f     NaN                NaN   \n",
       "\n",
       "  instant_bookable require_guest_profile_picture  \\\n",
       "0                f                             f   \n",
       "1                t                             f   \n",
       "2                f                             t   \n",
       "3                f                             f   \n",
       "4                f                             f   \n",
       "\n",
       "  require_guest_phone_verification calculated_host_listings_count  \\\n",
       "0                                f                              1   \n",
       "1                                f                              1   \n",
       "2                                f                              1   \n",
       "3                                f                              1   \n",
       "4                                f                              1   \n",
       "\n",
       "  reviews_per_month mean_review_scores  \n",
       "0               NaN           9.307398  \n",
       "1              1.30           9.307398  \n",
       "2              0.47           9.307398  \n",
       "3              1.00           9.307398  \n",
       "4              2.25           9.237421  \n",
       "\n",
       "[5 rows x 96 columns]"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So we can see that the index here is actually the same as the original dataframe. So lets just join this\n",
    "# in. Before we do that, lets rename the column in the transformed version\n",
    "transform_df.rename({'review_scores_value':'mean_review_scores'}, axis='columns', inplace=True)\n",
    "df=df.merge(transform_df, left_index=True, right_index=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         NaN\n",
       "1    0.307398\n",
       "2    0.692602\n",
       "3    0.692602\n",
       "4    0.762579\n",
       "Name: mean_diff, dtype: float64"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Great, we can see that our new column is in place, the mean_review_scores. So now we could create, for\n",
    "# instance, the difference between a given row and it's group (the cancellation policy) means.\n",
    "df['mean_diff']=np.absolute(df['review_scores_value']-df['mean_review_scores'])\n",
    "df['mean_diff'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The GroupBy object has build in support for filtering groups as well. It's often that you'll want to group\n",
    "# by some feature, then make some transformation to the groups, then drop certain groups as part of your\n",
    "# cleaning routines. The filter() function takes in a function which it applies to each group dataframe and\n",
    "# returns either a True or a False, depending upon whether that group should be included in the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cancellation_policy</th>\n",
       "      <th>review_scores_value</th>\n",
       "      <th>id</th>\n",
       "      <th>listing_url</th>\n",
       "      <th>scrape_id</th>\n",
       "      <th>last_scraped</th>\n",
       "      <th>name</th>\n",
       "      <th>summary</th>\n",
       "      <th>space</th>\n",
       "      <th>description</th>\n",
       "      <th>...</th>\n",
       "      <th>requires_license</th>\n",
       "      <th>license</th>\n",
       "      <th>jurisdiction_names</th>\n",
       "      <th>instant_bookable</th>\n",
       "      <th>require_guest_profile_picture</th>\n",
       "      <th>require_guest_phone_verification</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>mean_review_scores</th>\n",
       "      <th>mean_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>moderate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12147973</td>\n",
       "      <td>https://www.airbnb.com/rooms/12147973</td>\n",
       "      <td>20160906204935</td>\n",
       "      <td>2016-09-07</td>\n",
       "      <td>Sunny Bungalow in the City</td>\n",
       "      <td>Cozy, sunny, family home.  Master bedroom high...</td>\n",
       "      <td>The house has an open and cozy feel at the sam...</td>\n",
       "      <td>Cozy, sunny, family home.  Master bedroom high...</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.307398</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>moderate</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3075044</td>\n",
       "      <td>https://www.airbnb.com/rooms/3075044</td>\n",
       "      <td>20160906204935</td>\n",
       "      <td>2016-09-07</td>\n",
       "      <td>Charming room in pet friendly apt</td>\n",
       "      <td>Charming and quiet room in a second floor 1910...</td>\n",
       "      <td>Small but cozy and quite room with a full size...</td>\n",
       "      <td>Charming and quiet room in a second floor 1910...</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>1.30</td>\n",
       "      <td>9.307398</td>\n",
       "      <td>0.307398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>moderate</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6976</td>\n",
       "      <td>https://www.airbnb.com/rooms/6976</td>\n",
       "      <td>20160906204935</td>\n",
       "      <td>2016-09-07</td>\n",
       "      <td>Mexican Folk Art Haven in Boston</td>\n",
       "      <td>Come stay with a friendly, middle-aged guy in ...</td>\n",
       "      <td>Come stay with a friendly, middle-aged guy in ...</td>\n",
       "      <td>Come stay with a friendly, middle-aged guy in ...</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>0.47</td>\n",
       "      <td>9.307398</td>\n",
       "      <td>0.692602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>moderate</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1436513</td>\n",
       "      <td>https://www.airbnb.com/rooms/1436513</td>\n",
       "      <td>20160906204935</td>\n",
       "      <td>2016-09-07</td>\n",
       "      <td>Spacious Sunny Bedroom Suite in Historic Home</td>\n",
       "      <td>Come experience the comforts of home away from...</td>\n",
       "      <td>Most places you find in Boston are small howev...</td>\n",
       "      <td>Come experience the comforts of home away from...</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>9.307398</td>\n",
       "      <td>0.692602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>flexible</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7651065</td>\n",
       "      <td>https://www.airbnb.com/rooms/7651065</td>\n",
       "      <td>20160906204935</td>\n",
       "      <td>2016-09-07</td>\n",
       "      <td>Come Home to Boston</td>\n",
       "      <td>My comfy, clean and relaxing home is one block...</td>\n",
       "      <td>Clean, attractive, private room, one block fro...</td>\n",
       "      <td>My comfy, clean and relaxing home is one block...</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>2.25</td>\n",
       "      <td>9.237421</td>\n",
       "      <td>0.762579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3576</th>\n",
       "      <td>flexible</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14689681</td>\n",
       "      <td>https://www.airbnb.com/rooms/14689681</td>\n",
       "      <td>20160906204935</td>\n",
       "      <td>2016-09-07</td>\n",
       "      <td>Beautiful loft style bedroom with large bathroom</td>\n",
       "      <td>You'd be living on the top floor of a four sto...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>You'd be living on the top floor of a four sto...</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.237421</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3577</th>\n",
       "      <td>flexible</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13750763</td>\n",
       "      <td>https://www.airbnb.com/rooms/13750763</td>\n",
       "      <td>20160906204935</td>\n",
       "      <td>2016-09-07</td>\n",
       "      <td>Comfortable Space in the Heart of Brookline</td>\n",
       "      <td>Our place is close to Coolidge Corner, Allston...</td>\n",
       "      <td>This space consists of 2 Rooms and a private b...</td>\n",
       "      <td>Our place is close to Coolidge Corner, Allston...</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.237421</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3579</th>\n",
       "      <td>flexible</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14852179</td>\n",
       "      <td>https://www.airbnb.com/rooms/14852179</td>\n",
       "      <td>20160906204935</td>\n",
       "      <td>2016-09-07</td>\n",
       "      <td>Spacious Queen Bed Room Close to Boston Univer...</td>\n",
       "      <td>- Grocery: A full-size Star market is 2 minute...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>- Grocery: A full-size Star market is 2 minute...</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.237421</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3582</th>\n",
       "      <td>flexible</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14585486</td>\n",
       "      <td>https://www.airbnb.com/rooms/14585486</td>\n",
       "      <td>20160906204935</td>\n",
       "      <td>2016-09-07</td>\n",
       "      <td>Gorgeous funky apartment</td>\n",
       "      <td>Funky little apartment close to public transpo...</td>\n",
       "      <td>Modern and relaxed space with many facilities ...</td>\n",
       "      <td>Funky little apartment close to public transpo...</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.237421</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3584</th>\n",
       "      <td>flexible</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14504422</td>\n",
       "      <td>https://www.airbnb.com/rooms/14504422</td>\n",
       "      <td>20160906204935</td>\n",
       "      <td>2016-09-07</td>\n",
       "      <td>(K1) Private Room near Harvard/MIT</td>\n",
       "      <td>My place is close to My home is a warm and fri...</td>\n",
       "      <td>To ensure a smooth check in: 1. You MUST have ...</td>\n",
       "      <td>My place is close to My home is a warm and fri...</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.237421</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1918 rows × 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     cancellation_policy  review_scores_value        id  \\\n",
       "0               moderate                  NaN  12147973   \n",
       "1               moderate                  9.0   3075044   \n",
       "2               moderate                 10.0      6976   \n",
       "3               moderate                 10.0   1436513   \n",
       "4               flexible                 10.0   7651065   \n",
       "...                  ...                  ...       ...   \n",
       "3576            flexible                  NaN  14689681   \n",
       "3577            flexible                  NaN  13750763   \n",
       "3579            flexible                  NaN  14852179   \n",
       "3582            flexible                  NaN  14585486   \n",
       "3584            flexible                  NaN  14504422   \n",
       "\n",
       "                                listing_url       scrape_id last_scraped  \\\n",
       "0     https://www.airbnb.com/rooms/12147973  20160906204935   2016-09-07   \n",
       "1      https://www.airbnb.com/rooms/3075044  20160906204935   2016-09-07   \n",
       "2         https://www.airbnb.com/rooms/6976  20160906204935   2016-09-07   \n",
       "3      https://www.airbnb.com/rooms/1436513  20160906204935   2016-09-07   \n",
       "4      https://www.airbnb.com/rooms/7651065  20160906204935   2016-09-07   \n",
       "...                                     ...             ...          ...   \n",
       "3576  https://www.airbnb.com/rooms/14689681  20160906204935   2016-09-07   \n",
       "3577  https://www.airbnb.com/rooms/13750763  20160906204935   2016-09-07   \n",
       "3579  https://www.airbnb.com/rooms/14852179  20160906204935   2016-09-07   \n",
       "3582  https://www.airbnb.com/rooms/14585486  20160906204935   2016-09-07   \n",
       "3584  https://www.airbnb.com/rooms/14504422  20160906204935   2016-09-07   \n",
       "\n",
       "                                                   name  \\\n",
       "0                            Sunny Bungalow in the City   \n",
       "1                     Charming room in pet friendly apt   \n",
       "2                      Mexican Folk Art Haven in Boston   \n",
       "3         Spacious Sunny Bedroom Suite in Historic Home   \n",
       "4                                   Come Home to Boston   \n",
       "...                                                 ...   \n",
       "3576   Beautiful loft style bedroom with large bathroom   \n",
       "3577        Comfortable Space in the Heart of Brookline   \n",
       "3579  Spacious Queen Bed Room Close to Boston Univer...   \n",
       "3582                           Gorgeous funky apartment   \n",
       "3584                 (K1) Private Room near Harvard/MIT   \n",
       "\n",
       "                                                summary  \\\n",
       "0     Cozy, sunny, family home.  Master bedroom high...   \n",
       "1     Charming and quiet room in a second floor 1910...   \n",
       "2     Come stay with a friendly, middle-aged guy in ...   \n",
       "3     Come experience the comforts of home away from...   \n",
       "4     My comfy, clean and relaxing home is one block...   \n",
       "...                                                 ...   \n",
       "3576  You'd be living on the top floor of a four sto...   \n",
       "3577  Our place is close to Coolidge Corner, Allston...   \n",
       "3579  - Grocery: A full-size Star market is 2 minute...   \n",
       "3582  Funky little apartment close to public transpo...   \n",
       "3584  My place is close to My home is a warm and fri...   \n",
       "\n",
       "                                                  space  \\\n",
       "0     The house has an open and cozy feel at the sam...   \n",
       "1     Small but cozy and quite room with a full size...   \n",
       "2     Come stay with a friendly, middle-aged guy in ...   \n",
       "3     Most places you find in Boston are small howev...   \n",
       "4     Clean, attractive, private room, one block fro...   \n",
       "...                                                 ...   \n",
       "3576                                                NaN   \n",
       "3577  This space consists of 2 Rooms and a private b...   \n",
       "3579                                                NaN   \n",
       "3582  Modern and relaxed space with many facilities ...   \n",
       "3584  To ensure a smooth check in: 1. You MUST have ...   \n",
       "\n",
       "                                            description  ... requires_license  \\\n",
       "0     Cozy, sunny, family home.  Master bedroom high...  ...                f   \n",
       "1     Charming and quiet room in a second floor 1910...  ...                f   \n",
       "2     Come stay with a friendly, middle-aged guy in ...  ...                f   \n",
       "3     Come experience the comforts of home away from...  ...                f   \n",
       "4     My comfy, clean and relaxing home is one block...  ...                f   \n",
       "...                                                 ...  ...              ...   \n",
       "3576  You'd be living on the top floor of a four sto...  ...                f   \n",
       "3577  Our place is close to Coolidge Corner, Allston...  ...                f   \n",
       "3579  - Grocery: A full-size Star market is 2 minute...  ...                f   \n",
       "3582  Funky little apartment close to public transpo...  ...                f   \n",
       "3584  My place is close to My home is a warm and fri...  ...                f   \n",
       "\n",
       "     license jurisdiction_names instant_bookable  \\\n",
       "0        NaN                NaN                f   \n",
       "1        NaN                NaN                t   \n",
       "2        NaN                NaN                f   \n",
       "3        NaN                NaN                f   \n",
       "4        NaN                NaN                f   \n",
       "...      ...                ...              ...   \n",
       "3576     NaN                NaN                f   \n",
       "3577     NaN                NaN                f   \n",
       "3579     NaN                NaN                f   \n",
       "3582     NaN                NaN                f   \n",
       "3584     NaN                NaN                t   \n",
       "\n",
       "     require_guest_profile_picture require_guest_phone_verification  \\\n",
       "0                                f                                f   \n",
       "1                                f                                f   \n",
       "2                                t                                f   \n",
       "3                                f                                f   \n",
       "4                                f                                f   \n",
       "...                            ...                              ...   \n",
       "3576                             f                                f   \n",
       "3577                             f                                f   \n",
       "3579                             f                                f   \n",
       "3582                             f                                f   \n",
       "3584                             f                                f   \n",
       "\n",
       "     calculated_host_listings_count reviews_per_month mean_review_scores  \\\n",
       "0                                 1               NaN           9.307398   \n",
       "1                                 1              1.30           9.307398   \n",
       "2                                 1              0.47           9.307398   \n",
       "3                                 1              1.00           9.307398   \n",
       "4                                 1              2.25           9.237421   \n",
       "...                             ...               ...                ...   \n",
       "3576                              1               NaN           9.237421   \n",
       "3577                              1               NaN           9.237421   \n",
       "3579                              1               NaN           9.237421   \n",
       "3582                              1               NaN           9.237421   \n",
       "3584                              3               NaN           9.237421   \n",
       "\n",
       "     mean_diff  \n",
       "0          NaN  \n",
       "1     0.307398  \n",
       "2     0.692602  \n",
       "3     0.692602  \n",
       "4     0.762579  \n",
       "...        ...  \n",
       "3576       NaN  \n",
       "3577       NaN  \n",
       "3579       NaN  \n",
       "3582       NaN  \n",
       "3584       NaN  \n",
       "\n",
       "[1918 rows x 97 columns]"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For instance, if we only want those groups which have a mean rating above 9 included in our results\n",
    "df.groupby('cancellation_policy').filter(lambda x: np.nanmean(x['review_scores_value'])>9.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice that the results are still indexed, but that any of the results which were in a group with a mean\n",
    "# review score of less than or equal to 9.2 were not copied over."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cancellation_policy</th>\n",
       "      <th>review_scores_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>moderate</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>moderate</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>moderate</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>moderate</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>flexible</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cancellation_policy  review_scores_value\n",
       "0            moderate                  NaN\n",
       "1            moderate                  9.0\n",
       "2            moderate                 10.0\n",
       "3            moderate                 10.0\n",
       "4            flexible                 10.0"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# By far the most common operation I invoke on groupby objects is the apply() function. This allows you to\n",
    "# apply an arbitrary function to each group, and stitch the results back for each apply() into a single\n",
    "# dataframe where the index is preserved.\n",
    "\n",
    "# Lets look at an example using our airbnb data, I'm going to get a clean copy of the dataframe\n",
    "df=pd.read_csv(\"datasets/listings.csv\")\n",
    "# And lets just include some of the columns we were interested in previously\n",
    "df=df[['cancellation_policy','review_scores_value']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cancellation_policy</th>\n",
       "      <th>review_scores_value</th>\n",
       "      <th>review_scores_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>moderate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>moderate</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.307398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>moderate</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.692602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>moderate</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.692602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>flexible</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.762579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cancellation_policy  review_scores_value  review_scores_mean\n",
       "0            moderate                  NaN                 NaN\n",
       "1            moderate                  9.0            0.307398\n",
       "2            moderate                 10.0            0.692602\n",
       "3            moderate                 10.0            0.692602\n",
       "4            flexible                 10.0            0.762579"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In previous work we wanted to find the average review score of a listing and its deviation from the group\n",
    "# mean. This was a two step process, first we used transform() on the groupby object and then we had to\n",
    "# broadcast to create a new column. With apply() we could wrap this logic in one place\n",
    "def calc_mean_review_scores(group):\n",
    "    # group is a dataframe just of whatever we have grouped by, e.g. cancellation policy, so we can treat\n",
    "    # this as the complete dataframe\n",
    "    avg=np.nanmean(group[\"review_scores_value\"])\n",
    "    # now broadcast our formula and create a new column\n",
    "    group[\"review_scores_mean\"]=np.abs(avg-group[\"review_scores_value\"])\n",
    "    return group\n",
    "\n",
    "# Now just apply this to the groups\n",
    "df.groupby('cancellation_policy').apply(calc_mean_review_scores).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using apply can be slower than using some of the specialized functions, especially agg(). But, if your\n",
    "# dataframes are not huge, it's a solid general purpose approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Groupby is a powerful and commonly used tool for data cleaning and data analysis. Once you have grouped the\n",
    "data by some category you have a dataframe of just those values and you can conduct aggregated analsyis on\n",
    "the segments that you are interested. The groupby() function follows a split-apply-combine approach - first\n",
    "the data is split into subgroups, then you can apply some transformation, filtering, or aggregation, then\n",
    "the results are combined automatically by pandas for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Grades</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>excellent</th>\n",
       "      <td>A+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>excellent</th>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>excellent</th>\n",
       "      <td>A-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>B+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>B-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ok</th>\n",
       "      <td>C+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ok</th>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ok</th>\n",
       "      <td>C-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poor</th>\n",
       "      <td>D+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poor</th>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Grades\n",
       "excellent     A+\n",
       "excellent      A\n",
       "excellent     A-\n",
       "good          B+\n",
       "good           B\n",
       "good          B-\n",
       "ok            C+\n",
       "ok             C\n",
       "ok            C-\n",
       "poor          D+\n",
       "poor           D"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ratio Scale\n",
    "# Interval scale\n",
    "# Nominal data\n",
    "# Ordinal data\n",
    "\n",
    "# Let's bring in pandas as normal\n",
    "import pandas as pd\n",
    "\n",
    "# Here’s an example. Lets create a dataframe of letter grades in descending order. We can also set an index\n",
    "# value and here we'll just make it some human judgement of how good a student was, like \"excellent\" or \"good\"\n",
    "\n",
    "df=pd.DataFrame(['A+', 'A', 'A-', 'B+', 'B', 'B-', 'C+', 'C', 'C-', 'D+', 'D'],\n",
    "                index=['excellent', 'excellent', 'excellent', 'good', 'good', 'good', \n",
    "                       'ok', 'ok', 'ok', 'poor', 'poor'],\n",
    "               columns=[\"Grades\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Grades    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, if we check the datatype of this column, we see that it's just an object, since we set string values\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "excellent    A+\n",
       "excellent     A\n",
       "excellent    A-\n",
       "good         B+\n",
       "good          B\n",
       "Name: Grades, dtype: category\n",
       "Categories (11, object): ['A', 'A+', 'A-', 'B', ..., 'C+', 'C-', 'D', 'D+']"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can, however, tell pandas that we want to change the type to category, using the astype() function\n",
    "df[\"Grades\"].astype(\"category\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "excellent    A+\n",
       "excellent     A\n",
       "excellent    A-\n",
       "good         B+\n",
       "good          B\n",
       "Name: Grades, dtype: category\n",
       "Categories (11, object): ['D' < 'D+' < 'C-' < 'C' ... 'B+' < 'A-' < 'A' < 'A+']"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We see now that there are eleven categories, and pandas is aware of what those categories are. More\n",
    "# interesting though is that our data isn't just categorical, but that it's ordered. That is, an A- comes\n",
    "# after a B+, and B comes before a B+. We can tell pandas that the data is ordered by first creating a new\n",
    "# categorical data type with the list of the categories (in order) and the ordered=True flag\n",
    "my_categories=pd.CategoricalDtype(categories=['D', 'D+', 'C-', 'C', 'C+', 'B-', 'B', 'B+', 'A-', 'A', 'A+'], \n",
    "                           ordered=True)\n",
    "# then we can just pass this to the astype() function\n",
    "grades=df[\"Grades\"].astype(my_categories)\n",
    "grades.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Grades</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ok</th>\n",
       "      <td>C+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ok</th>\n",
       "      <td>C-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poor</th>\n",
       "      <td>D+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poor</th>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Grades\n",
       "ok       C+\n",
       "ok       C-\n",
       "poor     D+\n",
       "poor      D"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we see that pandas is not only aware that there are 11 categories, but it is also aware of the order of\n",
    "# those categoreies. So, what can you do with this? Well because there is an ordering this can help with\n",
    "# comparisons and boolean masking. For instance, if we have a list of our grades and we compare them to a “C”\n",
    "# we see that the lexicographical comparison returns results we were not intending. \n",
    "\n",
    "df[df[\"Grades\"]>\"C\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "excellent    A+\n",
       "excellent     A\n",
       "excellent    A-\n",
       "good         B+\n",
       "good          B\n",
       "good         B-\n",
       "ok           C+\n",
       "Name: Grades, dtype: category\n",
       "Categories (11, object): ['D' < 'D+' < 'C-' < 'C' ... 'B+' < 'A-' < 'A' < 'A+']"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So a C+ is great than a C, but a C- and D certainly are not. However, if we broadcast over the dataframe\n",
    "# which has the type set to an ordered categorical\n",
    "\n",
    "grades[grades>\"C\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We see that the operator works as we would expect. We can then use a certain set of mathematical operators,\n",
    "# like minimum, maximum, etc., on the ordinal data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sometimes it is useful to represent categorical values as each being a column with a true or a false as to\n",
    "# whether the category applies. This is especially common in feature extraction, which is a topic in the data\n",
    "# mining course. Variables with a boolean value are typically called dummy variables, and pandas has a built\n",
    "# in function called get_dummies which will convert the values of a single column into multiple columns of\n",
    "# zeros and ones indicating the presence of the dummy variable. I rarely use it, but when I do it's very\n",
    "# handy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STNAME\n",
       "Alabama        71339.343284\n",
       "Alaska         24490.724138\n",
       "Arizona       426134.466667\n",
       "Arkansas       38878.906667\n",
       "California    642309.586207\n",
       "Name: CENSUS2010POP, dtype: float64"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There’s one more common scale-based operation I’d like to talk about, and that’s on converting a scale from\n",
    "# something that is on the interval or ratio scale, like a numeric grade, into one which is categorical. Now,\n",
    "# this might seem a bit counter intuitive to you, since you are losing information about the value. But it’s\n",
    "# commonly done in a couple of places. For instance, if you are visualizing the frequencies of categories,\n",
    "# this can be an extremely useful approach, and histograms are regularly used with converted interval or ratio\n",
    "# data. In addition, if you’re using a machine learning classification approach on data, you need to be using\n",
    "# categorical data, so reducing dimensionality may be useful just to apply a given technique. Pandas has a\n",
    "# function called cut which takes as an argument some array-like structure like a column of a dataframe or a\n",
    "# series. It also takes a number of bins to be used, and all bins are kept at equal spacing.\n",
    " \n",
    "# Lets go back to our census data for an example. We saw that we could group by state, then aggregate to get a\n",
    "# list of the average county size by state. If we further apply cut to this with, say, ten bins, we can see\n",
    "# the states listed as categoricals using the average county size.\n",
    "\n",
    "# let's bring in numpy\n",
    "import numpy as np\n",
    "\n",
    "# Now we read in our dataset\n",
    "df=pd.read_csv(\"datasets/census.csv\")\n",
    "\n",
    "# And we reduce this to country data\n",
    "df=df[df['SUMLEV']==50]\n",
    "\n",
    "# And for a few groups\n",
    "df=df.set_index('STNAME').groupby(level=0)['CENSUS2010POP'].agg(np.average)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STNAME\n",
       "Alabama                   (11706.087, 75333.413]\n",
       "Alaska                    (11706.087, 75333.413]\n",
       "Arizona                 (390320.176, 453317.529]\n",
       "Arkansas                  (11706.087, 75333.413]\n",
       "California              (579312.234, 642309.586]\n",
       "Colorado                 (75333.413, 138330.766]\n",
       "Connecticut             (390320.176, 453317.529]\n",
       "Delaware                (264325.471, 327322.823]\n",
       "District of Columbia    (579312.234, 642309.586]\n",
       "Florida                 (264325.471, 327322.823]\n",
       "Georgia                   (11706.087, 75333.413]\n",
       "Hawaii                  (264325.471, 327322.823]\n",
       "Idaho                     (11706.087, 75333.413]\n",
       "Illinois                 (75333.413, 138330.766]\n",
       "Indiana                   (11706.087, 75333.413]\n",
       "Iowa                      (11706.087, 75333.413]\n",
       "Kansas                    (11706.087, 75333.413]\n",
       "Kentucky                  (11706.087, 75333.413]\n",
       "Louisiana                 (11706.087, 75333.413]\n",
       "Maine                    (75333.413, 138330.766]\n",
       "Maryland                (201328.118, 264325.471]\n",
       "Massachusetts           (453317.529, 516314.881]\n",
       "Michigan                 (75333.413, 138330.766]\n",
       "Minnesota                 (11706.087, 75333.413]\n",
       "Mississippi               (11706.087, 75333.413]\n",
       "Missouri                  (11706.087, 75333.413]\n",
       "Montana                   (11706.087, 75333.413]\n",
       "Nebraska                  (11706.087, 75333.413]\n",
       "Nevada                  (138330.766, 201328.118]\n",
       "New Hampshire            (75333.413, 138330.766]\n",
       "New Jersey              (390320.176, 453317.529]\n",
       "New Mexico                (11706.087, 75333.413]\n",
       "New York                (264325.471, 327322.823]\n",
       "North Carolina           (75333.413, 138330.766]\n",
       "North Dakota              (11706.087, 75333.413]\n",
       "Ohio                     (75333.413, 138330.766]\n",
       "Oklahoma                  (11706.087, 75333.413]\n",
       "Oregon                   (75333.413, 138330.766]\n",
       "Pennsylvania            (138330.766, 201328.118]\n",
       "Rhode Island            (201328.118, 264325.471]\n",
       "South Carolina           (75333.413, 138330.766]\n",
       "South Dakota              (11706.087, 75333.413]\n",
       "Tennessee                 (11706.087, 75333.413]\n",
       "Texas                    (75333.413, 138330.766]\n",
       "Utah                     (75333.413, 138330.766]\n",
       "Vermont                   (11706.087, 75333.413]\n",
       "Virginia                  (11706.087, 75333.413]\n",
       "Washington              (138330.766, 201328.118]\n",
       "West Virginia             (11706.087, 75333.413]\n",
       "Wisconsin                (75333.413, 138330.766]\n",
       "Wyoming                   (11706.087, 75333.413]\n",
       "Name: CENSUS2010POP, dtype: category\n",
       "Categories (10, interval[float64]): [(11706.087, 75333.413] < (75333.413, 138330.766] < (138330.766, 201328.118] < (201328.118, 264325.471] ... (390320.176, 453317.529] < (453317.529, 516314.881] < (516314.881, 579312.234] < (579312.234, 642309.586]]"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now if we just want to make \"bins\" of each of these, we can use cut()\n",
    "pd.cut(df,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we see that states like alabama and alaska fall into the same category, while california and the\n",
    "# disctrict of columbia fall in a very different category.\n",
    "\n",
    "# Now, cutting is just one way to build categories from your data, and there are many other methods. For\n",
    "# instance, cut gives you interval data, where the spacing between each category is equal sized. But sometimes\n",
    "# you want to form categories based on frequency – you want the number of items in each bin to the be the\n",
    "# same, instead of the spacing between bins. It really depends on what the shape of your data is, and what\n",
    "# you’re planning to do with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>world_rank</th>\n",
       "      <th>institution</th>\n",
       "      <th>country</th>\n",
       "      <th>national_rank</th>\n",
       "      <th>quality_of_education</th>\n",
       "      <th>alumni_employment</th>\n",
       "      <th>quality_of_faculty</th>\n",
       "      <th>publications</th>\n",
       "      <th>influence</th>\n",
       "      <th>citations</th>\n",
       "      <th>broad_impact</th>\n",
       "      <th>patents</th>\n",
       "      <th>score</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Harvard University</td>\n",
       "      <td>USA</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>100.00</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Massachusetts Institute of Technology</td>\n",
       "      <td>USA</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>91.67</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Stanford University</td>\n",
       "      <td>USA</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>89.50</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>University of Cambridge</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>86.17</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>California Institute of Technology</td>\n",
       "      <td>USA</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "      <td>37</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "      <td>85.21</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   world_rank                            institution         country  \\\n",
       "0           1                     Harvard University             USA   \n",
       "1           2  Massachusetts Institute of Technology             USA   \n",
       "2           3                    Stanford University             USA   \n",
       "3           4                University of Cambridge  United Kingdom   \n",
       "4           5     California Institute of Technology             USA   \n",
       "\n",
       "   national_rank  quality_of_education  alumni_employment  quality_of_faculty  \\\n",
       "0              1                     7                  9                   1   \n",
       "1              2                     9                 17                   3   \n",
       "2              3                    17                 11                   5   \n",
       "3              1                    10                 24                   4   \n",
       "4              4                     2                 29                   7   \n",
       "\n",
       "   publications  influence  citations  broad_impact  patents   score  year  \n",
       "0             1          1          1           NaN        5  100.00  2012  \n",
       "1            12          4          4           NaN        1   91.67  2012  \n",
       "2             4          2          2           NaN       15   89.50  2012  \n",
       "3            16         16         11           NaN       50   86.17  2012  \n",
       "4            37         22         22           NaN       18   85.21  2012  "
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we have the Times Higher Education World University Ranking dataset, which is one of the most\n",
    "# influential university measures. Let's import the dataset and see what it looks like\n",
    "df = pd.read_csv('datasets/cwurData.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>world_rank</th>\n",
       "      <th>institution</th>\n",
       "      <th>country</th>\n",
       "      <th>national_rank</th>\n",
       "      <th>quality_of_education</th>\n",
       "      <th>alumni_employment</th>\n",
       "      <th>quality_of_faculty</th>\n",
       "      <th>publications</th>\n",
       "      <th>influence</th>\n",
       "      <th>citations</th>\n",
       "      <th>broad_impact</th>\n",
       "      <th>patents</th>\n",
       "      <th>score</th>\n",
       "      <th>year</th>\n",
       "      <th>Rank_Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Harvard University</td>\n",
       "      <td>USA</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>100.00</td>\n",
       "      <td>2012</td>\n",
       "      <td>First Tier Top Unversity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Massachusetts Institute of Technology</td>\n",
       "      <td>USA</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>91.67</td>\n",
       "      <td>2012</td>\n",
       "      <td>First Tier Top Unversity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Stanford University</td>\n",
       "      <td>USA</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>89.50</td>\n",
       "      <td>2012</td>\n",
       "      <td>First Tier Top Unversity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>University of Cambridge</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>86.17</td>\n",
       "      <td>2012</td>\n",
       "      <td>First Tier Top Unversity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>California Institute of Technology</td>\n",
       "      <td>USA</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "      <td>37</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "      <td>85.21</td>\n",
       "      <td>2012</td>\n",
       "      <td>First Tier Top Unversity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   world_rank                            institution         country  \\\n",
       "0           1                     Harvard University             USA   \n",
       "1           2  Massachusetts Institute of Technology             USA   \n",
       "2           3                    Stanford University             USA   \n",
       "3           4                University of Cambridge  United Kingdom   \n",
       "4           5     California Institute of Technology             USA   \n",
       "\n",
       "   national_rank  quality_of_education  alumni_employment  quality_of_faculty  \\\n",
       "0              1                     7                  9                   1   \n",
       "1              2                     9                 17                   3   \n",
       "2              3                    17                 11                   5   \n",
       "3              1                    10                 24                   4   \n",
       "4              4                     2                 29                   7   \n",
       "\n",
       "   publications  influence  citations  broad_impact  patents   score  year  \\\n",
       "0             1          1          1           NaN        5  100.00  2012   \n",
       "1            12          4          4           NaN        1   91.67  2012   \n",
       "2             4          2          2           NaN       15   89.50  2012   \n",
       "3            16         16         11           NaN       50   86.17  2012   \n",
       "4            37         22         22           NaN       18   85.21  2012   \n",
       "\n",
       "                 Rank_Level  \n",
       "0  First Tier Top Unversity  \n",
       "1  First Tier Top Unversity  \n",
       "2  First Tier Top Unversity  \n",
       "3  First Tier Top Unversity  \n",
       "4  First Tier Top Unversity  "
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we can see each institution's rank, country, quality of education, other metrics, and overall score.\n",
    "# Let's say we want to create a new column called Rank_Level, where institutions with world ranking 1-100 are\n",
    "# categorized as first tier and those with world ranking 101 - 200 are second tier, ranking 201 - 300 are\n",
    "# third tier, after 301 is other top universities.\n",
    "\n",
    "# Now, you actually already have enough knowledge to do this, so why don't you pause the video and give it a\n",
    "# try?\n",
    "\n",
    "# Here's my solution, I'm going to create a function called create_category which will operate on the first\n",
    "# column in the dataframe, world_rank\n",
    "def create_category(ranking):\n",
    "    # Since the rank is just an integer, I'll just do a bunch of if/elif statements\n",
    "    if (ranking >= 1) & (ranking <= 100):\n",
    "        return \"First Tier Top Unversity\"\n",
    "    elif (ranking >= 101) & (ranking <= 200):\n",
    "        return \"Second Tier Top Unversity\"\n",
    "    elif (ranking >= 201) & (ranking <= 300):\n",
    "        return \"Third Tier Top Unversity\"\n",
    "    return \"Other Top Unversity\"\n",
    "\n",
    "# Now we can apply this to a single column of data to create a new series\n",
    "df['Rank_Level'] = df['world_rank'].apply(lambda x: create_category(x))\n",
    "# And lets look at the result\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rank_Level</th>\n",
       "      <th>First Tier Top Unversity</th>\n",
       "      <th>Other Top Unversity</th>\n",
       "      <th>Second Tier Top Unversity</th>\n",
       "      <th>Third Tier Top Unversity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Argentina</th>\n",
       "      <td>NaN</td>\n",
       "      <td>44.672857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia</th>\n",
       "      <td>47.9425</td>\n",
       "      <td>44.645750</td>\n",
       "      <td>49.2425</td>\n",
       "      <td>47.285000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Austria</th>\n",
       "      <td>NaN</td>\n",
       "      <td>44.864286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Belgium</th>\n",
       "      <td>51.8750</td>\n",
       "      <td>45.081000</td>\n",
       "      <td>49.0840</td>\n",
       "      <td>46.746667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brazil</th>\n",
       "      <td>NaN</td>\n",
       "      <td>44.499706</td>\n",
       "      <td>49.5650</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               mean                      \\\n",
       "Rank_Level First Tier Top Unversity Other Top Unversity   \n",
       "country                                                   \n",
       "Argentina                       NaN           44.672857   \n",
       "Australia                   47.9425           44.645750   \n",
       "Austria                         NaN           44.864286   \n",
       "Belgium                     51.8750           45.081000   \n",
       "Brazil                          NaN           44.499706   \n",
       "\n",
       "                                                               \n",
       "Rank_Level Second Tier Top Unversity Third Tier Top Unversity  \n",
       "country                                                        \n",
       "Argentina                        NaN                      NaN  \n",
       "Australia                    49.2425                47.285000  \n",
       "Austria                          NaN                47.066667  \n",
       "Belgium                      49.0840                46.746667  \n",
       "Brazil                       49.5650                      NaN  "
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A pivot table allows us to pivot out one of these columns a new column headers and compare it against\n",
    "# another column as row indices. Let's say we want to compare rank level versus country of the universities\n",
    "# and we want to compare in terms of overall score\n",
    "\n",
    "# To do this, we tell Pandas we want the values to be Score, and index to be the country and the columns to be\n",
    "# the rank levels. Then we specify that the aggregation function, and here we'll use the NumPy mean to get the\n",
    "# average rating for universities in that country\n",
    "\n",
    "df.pivot_table(values='score', index='country', columns='Rank_Level', aggfunc=[np.mean]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see a  hierarchical dataframe where the index, or rows, are by country and the columns have two\n",
    "# levels, the top level indicating that the mean value is being used and the second level being our ranks. In\n",
    "# this example we only have one variable, the mean, that we are looking at, so we don't really need a\n",
    "# heirarchical index.\n",
    "\n",
    "# We notice that there are some NaN values, for example, the first row, Argentia. The NaN values indicate that\n",
    "# Argentia has only observations in the \"Other Top Unversities\" category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">mean</th>\n",
       "      <th colspan=\"4\" halign=\"left\">amax</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rank_Level</th>\n",
       "      <th>First Tier Top Unversity</th>\n",
       "      <th>Other Top Unversity</th>\n",
       "      <th>Second Tier Top Unversity</th>\n",
       "      <th>Third Tier Top Unversity</th>\n",
       "      <th>First Tier Top Unversity</th>\n",
       "      <th>Other Top Unversity</th>\n",
       "      <th>Second Tier Top Unversity</th>\n",
       "      <th>Third Tier Top Unversity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Argentina</th>\n",
       "      <td>NaN</td>\n",
       "      <td>44.672857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia</th>\n",
       "      <td>47.9425</td>\n",
       "      <td>44.645750</td>\n",
       "      <td>49.2425</td>\n",
       "      <td>47.285000</td>\n",
       "      <td>51.61</td>\n",
       "      <td>45.97</td>\n",
       "      <td>50.40</td>\n",
       "      <td>47.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Austria</th>\n",
       "      <td>NaN</td>\n",
       "      <td>44.864286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.066667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Belgium</th>\n",
       "      <td>51.8750</td>\n",
       "      <td>45.081000</td>\n",
       "      <td>49.0840</td>\n",
       "      <td>46.746667</td>\n",
       "      <td>52.03</td>\n",
       "      <td>46.21</td>\n",
       "      <td>49.73</td>\n",
       "      <td>47.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brazil</th>\n",
       "      <td>NaN</td>\n",
       "      <td>44.499706</td>\n",
       "      <td>49.5650</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.08</td>\n",
       "      <td>49.82</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               mean                      \\\n",
       "Rank_Level First Tier Top Unversity Other Top Unversity   \n",
       "country                                                   \n",
       "Argentina                       NaN           44.672857   \n",
       "Australia                   47.9425           44.645750   \n",
       "Austria                         NaN           44.864286   \n",
       "Belgium                     51.8750           45.081000   \n",
       "Brazil                          NaN           44.499706   \n",
       "\n",
       "                                                               \\\n",
       "Rank_Level Second Tier Top Unversity Third Tier Top Unversity   \n",
       "country                                                         \n",
       "Argentina                        NaN                      NaN   \n",
       "Australia                    49.2425                47.285000   \n",
       "Austria                          NaN                47.066667   \n",
       "Belgium                      49.0840                46.746667   \n",
       "Brazil                       49.5650                      NaN   \n",
       "\n",
       "                               amax                      \\\n",
       "Rank_Level First Tier Top Unversity Other Top Unversity   \n",
       "country                                                   \n",
       "Argentina                       NaN               45.66   \n",
       "Australia                     51.61               45.97   \n",
       "Austria                         NaN               46.29   \n",
       "Belgium                       52.03               46.21   \n",
       "Brazil                          NaN               46.08   \n",
       "\n",
       "                                                               \n",
       "Rank_Level Second Tier Top Unversity Third Tier Top Unversity  \n",
       "country                                                        \n",
       "Argentina                        NaN                      NaN  \n",
       "Australia                      50.40                    47.47  \n",
       "Austria                          NaN                    47.78  \n",
       "Belgium                        49.73                    47.14  \n",
       "Brazil                         49.82                      NaN  "
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, pivot tables aren't limited to one function that you might want to apply. You can pass a named\n",
    "# parameter, aggfunc, which is a list of the different functions to apply, and pandas will provide you with\n",
    "# the result using hierarchical column names.  Let's try that same query, but pass in the max() function too\n",
    "\n",
    "df.pivot_table(values='score', index='country', columns='Rank_Level', aggfunc=[np.mean, np.max]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">mean</th>\n",
       "      <th colspan=\"5\" halign=\"left\">amax</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rank_Level</th>\n",
       "      <th>First Tier Top Unversity</th>\n",
       "      <th>Other Top Unversity</th>\n",
       "      <th>Second Tier Top Unversity</th>\n",
       "      <th>Third Tier Top Unversity</th>\n",
       "      <th>All</th>\n",
       "      <th>First Tier Top Unversity</th>\n",
       "      <th>Other Top Unversity</th>\n",
       "      <th>Second Tier Top Unversity</th>\n",
       "      <th>Third Tier Top Unversity</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Argentina</th>\n",
       "      <td>NaN</td>\n",
       "      <td>44.672857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.672857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia</th>\n",
       "      <td>47.9425</td>\n",
       "      <td>44.645750</td>\n",
       "      <td>49.2425</td>\n",
       "      <td>47.285000</td>\n",
       "      <td>45.825517</td>\n",
       "      <td>51.61</td>\n",
       "      <td>45.97</td>\n",
       "      <td>50.40</td>\n",
       "      <td>47.47</td>\n",
       "      <td>51.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Austria</th>\n",
       "      <td>NaN</td>\n",
       "      <td>44.864286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.066667</td>\n",
       "      <td>45.139583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.78</td>\n",
       "      <td>47.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Belgium</th>\n",
       "      <td>51.8750</td>\n",
       "      <td>45.081000</td>\n",
       "      <td>49.0840</td>\n",
       "      <td>46.746667</td>\n",
       "      <td>47.011000</td>\n",
       "      <td>52.03</td>\n",
       "      <td>46.21</td>\n",
       "      <td>49.73</td>\n",
       "      <td>47.14</td>\n",
       "      <td>52.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brazil</th>\n",
       "      <td>NaN</td>\n",
       "      <td>44.499706</td>\n",
       "      <td>49.5650</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.781111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.08</td>\n",
       "      <td>49.82</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               mean                      \\\n",
       "Rank_Level First Tier Top Unversity Other Top Unversity   \n",
       "country                                                   \n",
       "Argentina                       NaN           44.672857   \n",
       "Australia                   47.9425           44.645750   \n",
       "Austria                         NaN           44.864286   \n",
       "Belgium                     51.8750           45.081000   \n",
       "Brazil                          NaN           44.499706   \n",
       "\n",
       "                                                                          \\\n",
       "Rank_Level Second Tier Top Unversity Third Tier Top Unversity        All   \n",
       "country                                                                    \n",
       "Argentina                        NaN                      NaN  44.672857   \n",
       "Australia                    49.2425                47.285000  45.825517   \n",
       "Austria                          NaN                47.066667  45.139583   \n",
       "Belgium                      49.0840                46.746667  47.011000   \n",
       "Brazil                       49.5650                      NaN  44.781111   \n",
       "\n",
       "                               amax                      \\\n",
       "Rank_Level First Tier Top Unversity Other Top Unversity   \n",
       "country                                                   \n",
       "Argentina                       NaN               45.66   \n",
       "Australia                     51.61               45.97   \n",
       "Austria                         NaN               46.29   \n",
       "Belgium                       52.03               46.21   \n",
       "Brazil                          NaN               46.08   \n",
       "\n",
       "                                                                      \n",
       "Rank_Level Second Tier Top Unversity Third Tier Top Unversity    All  \n",
       "country                                                               \n",
       "Argentina                        NaN                      NaN  45.66  \n",
       "Australia                      50.40                    47.47  51.61  \n",
       "Austria                          NaN                    47.78  47.78  \n",
       "Belgium                        49.73                    47.14  52.03  \n",
       "Brazil                         49.82                      NaN  49.82  "
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So now we see we have both the mean and the max. As mentioned earlier, we can also summarize the values\n",
    "# within a given top level column. For instance, if we want to see an overall average for the country for the\n",
    "# mean and we want to see the max of the max, we can indicate that we want pandas to provide marginal values\n",
    "df.pivot_table(values='score', index='country', columns='Rank_Level', aggfunc=[np.mean, np.max], \n",
    "               margins=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Argentina', 'Australia', 'Austria', 'Belgium', 'Brazil', 'Bulgaria',\n",
      "       'Canada', 'Chile', 'China', 'Colombia', 'Croatia', 'Cyprus',\n",
      "       'Czech Republic', 'Denmark', 'Egypt', 'Estonia', 'Finland', 'France',\n",
      "       'Germany', 'Greece', 'Hong Kong', 'Hungary', 'Iceland', 'India', 'Iran',\n",
      "       'Ireland', 'Israel', 'Italy', 'Japan', 'Lebanon', 'Lithuania',\n",
      "       'Malaysia', 'Mexico', 'Netherlands', 'New Zealand', 'Norway', 'Poland',\n",
      "       'Portugal', 'Puerto Rico', 'Romania', 'Russia', 'Saudi Arabia',\n",
      "       'Serbia', 'Singapore', 'Slovak Republic', 'Slovenia', 'South Africa',\n",
      "       'South Korea', 'Spain', 'Sweden', 'Switzerland', 'Taiwan', 'Thailand',\n",
      "       'Turkey', 'USA', 'Uganda', 'United Arab Emirates', 'United Kingdom',\n",
      "       'Uruguay', 'All'],\n",
      "      dtype='object', name='country')\n",
      "MultiIndex([('mean',  'First Tier Top Unversity'),\n",
      "            ('mean',       'Other Top Unversity'),\n",
      "            ('mean', 'Second Tier Top Unversity'),\n",
      "            ('mean',  'Third Tier Top Unversity'),\n",
      "            ('mean',                       'All'),\n",
      "            ('amax',  'First Tier Top Unversity'),\n",
      "            ('amax',       'Other Top Unversity'),\n",
      "            ('amax', 'Second Tier Top Unversity'),\n",
      "            ('amax',  'Third Tier Top Unversity'),\n",
      "            ('amax',                       'All')],\n",
      "           names=[None, 'Rank_Level'])\n"
     ]
    }
   ],
   "source": [
    "# A pivot table is just a multi-level dataframe, and we can access series or cells in the dataframe in a similar way \n",
    "# as we do so for a regular dataframe. \n",
    "\n",
    "# Let's create a new dataframe from our previous example\n",
    "new_df=df.pivot_table(values='score', index='country', columns='Rank_Level', aggfunc=[np.mean, np.max], \n",
    "               margins=True)\n",
    "# Now let's look at the index\n",
    "print(new_df.index)\n",
    "# And let's look at the columns\n",
    "print(new_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country\n",
       "Argentina        NaN\n",
       "Australia    47.9425\n",
       "Austria          NaN\n",
       "Belgium      51.8750\n",
       "Brazil           NaN\n",
       "Name: First Tier Top Unversity, dtype: float64"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can see the columns are hierarchical. The top level column indices have two categories: mean and max, and\n",
    "# the lower level column indices have four categories, which are the four rank levels. How would we query this\n",
    "# if we want to get the average scores of First Tier Top Unversity levels in each country? We would just need\n",
    "# to make two dataframe projections, the first for the mean, then the second for the top tier\n",
    "new_df['mean']['First Tier Top Unversity'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can see that the output is a series object which we can confirm by printing the type. Remember that when\n",
    "# you project a single column of values out of a DataFrame you get a series.\n",
    "type(new_df['mean']['First Tier Top Unversity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'United Kingdom'"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What if we want to find the country that has the maximum average score on First Tier Top University level?\n",
    "# We can use the idxmax() function.\n",
    "new_df['mean']['First Tier Top Unversity'].idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, the idxmax() function isn't special for pivot tables, it's a built in function to the Series object.\n",
    "# We don't have time to go over all pandas functions and attributes, and I want to encourage you to explore\n",
    "# the API to learn more deeply what is available to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">mean</th>\n",
       "      <th colspan=\"5\" halign=\"left\">amax</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rank_Level</th>\n",
       "      <th>First Tier Top Unversity</th>\n",
       "      <th>Other Top Unversity</th>\n",
       "      <th>Second Tier Top Unversity</th>\n",
       "      <th>Third Tier Top Unversity</th>\n",
       "      <th>All</th>\n",
       "      <th>First Tier Top Unversity</th>\n",
       "      <th>Other Top Unversity</th>\n",
       "      <th>Second Tier Top Unversity</th>\n",
       "      <th>Third Tier Top Unversity</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Argentina</th>\n",
       "      <td>NaN</td>\n",
       "      <td>44.672857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.672857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia</th>\n",
       "      <td>47.9425</td>\n",
       "      <td>44.645750</td>\n",
       "      <td>49.2425</td>\n",
       "      <td>47.285000</td>\n",
       "      <td>45.825517</td>\n",
       "      <td>51.61</td>\n",
       "      <td>45.97</td>\n",
       "      <td>50.40</td>\n",
       "      <td>47.47</td>\n",
       "      <td>51.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Austria</th>\n",
       "      <td>NaN</td>\n",
       "      <td>44.864286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.066667</td>\n",
       "      <td>45.139583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.78</td>\n",
       "      <td>47.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Belgium</th>\n",
       "      <td>51.8750</td>\n",
       "      <td>45.081000</td>\n",
       "      <td>49.0840</td>\n",
       "      <td>46.746667</td>\n",
       "      <td>47.011000</td>\n",
       "      <td>52.03</td>\n",
       "      <td>46.21</td>\n",
       "      <td>49.73</td>\n",
       "      <td>47.14</td>\n",
       "      <td>52.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brazil</th>\n",
       "      <td>NaN</td>\n",
       "      <td>44.499706</td>\n",
       "      <td>49.5650</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.781111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.08</td>\n",
       "      <td>49.82</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               mean                      \\\n",
       "Rank_Level First Tier Top Unversity Other Top Unversity   \n",
       "country                                                   \n",
       "Argentina                       NaN           44.672857   \n",
       "Australia                   47.9425           44.645750   \n",
       "Austria                         NaN           44.864286   \n",
       "Belgium                     51.8750           45.081000   \n",
       "Brazil                          NaN           44.499706   \n",
       "\n",
       "                                                                          \\\n",
       "Rank_Level Second Tier Top Unversity Third Tier Top Unversity        All   \n",
       "country                                                                    \n",
       "Argentina                        NaN                      NaN  44.672857   \n",
       "Australia                    49.2425                47.285000  45.825517   \n",
       "Austria                          NaN                47.066667  45.139583   \n",
       "Belgium                      49.0840                46.746667  47.011000   \n",
       "Brazil                       49.5650                      NaN  44.781111   \n",
       "\n",
       "                               amax                      \\\n",
       "Rank_Level First Tier Top Unversity Other Top Unversity   \n",
       "country                                                   \n",
       "Argentina                       NaN               45.66   \n",
       "Australia                     51.61               45.97   \n",
       "Austria                         NaN               46.29   \n",
       "Belgium                       52.03               46.21   \n",
       "Brazil                          NaN               46.08   \n",
       "\n",
       "                                                                      \n",
       "Rank_Level Second Tier Top Unversity Third Tier Top Unversity    All  \n",
       "country                                                               \n",
       "Argentina                        NaN                      NaN  45.66  \n",
       "Australia                      50.40                    47.47  51.61  \n",
       "Austria                          NaN                    47.78  47.78  \n",
       "Belgium                        49.73                    47.14  52.03  \n",
       "Brazil                         49.82                      NaN  49.82  "
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you want to achieve a different shape of your pivot table, you can do so with the stack and unstack\n",
    "# functions. Stacking is pivoting the lowermost column index to become the innermost row index. Unstacking is\n",
    "# the inverse of stacking, pivoting the innermost row index to become the lowermost column index. An example\n",
    "# will help make this clear\n",
    "\n",
    "# Let's look at our pivot table first to refresh what it looks like\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>amax</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <th>Rank_Level</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Argentina</th>\n",
       "      <th>Other Top Unversity</th>\n",
       "      <td>44.672857</td>\n",
       "      <td>45.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>44.672857</td>\n",
       "      <td>45.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Australia</th>\n",
       "      <th>First Tier Top Unversity</th>\n",
       "      <td>47.942500</td>\n",
       "      <td>51.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other Top Unversity</th>\n",
       "      <td>44.645750</td>\n",
       "      <td>45.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Second Tier Top Unversity</th>\n",
       "      <td>49.242500</td>\n",
       "      <td>50.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          mean   amax\n",
       "country   Rank_Level                                 \n",
       "Argentina Other Top Unversity        44.672857  45.66\n",
       "          All                        44.672857  45.66\n",
       "Australia First Tier Top Unversity   47.942500  51.61\n",
       "          Other Top Unversity        44.645750  45.97\n",
       "          Second Tier Top Unversity  49.242500  50.40"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's try stacking, this should move the lowermost column, so the tiers of the university rankings, to\n",
    "# the inner most row\n",
    "new_df=new_df.stack()\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">mean</th>\n",
       "      <th colspan=\"5\" halign=\"left\">amax</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rank_Level</th>\n",
       "      <th>First Tier Top Unversity</th>\n",
       "      <th>Other Top Unversity</th>\n",
       "      <th>Second Tier Top Unversity</th>\n",
       "      <th>Third Tier Top Unversity</th>\n",
       "      <th>All</th>\n",
       "      <th>First Tier Top Unversity</th>\n",
       "      <th>Other Top Unversity</th>\n",
       "      <th>Second Tier Top Unversity</th>\n",
       "      <th>Third Tier Top Unversity</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>58.350675</td>\n",
       "      <td>44.738871</td>\n",
       "      <td>49.06545</td>\n",
       "      <td>46.843450</td>\n",
       "      <td>47.798395</td>\n",
       "      <td>100.00</td>\n",
       "      <td>46.34</td>\n",
       "      <td>51.29</td>\n",
       "      <td>47.93</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Argentina</th>\n",
       "      <td>NaN</td>\n",
       "      <td>44.672857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.672857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia</th>\n",
       "      <td>47.942500</td>\n",
       "      <td>44.645750</td>\n",
       "      <td>49.24250</td>\n",
       "      <td>47.285000</td>\n",
       "      <td>45.825517</td>\n",
       "      <td>51.61</td>\n",
       "      <td>45.97</td>\n",
       "      <td>50.40</td>\n",
       "      <td>47.47</td>\n",
       "      <td>51.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Austria</th>\n",
       "      <td>NaN</td>\n",
       "      <td>44.864286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.066667</td>\n",
       "      <td>45.139583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.78</td>\n",
       "      <td>47.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Belgium</th>\n",
       "      <td>51.875000</td>\n",
       "      <td>45.081000</td>\n",
       "      <td>49.08400</td>\n",
       "      <td>46.746667</td>\n",
       "      <td>47.011000</td>\n",
       "      <td>52.03</td>\n",
       "      <td>46.21</td>\n",
       "      <td>49.73</td>\n",
       "      <td>47.14</td>\n",
       "      <td>52.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               mean                      \\\n",
       "Rank_Level First Tier Top Unversity Other Top Unversity   \n",
       "country                                                   \n",
       "All                       58.350675           44.738871   \n",
       "Argentina                       NaN           44.672857   \n",
       "Australia                 47.942500           44.645750   \n",
       "Austria                         NaN           44.864286   \n",
       "Belgium                   51.875000           45.081000   \n",
       "\n",
       "                                                                          \\\n",
       "Rank_Level Second Tier Top Unversity Third Tier Top Unversity        All   \n",
       "country                                                                    \n",
       "All                         49.06545                46.843450  47.798395   \n",
       "Argentina                        NaN                      NaN  44.672857   \n",
       "Australia                   49.24250                47.285000  45.825517   \n",
       "Austria                          NaN                47.066667  45.139583   \n",
       "Belgium                     49.08400                46.746667  47.011000   \n",
       "\n",
       "                               amax                      \\\n",
       "Rank_Level First Tier Top Unversity Other Top Unversity   \n",
       "country                                                   \n",
       "All                          100.00               46.34   \n",
       "Argentina                       NaN               45.66   \n",
       "Australia                     51.61               45.97   \n",
       "Austria                         NaN               46.29   \n",
       "Belgium                       52.03               46.21   \n",
       "\n",
       "                                                                       \n",
       "Rank_Level Second Tier Top Unversity Third Tier Top Unversity     All  \n",
       "country                                                                \n",
       "All                            51.29                    47.93  100.00  \n",
       "Argentina                        NaN                      NaN   45.66  \n",
       "Australia                      50.40                    47.47   51.61  \n",
       "Austria                          NaN                    47.78   47.78  \n",
       "Belgium                        49.73                    47.14   52.03  "
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In the original pivot table, rank levels are the lowermost column, after stacking, rank levels become the\n",
    "# innermost index, appearing to the right after country\n",
    "\n",
    "# Now let's try unstacking\n",
    "new_df.unstack().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      Rank_Level                country  \n",
       "mean  First Tier Top Unversity  All          58.350675\n",
       "                                Argentina          NaN\n",
       "                                Australia    47.942500\n",
       "                                Austria            NaN\n",
       "                                Belgium      51.875000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# That seems to restore our dataframe to its original shape. What do you think would happen if we unstacked twice in a row?\n",
    "new_df.unstack().unstack().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We actually end up unstacking all the way to just a single column, so a series object is returned. This\n",
    "# column is just a \"value\", the meaning of which is denoted by the heirarachical index of operation, rank, and\n",
    "# country."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that's pivot tables. This has been a pretty short description, but they're incredibly useful when dealing\n",
    "with numeric data, especially if you're trying to summarize the data in some form. You'll regularly be\n",
    "creating new pivot tables on slices of data, whether you're exploring the data yourself or preparing data\n",
    "for others to report on. And of course, you can pass any function you want to the aggregate function,\n",
    "including those that you define yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Date/Time Functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
